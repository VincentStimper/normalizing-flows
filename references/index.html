<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://github.com/VincentStimper/normalizing-flows/references/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>API - Normalizing Flows</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/fontawesome.min.css" rel="stylesheet">
        <link href="../css/brands.min.css" rel="stylesheet">
        <link href="../css/solid.min.css" rel="stylesheet">
        <link href="../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <link href="../assets/_mkdocstrings.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Normalizing Flows</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href=".." class="nav-link">About</a>
                            </li>
                            <li class="nav-item">
                                <a href="./" class="nav-link active" aria-current="page">API</a>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Examples</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../examples/augmented_flow/" class="dropdown-item">Augmented Normalizing Flow based on Real NVP</a>
</li>
                                    
<li>
    <a href="../examples/change_base_distribution/" class="dropdown-item">Changing the base distribution of a flow model</a>
</li>
                                    
<li>
    <a href="../examples/circular_nsf/" class="dropdown-item">Mixed Circular and Normal Neural Spline Flow</a>
</li>
                                    
<li>
    <a href="../examples/comparison_plan_rad_aff/" class="dropdown-item">Comparison of Planar, Radial, and Affine Coupling Flows</a>
</li>
                                    
<li>
    <a href="../examples/conditional_flow/" class="dropdown-item">Conditional Normalizing Flow Model</a>
</li>
                                    
<li>
    <a href="../examples/glow/" class="dropdown-item">Glow</a>
</li>
                                    
<li>
    <a href="../examples/image/" class="dropdown-item">Learn Distribution given by an Image using Real NVP</a>
</li>
                                    
<li>
    <a href="../examples/neural_spline_flow/" class="dropdown-item">Neural Spline Flow</a>
</li>
                                    
<li>
    <a href="../examples/paper_example_nsf/" class="dropdown-item">Neural Spline Flow on a Circular and a Normal Coordinate</a>
</li>
                                    
<li>
    <a href="../examples/planar/" class="dropdown-item">Planar flow</a>
</li>
                                    
<li>
    <a href="../examples/real_nvp/" class="dropdown-item">Real NVP</a>
</li>
                                    
<li>
    <a href="../examples/residual/" class="dropdown-item">Residual Flow</a>
</li>
                                    
<li>
    <a href="../examples/vae/" class="dropdown-item">Variational Autoencoder with Normalizing Flows</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href=".." class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../examples/augmented_flow/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#api-references" class="nav-link">API references</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#normflows" class="nav-link">normflows</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.ClassCondFlow" class="nav-link">ClassCondFlow</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.ConditionalNormalizingFlow" class="nav-link">ConditionalNormalizingFlow</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.MultiscaleFlow" class="nav-link">MultiscaleFlow</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.NormalizingFlow" class="nav-link">NormalizingFlow</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.NormalizingFlowVAE" class="nav-link">NormalizingFlowVAE</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.core" class="nav-link">core</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.distributions" class="nav-link">distributions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.flows" class="nav-link">flows</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.nets" class="nav-link">nets</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.sampling" class="nav-link">sampling</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.transforms" class="nav-link">transforms</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#normflows.utils" class="nav-link">utils</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="api-references">API references</h1>


<div class="doc doc-object doc-module">



<a id="normflows"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="normflows.ClassCondFlow" class="doc doc-heading">
            <code>ClassCondFlow</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Class conditional normalizing Flow model, providing the
class to be conditioned on only to the base distribution,
as done e.g. in <a href="https://arxiv.org/abs/1807.03039">Glow</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ClassCondFlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class conditional normalizing Flow model, providing the</span>
<span class="sd">    class to be conditioned on only to the base distribution,</span>
<span class="sd">    as done e.g. in [Glow](https://arxiv.org/abs/1807.03039)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          q0: Base distribution</span>
<span class="sd">          flows: List of flows</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          y: Classes to sample from, will be sampled uniformly if None</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>
<span class="sd">          y: Classes of x</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">        Args:</span>
<span class="sd">         param path: Path including filename where to save model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to load model from</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="normflows.ClassCondFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>q0</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Base distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>flows</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of flows</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      q0: Base distribution</span>
<span class="sd">      flows: List of flows</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ClassCondFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ClassCondFlow.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Load model from state dict</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to load model from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to load model from</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ClassCondFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes of x</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>
<span class="sd">      y: Classes of x</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ClassCondFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes to sample from, will be sampled uniformly if None</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      y: Classes to sample from, will be sampled uniformly if None</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ClassCondFlow.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Save state dict of model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>param</code></td>
            <td>
                  <code>path</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to save model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">    Args:</span>
<span class="sd">     param path: Path including filename where to save model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="normflows.ConditionalNormalizingFlow" class="doc doc-heading">
            <code>ConditionalNormalizingFlow</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.core.NormalizingFlow" href="#normflows.core.NormalizingFlow">NormalizingFlow</a></code></p>


      <p>Conditional normalizing flow model, providing condition,
which is also called context, to both the base distribution
and the flow layers</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ConditionalNormalizingFlow</span><span class="p">(</span><span class="n">NormalizingFlow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Conditional normalizing flow model, providing condition,</span>
<span class="sd">    which is also called context, to both the base distribution</span>
<span class="sd">    and the flow layers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution,</span>
<span class="sd">          log determinant of the Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space, log determinant of the</span>
<span class="sd">          Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw from base distribution</span>
<span class="sd">          context: Batch of conditions/context</span>
<span class="sd">          beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">          score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.forward_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_and_log_det</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution,</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log determinant of the Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution,</span>
<span class="sd">      log determinant of the Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.inverse" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.inverse_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse_and_log_det</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space, log determinant of the</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space, log determinant of the</span>
<span class="sd">      Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.reverse_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reverse_kld</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Estimates reverse KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw from base distribution</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>beta</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Annealing parameter, see <a href="https://arxiv.org/abs/1505.05770">arXiv 1505.05770</a></p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>score_fn</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to include score function in gradient, see <a href="https://arxiv.org/abs/1703.09194">arXiv 1703.09194</a></p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of the reverse KL divergence averaged over latent samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw from base distribution</span>
<span class="sd">      context: Batch of conditions/context</span>
<span class="sd">      beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">      score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.ConditionalNormalizingFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="normflows.MultiscaleFlow" class="doc doc-heading">
            <code>MultiscaleFlow</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Normalizing Flow model with multiscale architecture, see RealNVP or Glow paper</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiscaleFlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalizing Flow model with multiscale architecture, see RealNVP or Glow paper</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>

<span class="sd">          q0: List of base distribution</span>
<span class="sd">          flows: List of flows for each level</span>
<span class="sd">          merges: List of merge/split operations (forward pass must do merge)</span>
<span class="sd">          transform: Initial transformation of inputs</span>
<span class="sd">          class_cond: Flag, indicated whether model has class conditional</span>
<span class="sd">        base distributions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">q0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span> <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="n">flows</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">merges</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">class_cond</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>
<span class="sd">          y: Batch of classes to condition on, if applicable</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get negative log-likelihood for maximum likelihood training</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch of data</span>
<span class="sd">          y: Batch of classes to condition on, if applicable</span>

<span class="sd">        Returns:</span>
<span class="sd">            Negative log-likelihood of the batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get observed variable x from list of latent variables z</span>

<span class="sd">        Args:</span>
<span class="sd">            z: List of latent variables</span>

<span class="sd">        Returns:</span>
<span class="sd">            Observed variable x, log determinant of Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
            <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get latent variable z from observed variable x</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Observed variable</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of latent variables z, log determinant of Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          y: Classes to sample from, will be sampled uniformly if None</span>
<span class="sd">          temperature: Temperature parameter for temp annealed sampling</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q_</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
                <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">])</span>
                <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
            <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_temperature</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>
<span class="sd">          y: Classes of x. Must be passed in if `class_cond` is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">],</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to save model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to load model from</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">set_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set temperature for temperature a annealed sampling</span>

<span class="sd">        Args:</span>
<span class="sd">          temperature: Temperature parameter</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">q0</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="s2">&quot;temperature&quot;</span><span class="p">):</span>
                <span class="n">q0</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;One base function does not &quot;</span>
                    <span class="s2">&quot;support temperature annealed sampling&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set temperature values of base distributions back to None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Constructor</p>
<p>Args:</p>
<p>q0: List of base distribution
  flows: List of flows for each level
  merges: List of merge/split operations (forward pass must do merge)
  transform: Initial transformation of inputs
  class_cond: Flag, indicated whether model has class conditional
base distributions</p>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>

<span class="sd">      q0: List of base distribution</span>
<span class="sd">      flows: List of flows for each level</span>
<span class="sd">      merges: List of merge/split operations (forward pass must do merge)</span>
<span class="sd">      transform: Initial transformation of inputs</span>
<span class="sd">      class_cond: Flag, indicated whether model has class conditional</span>
<span class="sd">    base distributions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">q0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span> <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="n">flows</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">merges</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">class_cond</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Get negative log-likelihood for maximum likelihood training</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of classes to condition on, if applicable</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Negative log-likelihood of the batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get negative log-likelihood for maximum likelihood training</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch of data</span>
<span class="sd">      y: Batch of classes to condition on, if applicable</span>

<span class="sd">    Returns:</span>
<span class="sd">        Negative log-likelihood of the batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.forward_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_and_log_det</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Get observed variable x from list of latent variables z</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of latent variables</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed variable x, log determinant of Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get observed variable x from list of latent variables z</span>

<span class="sd">    Args:</span>
<span class="sd">        z: List of latent variables</span>

<span class="sd">    Returns:</span>
<span class="sd">        Observed variable x, log determinant of Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of classes to condition on, if applicable</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>
<span class="sd">      y: Batch of classes to condition on, if applicable</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.inverse_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse_and_log_det</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Get latent variable z from observed variable x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of latent variables z, log determinant of Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get latent variable z from observed variable x</span>

<span class="sd">    Args:</span>
<span class="sd">        x: Observed variable</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of latent variables z, log determinant of Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Load model from state dict</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to load model from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to load model from</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes of x. Must be passed in if <code>class_cond</code> is True.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>
<span class="sd">      y: Classes of x. Must be passed in if `class_cond` is True.</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">],</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.reset_temperature" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset_temperature</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Set temperature values of base distributions back to None</p>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reset_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set temperature values of base distributions back to None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes to sample from, will be sampled uniformly if None</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>temperature</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Temperature parameter for temp annealed sampling</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      y: Classes to sample from, will be sampled uniformly if None</span>
<span class="sd">      temperature: Temperature parameter for temp annealed sampling</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q_</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">])</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_temperature</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Save state dict of model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to save model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to save model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.MultiscaleFlow.set_temperature" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">set_temperature</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Set temperature for temperature a annealed sampling</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>temperature</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Temperature parameter</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set temperature for temperature a annealed sampling</span>

<span class="sd">    Args:</span>
<span class="sd">      temperature: Temperature parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">q0</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="s2">&quot;temperature&quot;</span><span class="p">):</span>
            <span class="n">q0</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;One base function does not &quot;</span>
                <span class="s2">&quot;support temperature annealed sampling&quot;</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="normflows.NormalizingFlow" class="doc doc-heading">
            <code>NormalizingFlow</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Normalizing Flow model to approximate target distribution</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NormalizingFlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalizing Flow model to approximate target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          q0: Base distribution</span>
<span class="sd">          flows: List of flows</span>
<span class="sd">          p: Target distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution,</span>
<span class="sd">          log determinant of the Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space, log determinant of the</span>
<span class="sd">          Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw from base distribution</span>
<span class="sd">          beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">          score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reverse_alpha_div</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dreg</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alpha divergence when sampling from q</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          dreg: Flag whether to use Double Reparametrized Gradient estimator, see [arXiv 1810.04152](https://arxiv.org/abs/1810.04152)</span>

<span class="sd">        Returns:</span>
<span class="sd">          Alpha divergence</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dreg</span><span class="p">:</span>
            <span class="n">w_const</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span>
            <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_const</span><span class="o">**</span><span class="n">alpha</span>
            <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_alpha</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w_alpha</span><span class="p">)</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">w_alpha</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">w_alpha</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to save model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to load model from</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>q0</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Base distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>flows</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of flows</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>p</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target distribution</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      q0: Base distribution</span>
<span class="sd">      flows: List of flows</span>
<span class="sd">      p: Target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.forward_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_and_log_det</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution,</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log determinant of the Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution,</span>
<span class="sd">      log determinant of the Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.inverse" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.inverse_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse_and_log_det</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space, log determinant of the</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space, log determinant of the</span>
<span class="sd">      Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Load model from state dict</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to load model from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to load model from</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.reverse_alpha_div" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reverse_alpha_div</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dreg</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Alpha divergence when sampling from q</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dreg</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to use Double Reparametrized Gradient estimator, see <a href="https://arxiv.org/abs/1810.04152">arXiv 1810.04152</a></p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Alpha divergence</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reverse_alpha_div</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dreg</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Alpha divergence when sampling from q</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      dreg: Flag whether to use Double Reparametrized Gradient estimator, see [arXiv 1810.04152](https://arxiv.org/abs/1810.04152)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Alpha divergence</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dreg</span><span class="p">:</span>
        <span class="n">w_const</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span>
        <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_const</span><span class="o">**</span><span class="n">alpha</span>
        <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_alpha</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w_alpha</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">w_alpha</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">w_alpha</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.reverse_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reverse_kld</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Estimates reverse KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw from base distribution</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>beta</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Annealing parameter, see <a href="https://arxiv.org/abs/1505.05770">arXiv 1505.05770</a></p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>score_fn</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to include score function in gradient, see <a href="https://arxiv.org/abs/1703.09194">arXiv 1703.09194</a></p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of the reverse KL divergence averaged over latent samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw from base distribution</span>
<span class="sd">      beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">      score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlow.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Save state dict of model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to save model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to save model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="normflows.NormalizingFlowVAE" class="doc doc-heading">
            <code>NormalizingFlowVAE</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>VAE using normalizing flows to express approximate distribution</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NormalizingFlowVAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    VAE using normalizing flows to express approximate distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">q0</span><span class="o">=</span><span class="n">distributions</span><span class="o">.</span><span class="n">Dirac</span><span class="p">(),</span> <span class="n">flows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor of normalizing flow model</span>

<span class="sd">        Args:</span>
<span class="sd">          prior: Prior distribution of te VAE, i.e. Gaussian</span>
<span class="sd">          decoder: Optional decoder</span>
<span class="sd">          flows: Flows to transform output of base encoder</span>
<span class="sd">          q0: Base Encoder</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">prior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Takes data batch, samples num_samples for each data point from base distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          x: data batch</span>
<span class="sd">          num_samples: number of samples to draw for each data point</span>

<span class="sd">        Returns:</span>
<span class="sd">          latent variables for each batch and sample, log_q, and log_p</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="c1"># Flatten batch and sample dim</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_p</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
        <span class="c1"># Separate batch and sample dimension again</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_p</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_p</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span><span class="p">,</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlowVAE.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">q0</span><span class="o">=</span><span class="n">distributions</span><span class="o">.</span><span class="n">Dirac</span><span class="p">(),</span> <span class="n">flows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Constructor of normalizing flow model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prior</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prior distribution of te VAE, i.e. Gaussian</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional decoder</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>flows</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flows to transform output of base encoder</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>q0</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Base Encoder</p>
              </div>
            </td>
            <td>
                  <code><span title="normflows.distributions.Dirac">Dirac</span>()</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">q0</span><span class="o">=</span><span class="n">distributions</span><span class="o">.</span><span class="n">Dirac</span><span class="p">(),</span> <span class="n">flows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor of normalizing flow model</span>

<span class="sd">    Args:</span>
<span class="sd">      prior: Prior distribution of te VAE, i.e. Gaussian</span>
<span class="sd">      decoder: Optional decoder</span>
<span class="sd">      flows: Flows to transform output of base encoder</span>
<span class="sd">      q0: Base Encoder</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">prior</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="normflows.NormalizingFlowVAE.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Takes data batch, samples num_samples for each data point from base distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>data batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of samples to draw for each data point</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>latent variables for each batch and sample, log_q, and log_p</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Takes data batch, samples num_samples for each data point from base distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      x: data batch</span>
<span class="sd">      num_samples: number of samples to draw for each data point</span>

<span class="sd">    Returns:</span>
<span class="sd">      latent variables for each batch and sample, log_q, and log_p</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="c1"># Flatten batch and sample dim</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">log_p</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
    <span class="c1"># Separate batch and sample dimension again</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_p</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_p</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span><span class="p">,</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>



<div class="doc doc-object doc-module">



<h2 id="normflows.core" class="doc doc-heading">
            <code>core</code>


</h2>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="normflows.core.ClassCondFlow" class="doc doc-heading">
            <code>ClassCondFlow</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Class conditional normalizing Flow model, providing the
class to be conditioned on only to the base distribution,
as done e.g. in <a href="https://arxiv.org/abs/1807.03039">Glow</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ClassCondFlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class conditional normalizing Flow model, providing the</span>
<span class="sd">    class to be conditioned on only to the base distribution,</span>
<span class="sd">    as done e.g. in [Glow](https://arxiv.org/abs/1807.03039)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          q0: Base distribution</span>
<span class="sd">          flows: List of flows</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          y: Classes to sample from, will be sampled uniformly if None</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>
<span class="sd">          y: Classes of x</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">        Args:</span>
<span class="sd">         param path: Path including filename where to save model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to load model from</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.core.ClassCondFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>q0</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Base distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>flows</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of flows</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      q0: Base distribution</span>
<span class="sd">      flows: List of flows</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ClassCondFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ClassCondFlow.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Load model from state dict</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to load model from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to load model from</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ClassCondFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes of x</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>
<span class="sd">      y: Classes of x</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ClassCondFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes to sample from, will be sampled uniformly if None</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      y: Classes to sample from, will be sampled uniformly if None</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ClassCondFlow.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Save state dict of model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>param</code></td>
            <td>
                  <code>path</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to save model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">    Args:</span>
<span class="sd">     param path: Path including filename where to save model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="normflows.core.ConditionalNormalizingFlow" class="doc doc-heading">
            <code>ConditionalNormalizingFlow</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.core.NormalizingFlow" href="#normflows.core.NormalizingFlow">NormalizingFlow</a></code></p>


      <p>Conditional normalizing flow model, providing condition,
which is also called context, to both the base distribution
and the flow layers</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ConditionalNormalizingFlow</span><span class="p">(</span><span class="n">NormalizingFlow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Conditional normalizing flow model, providing condition,</span>
<span class="sd">    which is also called context, to both the base distribution</span>
<span class="sd">    and the flow layers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution,</span>
<span class="sd">          log determinant of the Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space, log determinant of the</span>
<span class="sd">          Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>
<span class="sd">          context: Batch of conditions/context</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw from base distribution</span>
<span class="sd">          context: Batch of conditions/context</span>
<span class="sd">          beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">          score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.forward_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_and_log_det</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution,</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log determinant of the Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution,</span>
<span class="sd">      log determinant of the Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.inverse" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.inverse_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse_and_log_det</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space, log determinant of the</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space, log determinant of the</span>
<span class="sd">      Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.reverse_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reverse_kld</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Estimates reverse KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw from base distribution</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>beta</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Annealing parameter, see <a href="https://arxiv.org/abs/1505.05770">arXiv 1505.05770</a></p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>score_fn</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to include score function in gradient, see <a href="https://arxiv.org/abs/1703.09194">arXiv 1703.09194</a></p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of the reverse KL divergence averaged over latent samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw from base distribution</span>
<span class="sd">      context: Batch of conditions/context</span>
<span class="sd">      beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">      score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.ConditionalNormalizingFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of conditions/context</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      context: Batch of conditions/context</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="normflows.core.MultiscaleFlow" class="doc doc-heading">
            <code>MultiscaleFlow</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Normalizing Flow model with multiscale architecture, see RealNVP or Glow paper</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiscaleFlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalizing Flow model with multiscale architecture, see RealNVP or Glow paper</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>

<span class="sd">          q0: List of base distribution</span>
<span class="sd">          flows: List of flows for each level</span>
<span class="sd">          merges: List of merge/split operations (forward pass must do merge)</span>
<span class="sd">          transform: Initial transformation of inputs</span>
<span class="sd">          class_cond: Flag, indicated whether model has class conditional</span>
<span class="sd">        base distributions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">q0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span> <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="n">flows</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">merges</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">class_cond</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>
<span class="sd">          y: Batch of classes to condition on, if applicable</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get negative log-likelihood for maximum likelihood training</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch of data</span>
<span class="sd">          y: Batch of classes to condition on, if applicable</span>

<span class="sd">        Returns:</span>
<span class="sd">            Negative log-likelihood of the batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get observed variable x from list of latent variables z</span>

<span class="sd">        Args:</span>
<span class="sd">            z: List of latent variables</span>

<span class="sd">        Returns:</span>
<span class="sd">            Observed variable x, log determinant of Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
            <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get latent variable z from observed variable x</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Observed variable</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of latent variables z, log determinant of Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          y: Classes to sample from, will be sampled uniformly if None</span>
<span class="sd">          temperature: Temperature parameter for temp annealed sampling</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q_</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
                <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">])</span>
                <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
            <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_temperature</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>
<span class="sd">          y: Classes of x. Must be passed in if `class_cond` is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">],</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to save model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to load model from</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">set_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set temperature for temperature a annealed sampling</span>

<span class="sd">        Args:</span>
<span class="sd">          temperature: Temperature parameter</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">q0</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="s2">&quot;temperature&quot;</span><span class="p">):</span>
                <span class="n">q0</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;One base function does not &quot;</span>
                    <span class="s2">&quot;support temperature annealed sampling&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set temperature values of base distributions back to None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Constructor</p>
<p>Args:</p>
<p>q0: List of base distribution
  flows: List of flows for each level
  merges: List of merge/split operations (forward pass must do merge)
  transform: Initial transformation of inputs
  class_cond: Flag, indicated whether model has class conditional
base distributions</p>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>

<span class="sd">      q0: List of base distribution</span>
<span class="sd">      flows: List of flows for each level</span>
<span class="sd">      merges: List of merge/split operations (forward pass must do merge)</span>
<span class="sd">      transform: Initial transformation of inputs</span>
<span class="sd">      class_cond: Flag, indicated whether model has class conditional</span>
<span class="sd">    base distributions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">q0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span> <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="n">flows</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">merges</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">class_cond</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Get negative log-likelihood for maximum likelihood training</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of classes to condition on, if applicable</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Negative log-likelihood of the batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get negative log-likelihood for maximum likelihood training</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch of data</span>
<span class="sd">      y: Batch of classes to condition on, if applicable</span>

<span class="sd">    Returns:</span>
<span class="sd">        Negative log-likelihood of the batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.forward_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_and_log_det</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Get observed variable x from list of latent variables z</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of latent variables</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed variable x, log determinant of Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get observed variable x from list of latent variables z</span>

<span class="sd">    Args:</span>
<span class="sd">        z: List of latent variables</span>

<span class="sd">    Returns:</span>
<span class="sd">        Observed variable x, log determinant of Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">z_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of classes to condition on, if applicable</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>
<span class="sd">      y: Batch of classes to condition on, if applicable</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.inverse_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse_and_log_det</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Get latent variable z from observed variable x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of latent variables z, log determinant of Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get latent variable z from observed variable x</span>

<span class="sd">    Args:</span>
<span class="sd">        x: Observed variable</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of latent variables z, log determinant of Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_det_</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Load model from state dict</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to load model from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to load model from</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes of x. Must be passed in if <code>class_cond</code> is True.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>
<span class="sd">      y: Classes of x. Must be passed in if `class_cond` is True.</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">],</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.reset_temperature" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset_temperature</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Set temperature values of base distributions back to None</p>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reset_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set temperature values of base distributions back to None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Classes to sample from, will be sampled uniformly if None</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>temperature</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Temperature parameter for temp annealed sampling</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      y: Classes to sample from, will be sampled uniformly if None</span>
<span class="sd">      temperature: Temperature parameter for temp annealed sampling</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_temperature</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">)):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q_</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merges</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">])</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_temperature</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Save state dict of model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to save model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to save model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.MultiscaleFlow.set_temperature" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">set_temperature</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Set temperature for temperature a annealed sampling</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>temperature</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Temperature parameter</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set temperature for temperature a annealed sampling</span>

<span class="sd">    Args:</span>
<span class="sd">      temperature: Temperature parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">q0</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="s2">&quot;temperature&quot;</span><span class="p">):</span>
            <span class="n">q0</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;One base function does not &quot;</span>
                <span class="s2">&quot;support temperature annealed sampling&quot;</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="normflows.core.NormalizingFlow" class="doc doc-heading">
            <code>NormalizingFlow</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Normalizing Flow model to approximate target distribution</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NormalizingFlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalizing Flow model to approximate target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          q0: Base distribution</span>
<span class="sd">          flows: List of flows</span>
<span class="sd">          p: Target distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch in the latent space</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the space of the target distribution,</span>
<span class="sd">          log determinant of the Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">        computes log determinant of the Jacobian</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch in the space of the target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Batch in the latent space, log determinant of the</span>
<span class="sd">          Jacobian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch sampled from target distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of forward KL divergence averaged over batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw from base distribution</span>
<span class="sd">          beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">          score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">        Returns:</span>
<span class="sd">          Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reverse_alpha_div</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dreg</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alpha divergence when sampling from q</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>
<span class="sd">          dreg: Flag whether to use Double Reparametrized Gradient estimator, see [arXiv 1810.04152](https://arxiv.org/abs/1810.04152)</span>

<span class="sd">        Returns:</span>
<span class="sd">          Alpha divergence</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dreg</span><span class="p">:</span>
            <span class="n">w_const</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
                <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span>
            <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_const</span><span class="o">**</span><span class="n">alpha</span>
            <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_alpha</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w_alpha</span><span class="p">)</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">w_alpha</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">w_alpha</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">        Args:</span>
<span class="sd">          x: Batch</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to save model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">        Args:</span>
<span class="sd">          path: Path including filename where to load model from</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>q0</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Base distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>flows</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of flows</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>p</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target distribution</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      q0: Base distribution</span>
<span class="sd">      flows: List of flows</span>
<span class="sd">      p: Target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.forward_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_and_log_det</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms latent variable z to the flow variable x and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution,</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log determinant of the Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms latent variable z to the flow variable x and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch in the latent space</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the space of the target distribution,</span>
<span class="sd">      log determinant of the Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.forward_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward_kld</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Estimates forward KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch sampled from target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of forward KL divergence averaged over batch</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates forward KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch sampled from target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of forward KL divergence averaged over batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.inverse" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.inverse_and_log_det" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse_and_log_det</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Transforms flow variable x to the latent variable z and
computes log determinant of the Jacobian</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the space of the target distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch in the latent space, log determinant of the</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Jacobian</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inverse_and_log_det</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms flow variable x to the latent variable z and</span>
<span class="sd">    computes log determinant of the Jacobian</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch in the space of the target distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">      Batch in the latent space, log determinant of the</span>
<span class="sd">      Jacobian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">log_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">+=</span> <span class="n">log_d</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Load model from state dict</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to load model from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model from state dict</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to load model from</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Get log probability for batch</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get log probability for batch</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Batch</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.reverse_alpha_div" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reverse_alpha_div</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dreg</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Alpha divergence when sampling from q</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dreg</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to use Double Reparametrized Gradient estimator, see <a href="https://arxiv.org/abs/1810.04152">arXiv 1810.04152</a></p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Alpha divergence</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reverse_alpha_div</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dreg</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Alpha divergence when sampling from q</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>
<span class="sd">      dreg: Flag whether to use Double Reparametrized Gradient estimator, see [arXiv 1810.04152](https://arxiv.org/abs/1810.04152)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Alpha divergence</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dreg</span><span class="p">:</span>
        <span class="n">w_const</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">)</span>
        <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_const</span><span class="o">**</span><span class="n">alpha</span>
        <span class="n">w_alpha</span> <span class="o">=</span> <span class="n">w_alpha</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w_alpha</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">w_alpha</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">w_alpha</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">log_p</span> <span class="o">-</span> <span class="n">log_q</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.reverse_kld" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reverse_kld</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Estimates reverse KL divergence, see <a href="https://arxiv.org/abs/1912.02762">arXiv 1912.02762</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw from base distribution</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>beta</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Annealing parameter, see <a href="https://arxiv.org/abs/1505.05770">arXiv 1505.05770</a></p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>score_fn</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to include score function in gradient, see <a href="https://arxiv.org/abs/1703.09194">arXiv 1703.09194</a></p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimate of the reverse KL divergence averaged over latent samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reverse_kld</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">score_fn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates reverse KL divergence, see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw from base distribution</span>
<span class="sd">      beta: Annealing parameter, see [arXiv 1505.05770](https://arxiv.org/abs/1505.05770)</span>
<span class="sd">      score_fn: Flag whether to include score function in gradient, see [arXiv 1703.09194](https://arxiv.org/abs/1703.09194)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Estimate of the reverse KL divergence averaged over latent samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_q_</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_q_</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">score_fn</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z_</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_q</span><span class="p">)</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_p</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Samples from flow-based approximate distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from flow-based approximate distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlow.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Save state dict of model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path including filename where to save model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save state dict of model</span>

<span class="sd">    Args:</span>
<span class="sd">      path: Path including filename where to save model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="normflows.core.NormalizingFlowVAE" class="doc doc-heading">
            <code>NormalizingFlowVAE</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>VAE using normalizing flows to express approximate distribution</p>

              <details class="quote">
                <summary>Source code in <code>normflows/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NormalizingFlowVAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    VAE using normalizing flows to express approximate distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">q0</span><span class="o">=</span><span class="n">distributions</span><span class="o">.</span><span class="n">Dirac</span><span class="p">(),</span> <span class="n">flows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor of normalizing flow model</span>

<span class="sd">        Args:</span>
<span class="sd">          prior: Prior distribution of te VAE, i.e. Gaussian</span>
<span class="sd">          decoder: Optional decoder</span>
<span class="sd">          flows: Flows to transform output of base encoder</span>
<span class="sd">          q0: Base Encoder</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">prior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Takes data batch, samples num_samples for each data point from base distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          x: data batch</span>
<span class="sd">          num_samples: number of samples to draw for each data point</span>

<span class="sd">        Returns:</span>
<span class="sd">          latent variables for each batch and sample, log_q, and log_p</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="c1"># Flatten batch and sample dim</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_p</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
        <span class="c1"># Separate batch and sample dimension again</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_p</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_p</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span><span class="p">,</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlowVAE.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">q0</span><span class="o">=</span><span class="n">distributions</span><span class="o">.</span><span class="n">Dirac</span><span class="p">(),</span> <span class="n">flows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Constructor of normalizing flow model</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prior</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prior distribution of te VAE, i.e. Gaussian</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional decoder</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>flows</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flows to transform output of base encoder</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>q0</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Base Encoder</p>
              </div>
            </td>
            <td>
                  <code><span title="normflows.distributions.Dirac">Dirac</span>()</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">q0</span><span class="o">=</span><span class="n">distributions</span><span class="o">.</span><span class="n">Dirac</span><span class="p">(),</span> <span class="n">flows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor of normalizing flow model</span>

<span class="sd">    Args:</span>
<span class="sd">      prior: Prior distribution of te VAE, i.e. Gaussian</span>
<span class="sd">      decoder: Optional decoder</span>
<span class="sd">      flows: Flows to transform output of base encoder</span>
<span class="sd">      q0: Base Encoder</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">prior</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">q0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.core.NormalizingFlowVAE.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Takes data batch, samples num_samples for each data point from base distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>data batch</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of samples to draw for each data point</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>latent variables for each batch and sample, log_q, and log_p</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Takes data batch, samples num_samples for each data point from base distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      x: data batch</span>
<span class="sd">      num_samples: number of samples to draw for each data point</span>

<span class="sd">    Returns:</span>
<span class="sd">      latent variables for each batch and sample, log_q, and log_p</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="c1"># Flatten batch and sample dim</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log_det</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">log_p</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
    <span class="c1"># Separate batch and sample dimension again</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="n">log_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_q</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_p</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">log_p</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span><span class="p">,</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="normflows.distributions" class="doc doc-heading">
            <code>distributions</code>


</h2>

    <div class="doc doc-contents ">



  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.base" class="doc doc-heading">
            <code>base</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.AffineGaussian" class="doc doc-heading">
            <code>AffineGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Diagonal Gaussian an affine constant transformation applied to it,
can be class conditional or not</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AffineGaussian</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Diagonal Gaussian an affine constant transformation applied to it,</span>
<span class="sd">    can be class conditional or not</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">affine_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Shape of the variables</span>
<span class="sd">          affine_shape: Shape of the parameters in the affine transformation</span>
<span class="sd">          num_classes: Number of classes if the base is class conditional, None otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">affine_shape</span> <span class="o">=</span> <span class="n">affine_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">num_classes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="c1"># Affine transformation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">CCAffineConst</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">affine_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">AffineConstFlow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">affine_shape</span><span class="p">)</span>
        <span class="c1"># Temperature parameter for annealed sampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_samples</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">y_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="n">y_onehot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y_onehot</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="c1"># Sample</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="c1"># Get log prob</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">log_scale</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># Apply transform</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">-=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Perpare onehot encoding of class if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">y_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">y_onehot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y_onehot</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="c1"># Get log prob</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">log_p</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">log_scale</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.AffineGaussian.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">affine_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape of the variables</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>affine_shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape of the parameters in the affine transformation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_classes</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of classes if the base is class conditional, None otherwise</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">affine_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Shape of the variables</span>
<span class="sd">      affine_shape: Shape of the parameters in the affine transformation</span>
<span class="sd">      num_classes: Number of classes if the base is class conditional, None otherwise</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">affine_shape</span> <span class="o">=</span> <span class="n">affine_shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">num_classes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="c1"># Affine transformation</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">CCAffineConst</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">affine_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">AffineConstFlow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">affine_shape</span><span class="p">)</span>
    <span class="c1"># Temperature parameter for annealed sampling</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.BaseDistribution" class="doc doc-heading">
            <code>BaseDistribution</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Base distribution of a flow-based model
Parameters do not depend of target variable (as is the case for a VAE encoder)</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BaseDistribution</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base distribution of a flow-based model</span>
<span class="sd">    Parameters do not depend of target variable (as is the case for a VAE encoder)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from base distribution and calculates log probability</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw from the distriubtion</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples drawn from the distribution, log probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate log probability of batch of samples</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Batch of random variables to determine log probability for</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability for each batch element</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples from base distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw from the distriubtion</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples drawn from the distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.BaseDistribution.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Samples from base distribution and calculates log probability</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw from the distriubtion</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples drawn from the distribution, log probability</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from base distribution and calculates log probability</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw from the distriubtion</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples drawn from the distribution, log probability</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.BaseDistribution.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Calculate log probability of batch of samples</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of random variables to determine log probability for</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability for each batch element</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate log probability of batch of samples</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Batch of random variables to determine log probability for</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability for each batch element</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.BaseDistribution.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Samples from base distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw from the distriubtion</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples drawn from the distribution</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Samples from base distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw from the distriubtion</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples drawn from the distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.ClassCondDiagGaussian" class="doc doc-heading">
            <code>ClassCondDiagGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Class conditional multivariate Gaussian distribution with diagonal covariance matrix</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ClassCondDiagGaussian</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class conditional multivariate Gaussian distribution with diagonal covariance matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">          num_classes: Number of classes to condition on</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Temperature parameter for annealed sampling</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_samples</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">y_onehot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y_onehot</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">perm</span><span class="p">)</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">perm</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_scale</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">loc</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">log_scale</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">y_onehot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y_onehot</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">perm</span><span class="p">)</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">perm</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_scale</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">log_scale</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.ClassCondDiagGaussian.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple with shape of data, if int shape has one dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_classes</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of classes to condition on</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">      num_classes: Number of classes to condition on</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Temperature parameter for annealed sampling</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.ConditionalDiagGaussian" class="doc doc-heading">
            <code>ConditionalDiagGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Conditional multivariate Gaussian distribution with diagonal
covariance matrix, parameters are obtained by a context encoder,
context meaning the variable to condition on</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ConditionalDiagGaussian</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Conditional multivariate Gaussian distribution with diagonal</span>
<span class="sd">    covariance matrix, parameters are obtained by a context encoder,</span>
<span class="sd">    context meaning the variable to condition on</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">context_encoder</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">          context_encoder: Computes mean and log of the standard deviation</span>
<span class="sd">          of the Gaussian, mean is the first half of the last dimension</span>
<span class="sd">          of the encoder output, log of the standard deviation the second</span>
<span class="sd">          half</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_encoder</span> <span class="o">=</span> <span class="n">context_encoder</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">encoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_encoder</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
        <span class="n">split_ind</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">split_ind</span><span class="p">]</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">split_ind</span><span class="p">:]</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mean</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">mean</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">log_scale</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">encoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_encoder</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
        <span class="n">split_ind</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">split_ind</span><span class="p">]</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">split_ind</span><span class="p">:]</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">log_scale</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.ConditionalDiagGaussian.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">context_encoder</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple with shape of data, if int shape has one dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context_encoder</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computes mean and log of the standard deviation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">context_encoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">      context_encoder: Computes mean and log of the standard deviation</span>
<span class="sd">      of the Gaussian, mean is the first half of the last dimension</span>
<span class="sd">      of the encoder output, log of the standard deviation the second</span>
<span class="sd">      half</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">context_encoder</span> <span class="o">=</span> <span class="n">context_encoder</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.DiagGaussian" class="doc doc-heading">
            <code>DiagGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Multivariate Gaussian distribution with diagonal covariance matrix</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DiagGaussian</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multivariate Gaussian distribution with diagonal covariance matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">          trainable: Flag whether to use trainable or fixed parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;log_scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Temperature parameter for annealed sampling</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">log_scale</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">log_scale</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.DiagGaussian.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple with shape of data, if int shape has one dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>trainable</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to use trainable or fixed parameters</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">      trainable: Flag whether to use trainable or fixed parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;log_scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Temperature parameter for annealed sampling</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.GaussianMixture" class="doc doc-heading">
            <code>GaussianMixture</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Mixture of Gaussians with diagonal covariance matrix</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">GaussianMixture</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mixture of Gaussians with diagonal covariance matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n_modes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          n_modes: Number of modes of the mixture model</span>
<span class="sd">          dim: Number of dimensions of each Gaussian</span>
<span class="sd">          loc: List of mean values</span>
<span class="sd">          scale: List of diagonals of the covariance matrices</span>
<span class="sd">          weights: List of mode probabilities</span>
<span class="sd">          trainable: Flag, if true parameters will be optimized during training</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="n">n_modes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

        <span class="k">if</span> <span class="n">loc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loc</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scale</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="n">weights</span> <span class="o">/=</span> <span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">loc</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_scores</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">loc</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;log_scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;weight_scores&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Get weights</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_scores</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Sample mode indices</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">mode_1h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">)</span>
        <span class="n">mode_1h</span> <span class="o">=</span> <span class="n">mode_1h</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="c1"># Get samples</span>
        <span class="n">eps_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">scale_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span><span class="p">)</span> <span class="o">*</span> <span class="n">mode_1h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">loc_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">*</span> <span class="n">mode_1h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">eps_</span> <span class="o">*</span> <span class="n">scale_sample</span> <span class="o">+</span> <span class="n">loc_sample</span>

        <span class="c1"># Compute log probability</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">log_p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># Get weights</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_scores</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute log probability</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">log_p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.GaussianMixture.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">n_modes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>n_modes</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of modes of the mixture model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dim</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of dimensions of each Gaussian</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>loc</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of mean values</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of diagonals of the covariance matrices</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of mode probabilities</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>trainable</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, if true parameters will be optimized during training</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">n_modes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      n_modes: Number of modes of the mixture model</span>
<span class="sd">      dim: Number of dimensions of each Gaussian</span>
<span class="sd">      loc: List of mean values</span>
<span class="sd">      scale: List of diagonals of the covariance matrices</span>
<span class="sd">      weights: List of mode probabilities</span>
<span class="sd">      trainable: Flag, if true parameters will be optimized during training</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="n">n_modes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">if</span> <span class="n">loc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loc</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scale</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    <span class="n">weights</span> <span class="o">/=</span> <span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">loc</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_scores</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">loc</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;log_scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;weight_scores&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.GaussianPCA" class="doc doc-heading">
            <code>GaussianPCA</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Gaussian distribution resulting from linearly mapping a normal distributed latent
variable describing the "content of the target"</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">GaussianPCA</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gaussian distribution resulting from linearly mapping a normal distributed latent</span>
<span class="sd">    variable describing the &quot;content of the target&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          dim: Number of dimensions of the flow variables</span>
<span class="sd">          latent_dim: Number of dimensions of the latent &quot;content&quot; variable;</span>
<span class="sd">                           if None it is set equal to dim</span>
<span class="sd">          sigma: Noise level</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="k">if</span> <span class="n">latent_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_sigma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>

        <span class="n">Sig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_sigma</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">Sig</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">z_</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">Sig</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>

        <span class="n">Sig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_sigma</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">Sig</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">z_</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">Sig</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.GaussianPCA.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>dim</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of dimensions of the flow variables</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latent_dim</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of dimensions of the latent "content" variable;
               if None it is set equal to dim</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>sigma</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Noise level</p>
              </div>
            </td>
            <td>
                  <code>0.1</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      dim: Number of dimensions of the flow variables</span>
<span class="sd">      latent_dim: Number of dimensions of the latent &quot;content&quot; variable;</span>
<span class="sd">                       if None it is set equal to dim</span>
<span class="sd">      sigma: Noise level</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
    <span class="k">if</span> <span class="n">latent_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">dim</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_sigma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.GlowBase" class="doc doc-heading">
            <code>GlowBase</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Base distribution of the Glow model, i.e. Diagonal Gaussian with one mean and
log scale for each channel</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">GlowBase</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base distribution of the Glow model, i.e. Diagonal Gaussian with one mean and</span>
<span class="sd">    log scale for each channel</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">logscale_factor</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Shape of the variables</span>
<span class="sd">          num_classes: Number of classes if the base is class conditional, None otherwise</span>
<span class="sd">          logscale_factor: Scaling factor for mean and log variance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Save shape and related statistics</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_pix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">num_classes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logscale_factor</span> <span class="o">=</span> <span class="n">logscale_factor</span>
        <span class="c1"># Set up parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc_logs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_logs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="p">)</span>
        <span class="c1"># Class conditional parameter if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loc_cc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_cc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="c1"># Temperature parameter for annealed sampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Prepare parameter</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc_logs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">logscale_factor</span><span class="p">)</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_logs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">logscale_factor</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_samples</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">y_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">y_onehot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y_onehot</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">log_scale</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">log_scale</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
        <span class="c1"># Sample</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">loc</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="c1"># Get log prob</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_pix</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_scale</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Perpare parameter</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc_logs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">logscale_factor</span><span class="p">)</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_logs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">logscale_factor</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">y_onehot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">y_onehot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y_onehot</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">log_scale</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_scale</span> <span class="o">=</span> <span class="n">log_scale</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
        <span class="c1"># Get log prob</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_pix</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_scale</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span>
            <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.GlowBase.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">logscale_factor</span><span class="o">=</span><span class="mf">3.0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape of the variables</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_classes</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of classes if the base is class conditional, None otherwise</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>logscale_factor</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scaling factor for mean and log variance</p>
              </div>
            </td>
            <td>
                  <code>3.0</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">logscale_factor</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Shape of the variables</span>
<span class="sd">      num_classes: Number of classes if the base is class conditional, None otherwise</span>
<span class="sd">      logscale_factor: Scaling factor for mean and log variance</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># Save shape and related statistics</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_pix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span> <span class="o">=</span> <span class="n">num_classes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logscale_factor</span> <span class="o">=</span> <span class="n">logscale_factor</span>
    <span class="c1"># Set up parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc_logs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_logs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="p">)</span>
    <span class="c1"># Class conditional parameter if needed</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_cond</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc_cc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_scale_cc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="p">)</span>
    <span class="c1"># Temperature parameter for annealed sampling</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.Uniform" class="doc doc-heading">
            <code>Uniform</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Multivariate uniform distribution</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Uniform</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multivariate uniform distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">          low: Lower bound of uniform distribution</span>
<span class="sd">          high: Upper bound of uniform distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">low</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">high</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_prob_val</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_prob_val</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_prob_val</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">z</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="n">z</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="n">ind_inf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out_range</span><span class="p">,</span> <span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_p</span><span class="p">[</span><span class="n">ind_inf</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.Uniform.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple with shape of data, if int shape has one dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>low</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lower bound of uniform distribution</p>
              </div>
            </td>
            <td>
                  <code>-1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>high</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Upper bound of uniform distribution</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Tuple with shape of data, if int shape has one dimension</span>
<span class="sd">      low: Lower bound of uniform distribution</span>
<span class="sd">      high: Upper bound of uniform distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">low</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">high</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_prob_val</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.base.UniformGaussian" class="doc doc-heading">
            <code>UniformGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.base.BaseDistribution" href="#normflows.distributions.base.BaseDistribution">BaseDistribution</a></code></p>


      <p>Distribution of a 1D random variable with some entries having a uniform and
others a Gaussian distribution</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">UniformGaussian</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Distribution of a 1D random variable with some entries having a uniform and</span>
<span class="sd">    others a Gaussian distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          ndim: Int, number of dimensions</span>
<span class="sd">          ind: Iterable, indices of uniformly distributed entries</span>
<span class="sd">          scale: Iterable, standard deviation of Gaussian or width of uniform distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="p">[</span><span class="n">ind</span><span class="p">]</span>

        <span class="c1"># Set up indices and permutations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_cast_Long</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

        <span class="n">ind_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">:</span>
                <span class="n">ind_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind_&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

        <span class="n">perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">))</span>
        <span class="n">inv_perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">perm_</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
            <span class="n">inv_perm_</span><span class="p">[</span><span class="n">perm_</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">i</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;inv_perm&quot;</span><span class="p">,</span> <span class="n">inv_perm_</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">eps_u</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
                <span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">)),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span>
        <span class="p">)</span>
        <span class="n">eps_g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">)),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">eps_u</span><span class="p">,</span> <span class="n">eps_g</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_perm</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">log_p_u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]),</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">log_p_g</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">])</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_p_u</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_p_g</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.base.UniformGaussian.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>ndim</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Int, number of dimensions</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ind</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Iterable, indices of uniformly distributed entries</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Iterable, standard deviation of Gaussian or width of uniform distribution</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      ndim: Int, number of dimensions</span>
<span class="sd">      ind: Iterable, indices of uniformly distributed entries</span>
<span class="sd">      scale: Iterable, standard deviation of Gaussian or width of uniform distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="c1"># Set up indices and permutations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_cast_Long</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

    <span class="n">ind_</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">:</span>
            <span class="n">ind_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind_&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

    <span class="n">perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">))</span>
    <span class="n">inv_perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">perm_</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">inv_perm_</span><span class="p">[</span><span class="n">perm_</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;inv_perm&quot;</span><span class="p">,</span> <span class="n">inv_perm_</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.decoder" class="doc doc-heading">
            <code>decoder</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.decoder.BaseDecoder" class="doc doc-heading">
            <code>BaseDecoder</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/decoder.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BaseDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Decodes z to x</span>

<span class="sd">        Args:</span>
<span class="sd">          z: latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          x, std of x</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Log probability</span>

<span class="sd">        Args:</span>
<span class="sd">          x: observable</span>
<span class="sd">          z: latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log(p) of x given z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.decoder.BaseDecoder.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Decodes z to x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>x, std of x</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/decoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decodes z to x</span>

<span class="sd">    Args:</span>
<span class="sd">      z: latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      x, std of x</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.decoder.BaseDecoder.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Log probability</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>observable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log(p) of x given z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/decoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log probability</span>

<span class="sd">    Args:</span>
<span class="sd">      x: observable</span>
<span class="sd">      z: latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log(p) of x given z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.decoder.NNBernoulliDecoder" class="doc doc-heading">
            <code>NNBernoulliDecoder</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.decoder.BaseDecoder" href="#normflows.distributions.decoder.BaseDecoder">BaseDecoder</a></code></p>


      <p>BaseDecoder representing a Bernoulli distribution with mean parametrized by a NN</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/decoder.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NNBernoulliDecoder</span><span class="p">(</span><span class="n">BaseDecoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BaseDecoder representing a Bernoulli distribution with mean parametrized by a NN</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          net: neural network parametrizing mean Bernoulli (mean = sigmoid(nn_out)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">mean</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]</span>
            <span class="p">)</span>
        <span class="n">log_sig</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)))</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">x</span> <span class="o">*</span> <span class="n">log_sig</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">log_sig</span><span class="p">(</span><span class="o">-</span><span class="n">score</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.decoder.NNBernoulliDecoder.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">net</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>net</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>neural network parametrizing mean Bernoulli (mean = sigmoid(nn_out)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/decoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      net: neural network parametrizing mean Bernoulli (mean = sigmoid(nn_out)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.decoder.NNDiagGaussianDecoder" class="doc doc-heading">
            <code>NNDiagGaussianDecoder</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.decoder.BaseDecoder" href="#normflows.distributions.decoder.BaseDecoder">BaseDecoder</a></code></p>


      <p>BaseDecoder representing a diagonal Gaussian distribution with mean and std parametrized by a NN</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/decoder.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NNDiagGaussianDecoder</span><span class="p">(</span><span class="n">BaseDecoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BaseDecoder representing a diagonal Gaussian distribution with mean and std parametrized by a NN</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          net: neural network parametrizing mean and standard deviation of diagonal Gaussian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">mean_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">mean_std</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_hidden</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="n">n_hidden</span><span class="p">:,</span> <span class="o">...</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">mean_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">mean_std</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_hidden</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mean_std</span><span class="p">[:,</span> <span class="n">n_hidden</span><span class="p">:,</span> <span class="o">...</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]</span>
            <span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
        <span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">var</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.decoder.NNDiagGaussianDecoder.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">net</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>net</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>neural network parametrizing mean and standard deviation of diagonal Gaussian</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/decoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      net: neural network parametrizing mean and standard deviation of diagonal Gaussian</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.distribution_test" class="doc doc-heading">
            <code>distribution_test</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.distribution_test.DistributionTest" class="doc doc-heading">
            <code>DistributionTest</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="unittest.TestCase">TestCase</span></code></p>


      <p>Generic test case for distribution modules</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/distribution_test.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DistributionTest</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generic test case for distribution modules</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">assertClose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">assert_close</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">checkForward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Do forward</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">log_p</span> <span class="o">=</span> <span class="n">distribution</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># Check type</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">log_p</span><span class="o">.</span><span class="n">dtype</span>
        <span class="c1"># Check shape</span>
        <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_samples</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_samples</span>
        <span class="c1"># Check dim</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">log_p</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="c1"># Return results</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">checkLogProb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Compute log prob</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># Check type</span>
        <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span>
        <span class="c1"># Check shape</span>
        <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Return results</span>
        <span class="k">return</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">checkSample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Do forward</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># Check shape</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_samples</span>
        <span class="c1"># Check dim</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="c1"># Return results</span>
        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">checkForwardLogProb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Check forward</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkForward</span><span class="p">(</span><span class="n">distribution</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># Check log prob</span>
        <span class="n">log_p_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkLogProb</span><span class="p">(</span><span class="n">distribution</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># Check consistency</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertClose</span><span class="p">(</span><span class="n">log_p_</span><span class="p">,</span> <span class="n">log_p</span><span class="p">,</span> <span class="n">atol</span><span class="p">,</span> <span class="n">rtol</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.encoder" class="doc doc-heading">
            <code>encoder</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.encoder.BaseEncoder" class="doc doc-heading">
            <code>BaseEncoder</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Base distribution of a flow-based variational autoencoder
Parameters of the distribution depend of the target variable x</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BaseEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base distribution of a flow-based variational autoencoder</span>
<span class="sd">    Parameters of the distribution depend of the target variable x</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          x: Variable to condition on, first dimension is batch size</span>
<span class="sd">          num_samples: number of samples to draw per element of mini-batch</span>

<span class="sd">        Returns</span>
<span class="sd">          sample of z for x, log probability for sample</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Primary random variable, first dimension is batch size</span>
<span class="sd">          x: Variable to condition on, first dimension is batch size</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of z given x</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.BaseEncoder.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable to condition on, first dimension is batch size</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of samples to draw per element of mini-batch</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>
      <p>Returns
  sample of z for x, log probability for sample</p>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      x: Variable to condition on, first dimension is batch size</span>
<span class="sd">      num_samples: number of samples to draw per element of mini-batch</span>

<span class="sd">    Returns</span>
<span class="sd">      sample of z for x, log probability for sample</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.BaseEncoder.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Primary random variable, first dimension is batch size</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable to condition on, first dimension is batch size</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of z given x</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Primary random variable, first dimension is batch size</span>
<span class="sd">      x: Variable to condition on, first dimension is batch size</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of z given x</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.encoder.ConstDiagGaussian" class="doc doc-heading">
            <code>ConstDiagGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.encoder.BaseEncoder" href="#normflows.distributions.encoder.BaseEncoder">BaseEncoder</a></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ConstDiagGaussian</span><span class="p">(</span><span class="n">BaseEncoder</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Multivariate Gaussian distribution with diagonal covariance and parameters being constant wrt x</span>

<span class="sd">        Args:</span>
<span class="sd">          loc: mean vector of the distribution</span>
<span class="sd">          scale: vector of the standard deviations on the diagonal of the covariance matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">loc</span><span class="p">):</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">):</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">loc</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          x: Variable to condition on, will only be used to determine the batch size</span>
<span class="sd">          num_samples: number of samples to draw per element of mini-batch</span>

<span class="sd">        Returns:</span>
<span class="sd">          sample of z for x, log probability for sample</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z: Primary random variable, first dimension is batch dimension</span>
<span class="sd">          x: Variable to condition on, first dimension is batch dimension</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of z given x</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.ConstDiagGaussian.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Multivariate Gaussian distribution with diagonal covariance and parameters being constant wrt x</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>loc</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>mean vector of the distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>vector of the standard deviations on the diagonal of the covariance matrix</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multivariate Gaussian distribution with diagonal covariance and parameters being constant wrt x</span>

<span class="sd">    Args:</span>
<span class="sd">      loc: mean vector of the distribution</span>
<span class="sd">      scale: vector of the standard deviations on the diagonal of the covariance matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">loc</span><span class="p">):</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">):</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">loc</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.ConstDiagGaussian.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable to condition on, will only be used to determine the batch size</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of samples to draw per element of mini-batch</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>sample of z for x, log probability for sample</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      x: Variable to condition on, will only be used to determine the batch size</span>
<span class="sd">      num_samples: number of samples to draw per element of mini-batch</span>

<span class="sd">    Returns:</span>
<span class="sd">      sample of z for x, log probability for sample</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">eps</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.ConstDiagGaussian.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Primary random variable, first dimension is batch dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable to condition on, first dimension is batch dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of z given x</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z: Primary random variable, first dimension is batch dimension</span>
<span class="sd">      x: Variable to condition on, first dimension is batch dimension</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of z given x</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.encoder.NNDiagGaussian" class="doc doc-heading">
            <code>NNDiagGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.encoder.BaseEncoder" href="#normflows.distributions.encoder.BaseEncoder">BaseEncoder</a></code></p>


      <p>Diagonal Gaussian distribution with mean and variance determined by a neural network</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NNDiagGaussian</span><span class="p">(</span><span class="n">BaseEncoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Diagonal Gaussian distribution with mean and variance determined by a neural network</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construtor</span>

<span class="sd">        Args:</span>
<span class="sd">          net: net computing mean (first n / 2 outputs), standard deviation (second n / 2 outputs)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          x: Variable to condition on</span>
<span class="sd">          num_samples: number of samples to draw per element of mini-batch</span>

<span class="sd">        Returns:</span>
<span class="sd">          sample of z for x, log probability for sample</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mean_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">mean_std</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_hidden</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="n">n_hidden</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_hidden</span><span class="p">),</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">std</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
        <span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Primary random variable, first dimension is batch dimension</span>
<span class="sd">          x: Variable to condition on, first dimension is batch dimension</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of z given x</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">mean_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">mean_std</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_hidden</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mean_std</span><span class="p">[:,</span> <span class="n">n_hidden</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_hidden</span><span class="p">),</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
        <span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">var</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.NNDiagGaussian.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">net</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Construtor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>net</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>net computing mean (first n / 2 outputs), standard deviation (second n / 2 outputs)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Construtor</span>

<span class="sd">    Args:</span>
<span class="sd">      net: net computing mean (first n / 2 outputs), standard deviation (second n / 2 outputs)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.NNDiagGaussian.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable to condition on</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of samples to draw per element of mini-batch</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>sample of z for x, log probability for sample</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      x: Variable to condition on</span>
<span class="sd">      num_samples: number of samples to draw per element of mini-batch</span>

<span class="sd">    Returns:</span>
<span class="sd">      sample of z for x, log probability for sample</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">mean_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">mean_std</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_hidden</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="n">n_hidden</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_hidden</span><span class="p">),</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
        <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">std</span> <span class="o">*</span> <span class="n">eps</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
        <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
    <span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.encoder.NNDiagGaussian.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Primary random variable, first dimension is batch dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable to condition on, first dimension is batch dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of z given x</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Primary random variable, first dimension is batch dimension</span>
<span class="sd">      x: Variable to condition on, first dimension is batch dimension</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of z given x</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">mean_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">mean_std</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_std</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_hidden</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mean_std</span><span class="p">[:,</span> <span class="n">n_hidden</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_hidden</span><span class="p">),</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
        <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
    <span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">var</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_q</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.linear_interpolation" class="doc doc-heading">
            <code>linear_interpolation</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.linear_interpolation.LinearInterpolation" class="doc doc-heading">
            <code>LinearInterpolation</code>


</h4>


    <div class="doc doc-contents ">


      <p>Linear interpolation of two distributions in the log space</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/linear_interpolation.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LinearInterpolation</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear interpolation of two distributions in the log space</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Interpolation parameter alpha:</span>

<span class="sd">        ```</span>
<span class="sd">        log_p = alpha * log_p_1 + (1 - alpha) * log_p_2</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          dist1: First distribution</span>
<span class="sd">          dist2: Second distribution</span>
<span class="sd">          alpha: Interpolation parameter</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist1</span> <span class="o">=</span> <span class="n">dist1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist2</span> <span class="o">=</span> <span class="n">dist2</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist1</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span>
            <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist2</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.linear_interpolation.LinearInterpolation.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>
<p>Interpolation parameter alpha:</p>
<pre><code>log_p = alpha * log_p_1 + (1 - alpha) * log_p_2
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>dist1</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>First distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dist2</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Second distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>alpha</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Interpolation parameter</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/linear_interpolation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Interpolation parameter alpha:</span>

<span class="sd">    ```</span>
<span class="sd">    log_p = alpha * log_p_1 + (1 - alpha) * log_p_2</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      dist1: First distribution</span>
<span class="sd">      dist2: Second distribution</span>
<span class="sd">      alpha: Interpolation parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dist1</span> <span class="o">=</span> <span class="n">dist1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dist2</span> <span class="o">=</span> <span class="n">dist2</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.mh_proposal" class="doc doc-heading">
            <code>mh_proposal</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.mh_proposal.DiagGaussianProposal" class="doc doc-heading">
            <code>DiagGaussianProposal</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.mh_proposal.MHProposal" href="#normflows.distributions.mh_proposal.MHProposal">MHProposal</a></code></p>


      <p>Diagonal Gaussian distribution with previous value as mean
as a proposal for Metropolis Hastings algorithm</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/mh_proposal.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DiagGaussianProposal</span><span class="p">(</span><span class="n">MHProposal</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Diagonal Gaussian distribution with previous value as mean</span>
<span class="sd">    as a proposal for Metropolis Hastings algorithm</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Shape of variables to sample</span>
<span class="sd">          scale: Standard deviation of distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">eps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">+</span> <span class="n">z</span>
        <span class="k">return</span> <span class="n">z_</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">((</span><span class="n">z_</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">())),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">eps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">+</span> <span class="n">z</span>
        <span class="n">log_p_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_p_diff</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.mh_proposal.DiagGaussianProposal.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape of variables to sample</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Standard deviation of distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/mh_proposal.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Shape of variables to sample</span>
<span class="sd">      scale: Standard deviation of distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.mh_proposal.MHProposal" class="doc doc-heading">
            <code>MHProposal</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Proposal distribution for the Metropolis Hastings algorithm</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/mh_proposal.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MHProposal</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Proposal distribution for the Metropolis Hastings algorithm</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sample new value based on previous z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z_: Potential new sample</span>
<span class="sd">          z: Previous sample</span>

<span class="sd">        Returns:</span>
<span class="sd">          Log probability of proposal distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Draw samples given z and compute log probability difference</span>

<span class="sd">        ```</span>
<span class="sd">        log(p(z | z_new)) - log(p(z_new | z))</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          z: Previous samples</span>

<span class="sd">        Returns:</span>
<span class="sd">          Proposal, difference of log probability ratio</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.mh_proposal.MHProposal.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Draw samples given z and compute log probability difference</p>
<pre><code>log(p(z | z_new)) - log(p(z_new | z))
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Previous samples</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Proposal, difference of log probability ratio</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/mh_proposal.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Draw samples given z and compute log probability difference</span>

<span class="sd">    ```</span>
<span class="sd">    log(p(z | z_new)) - log(p(z_new | z))</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      z: Previous samples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Proposal, difference of log probability ratio</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.mh_proposal.MHProposal.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z_</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Potential new sample</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Previous sample</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Log probability of proposal distribution</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/mh_proposal.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z_: Potential new sample</span>
<span class="sd">      z: Previous sample</span>

<span class="sd">    Returns:</span>
<span class="sd">      Log probability of proposal distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.mh_proposal.MHProposal.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Sample new value based on previous z</p>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/mh_proposal.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample new value based on previous z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.prior" class="doc doc-heading">
            <code>prior</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.prior.ImagePrior" class="doc doc-heading">
            <code>ImagePrior</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Intensities of an image determine probability density of prior</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ImagePrior</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Intensities of an image determine probability density of prior</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">x_range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">y_range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          image: image as np matrix</span>
<span class="sd">          x_range: x range to position image at</span>
<span class="sd">          y_range: y range to position image at</span>
<span class="sd">          eps: small value to add to image to avoid log(0) problems</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">image_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">+</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image_</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">image_</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size_cpu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_range</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;image_size&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size_cpu</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;scale&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">x_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;shift&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]]])</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">density</span><span class="p">[</span><span class="n">ind</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ind</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">rejection_sampling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform rejection sampling on image distribution</span>

<span class="sd">        Args:</span>
<span class="sd">         num_steps: Number of rejection sampling steps to perform</span>

<span class="sd">        Returns:</span>
<span class="sd">          Accepted samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">intensity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="p">[</span><span class="n">ind</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ind</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
        <span class="n">accept</span> <span class="o">=</span> <span class="n">intensity</span> <span class="o">&gt;</span> <span class="n">prob</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span><span class="p">[</span><span class="n">accept</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample from image distribution through rejection sampling</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_samples</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rejection_sampling</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">num_samples</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)])</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">[:</span><span class="n">ind</span><span class="p">,</span> <span class="p">:]],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.ImagePrior.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">x_range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">y_range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>image</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>image as np matrix</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>x_range</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>x range to position image at</p>
              </div>
            </td>
            <td>
                  <code>[-3, 3]</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_range</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>y range to position image at</p>
              </div>
            </td>
            <td>
                  <code>[-3, 3]</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>eps</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>small value to add to image to avoid log(0) problems</p>
              </div>
            </td>
            <td>
                  <code>1e-10</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">x_range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">y_range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      image: image as np matrix</span>
<span class="sd">      x_range: x range to position image at</span>
<span class="sd">      y_range: y range to position image at</span>
<span class="sd">      eps: small value to add to image to avoid log(0) problems</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">image_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">+</span> <span class="n">eps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image_</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">image_</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_size_cpu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_range</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
        <span class="s2">&quot;image_size&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size_cpu</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
        <span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_cpu</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
        <span class="s2">&quot;scale&quot;</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">x_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
        <span class="s2">&quot;shift&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]]])</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.ImagePrior.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">density</span><span class="p">[</span><span class="n">ind</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ind</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.ImagePrior.rejection_sampling" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">rejection_sampling</span><span class="p">(</span><span class="n">num_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Perform rejection sampling on image distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_steps</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of rejection sampling steps to perform</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Accepted samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">rejection_sampling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform rejection sampling on image distribution</span>

<span class="sd">    Args:</span>
<span class="sd">     num_steps: Number of rejection sampling steps to perform</span>

<span class="sd">    Returns:</span>
<span class="sd">      Accepted samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
        <span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
    <span class="n">intensity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="p">[</span><span class="n">ind</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ind</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
    <span class="n">accept</span> <span class="o">=</span> <span class="n">intensity</span> <span class="o">&gt;</span> <span class="n">prob</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span><span class="p">[</span><span class="n">accept</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.ImagePrior.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Sample from image distribution through rejection sampling</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from image distribution through rejection sampling</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_samples</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rejection_sampling</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">num_samples</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)])</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">[:</span><span class="n">ind</span><span class="p">,</span> <span class="p">:]],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.prior.PriorDistribution" class="doc doc-heading">
            <code>PriorDistribution</code>


</h4>


    <div class="doc doc-contents ">


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PriorDistribution</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">         z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.PriorDistribution.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">     z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.prior.Sinusoidal" class="doc doc-heading">
            <code>Sinusoidal</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.prior.PriorDistribution" href="#normflows.distributions.prior.PriorDistribution">PriorDistribution</a></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Sinusoidal</span><span class="p">(</span><span class="n">PriorDistribution</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Distribution 2d with sinusoidal density</span>
<span class="sd">        given by</span>

<span class="sd">        ```</span>
<span class="sd">        w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">        log(p) = - 1/2 * ((z[1] - w_1(z)) / (2 * scale)) ** 2</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          scale: scale of the distribution, see formula</span>
<span class="sd">          period: period of the sinosoidal</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">period</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        ```</span>
<span class="sd">        log(p) = - 1/2 * ((z[1] - w_1(z)) / (2 * scale)) ** 2</span>
<span class="sd">        w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

        <span class="n">w_1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">*</span> <span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w_1</span><span class="p">(</span><span class="n">z_</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">4</span>
        <span class="p">)</span>  <span class="c1"># add Gaussian envelope for valid p(z)</span>

        <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Sinusoidal.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Distribution 2d with sinusoidal density
given by</p>
<pre><code>w_1(z) = sin(2*pi / period * z[0])
log(p) = - 1/2 * ((z[1] - w_1(z)) / (2 * scale)) ** 2
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>scale of the distribution, see formula</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>period</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>period of the sinosoidal</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distribution 2d with sinusoidal density</span>
<span class="sd">    given by</span>

<span class="sd">    ```</span>
<span class="sd">    w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">    log(p) = - 1/2 * ((z[1] - w_1(z)) / (2 * scale)) ** 2</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      scale: scale of the distribution, see formula</span>
<span class="sd">      period: period of the sinosoidal</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">period</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Sinusoidal.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <pre><code>log(p) = - 1/2 * ((z[1] - w_1(z)) / (2 * scale)) ** 2
w_1(z) = sin(2*pi / period * z[0])
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    ```</span>
<span class="sd">    log(p) = - 1/2 * ((z[1] - w_1(z)) / (2 * scale)) ** 2</span>
<span class="sd">    w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

    <span class="n">w_1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">*</span> <span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
        <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w_1</span><span class="p">(</span><span class="n">z_</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">4</span>
    <span class="p">)</span>  <span class="c1"># add Gaussian envelope for valid p(z)</span>

    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.prior.Sinusoidal_gap" class="doc doc-heading">
            <code>Sinusoidal_gap</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.prior.PriorDistribution" href="#normflows.distributions.prior.PriorDistribution">PriorDistribution</a></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Sinusoidal_gap</span><span class="p">(</span><span class="n">PriorDistribution</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Distribution 2d with sinusoidal density with gap</span>
<span class="sd">        given by</span>

<span class="sd">        ```</span>
<span class="sd">        w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">        w_2(z) = 3 * exp(-0.5 * ((z[0] - 1) / 0.6) ** 2)</span>
<span class="sd">        log(p) = -log(exp(-0.5 * ((z[1] - w_1(z)) / 0.35) ** 2) + exp(-0.5 * ((z[1] - w_1(z) + w_2(z)) / 0.35) ** 2))</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          loc: distance of modes from the origin</span>
<span class="sd">          scale: scale of modes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">period</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2_scale</span> <span class="o">=</span> <span class="mf">0.6</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2_amp</span> <span class="o">=</span> <span class="mf">3.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2_mu</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

        <span class="n">w_1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">*</span> <span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">w_2</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2_amp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2_mu</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2_scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="p">)</span>

        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w_2</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w_1</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">+</span> <span class="n">w_2</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">eps</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">4</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Sinusoidal_gap.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Distribution 2d with sinusoidal density with gap
given by</p>
<pre><code>w_1(z) = sin(2*pi / period * z[0])
w_2(z) = 3 * exp(-0.5 * ((z[0] - 1) / 0.6) ** 2)
log(p) = -log(exp(-0.5 * ((z[1] - w_1(z)) / 0.35) ** 2) + exp(-0.5 * ((z[1] - w_1(z) + w_2(z)) / 0.35) ** 2))
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>loc</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>distance of modes from the origin</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>scale of modes</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distribution 2d with sinusoidal density with gap</span>
<span class="sd">    given by</span>

<span class="sd">    ```</span>
<span class="sd">    w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">    w_2(z) = 3 * exp(-0.5 * ((z[0] - 1) / 0.6) ** 2)</span>
<span class="sd">    log(p) = -log(exp(-0.5 * ((z[1] - w_1(z)) / 0.35) ** 2) + exp(-0.5 * ((z[1] - w_1(z) + w_2(z)) / 0.35) ** 2))</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      loc: distance of modes from the origin</span>
<span class="sd">      scale: scale of modes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">period</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2_scale</span> <span class="o">=</span> <span class="mf">0.6</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2_amp</span> <span class="o">=</span> <span class="mf">3.0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2_mu</span> <span class="o">=</span> <span class="mf">1.0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Sinusoidal_gap.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

    <span class="n">w_1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">*</span> <span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">w_2</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2_amp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
        <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2_mu</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2_scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="p">)</span>

    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w_2</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w_1</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">+</span> <span class="n">w_2</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
        <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">eps</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
        <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">4</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.prior.Sinusoidal_split" class="doc doc-heading">
            <code>Sinusoidal_split</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.prior.PriorDistribution" href="#normflows.distributions.prior.PriorDistribution">PriorDistribution</a></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Sinusoidal_split</span><span class="p">(</span><span class="n">PriorDistribution</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Distribution 2d with sinusoidal density with split</span>
<span class="sd">        given by</span>

<span class="sd">        ```</span>
<span class="sd">        w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">        w_3(z) = 3 * sigmoid((z[0] - 1) / 0.3)</span>
<span class="sd">        log(p) = -log(exp(-0.5 * ((z[1] - w_1(z)) / 0.4) ** 2) + exp(-0.5 * ((z[1] - w_1(z) + w_3(z)) / 0.35) ** 2))</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          loc: distance of modes from the origin</span>
<span class="sd">          scale: scale of modes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">period</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w3_scale</span> <span class="o">=</span> <span class="mf">0.3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w3_amp</span> <span class="o">=</span> <span class="mf">3.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w3_mu</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

        <span class="n">w_1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">*</span> <span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">w_3</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3_amp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span>
            <span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3_mu</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3_scale</span>
        <span class="p">)</span>

        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w_3</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w_1</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">+</span> <span class="n">w_3</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">eps</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">4</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Sinusoidal_split.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Distribution 2d with sinusoidal density with split
given by</p>
<pre><code>w_1(z) = sin(2*pi / period * z[0])
w_3(z) = 3 * sigmoid((z[0] - 1) / 0.3)
log(p) = -log(exp(-0.5 * ((z[1] - w_1(z)) / 0.4) ** 2) + exp(-0.5 * ((z[1] - w_1(z) + w_3(z)) / 0.35) ** 2))
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>loc</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>distance of modes from the origin</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>scale of modes</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">period</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distribution 2d with sinusoidal density with split</span>
<span class="sd">    given by</span>

<span class="sd">    ```</span>
<span class="sd">    w_1(z) = sin(2*pi / period * z[0])</span>
<span class="sd">    w_3(z) = 3 * sigmoid((z[0] - 1) / 0.3)</span>
<span class="sd">    log(p) = -log(exp(-0.5 * ((z[1] - w_1(z)) / 0.4) ** 2) + exp(-0.5 * ((z[1] - w_1(z) + w_3(z)) / 0.35) ** 2))</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      loc: distance of modes from the origin</span>
<span class="sd">      scale: scale of modes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">period</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w3_scale</span> <span class="o">=</span> <span class="mf">0.3</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w3_amp</span> <span class="o">=</span> <span class="mf">3.0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w3_mu</span> <span class="o">=</span> <span class="mf">1.0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Sinusoidal_split.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

    <span class="n">w_1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">*</span> <span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">w_3</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3_amp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span>
        <span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3_mu</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3_scale</span>
    <span class="p">)</span>

    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w_3</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w_1</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">+</span> <span class="n">w_3</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
        <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">eps</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
        <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">4</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.prior.Smiley" class="doc doc-heading">
            <code>Smiley</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.prior.PriorDistribution" href="#normflows.distributions.prior.PriorDistribution">PriorDistribution</a></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Smiley</span><span class="p">(</span><span class="n">PriorDistribution</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Distribution 2d of a smiley :)</span>

<span class="sd">        Args:</span>
<span class="sd">          scale: scale of the smiley</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">2.0</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

        <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.8</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Smiley.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Distribution 2d of a smiley :)</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>scale of the smiley</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distribution 2d of a smiley :)</span>

<span class="sd">    Args:</span>
<span class="sd">      scale: scale of the smiley</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">2.0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.Smiley.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span>

    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
        <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.8</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.prior.TwoModes" class="doc doc-heading">
            <code>TwoModes</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.prior.PriorDistribution" href="#normflows.distributions.prior.PriorDistribution">PriorDistribution</a></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TwoModes</span><span class="p">(</span><span class="n">PriorDistribution</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Distribution 2d with two modes</span>

<span class="sd">        Distribution 2d with two modes at</span>
<span class="sd">        ```z[0] = -loc```  and ```z[0] = loc```</span>
<span class="sd">        following the density</span>
<span class="sd">        ```</span>
<span class="sd">        log(p) = 1/2 * ((norm(z) - loc) / (2 * scale)) ** 2</span>
<span class="sd">                - log(exp(-1/2 * ((z[0] - loc) / (3 * scale)) ** 2) + exp(-1/2 * ((z[0] + loc) / (3 * scale)) ** 2))</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          loc: distance of modes from the origin</span>
<span class="sd">          scale: scale of modes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        ```</span>
<span class="sd">        log(p) = 1/2 * ((norm(z) - loc) / (2 * scale)) ** 2</span>
<span class="sd">                - log(exp(-1/2 * ((z[0] - loc) / (3 * scale)) ** 2) + exp(-1/2 * ((z[0] + loc) / (3 * scale)) ** 2))</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">))</span>

        <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.TwoModes.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Distribution 2d with two modes</p>
<p>Distribution 2d with two modes at
<code>z[0] = -loc</code>  and <code>z[0] = loc</code>
following the density</p>
<pre><code>log(p) = 1/2 * ((norm(z) - loc) / (2 * scale)) ** 2
        - log(exp(-1/2 * ((z[0] - loc) / (3 * scale)) ** 2) + exp(-1/2 * ((z[0] + loc) / (3 * scale)) ** 2))
</code></pre>
<p>Args:
  loc: distance of modes from the origin
  scale: scale of modes</p>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distribution 2d with two modes</span>

<span class="sd">    Distribution 2d with two modes at</span>
<span class="sd">    ```z[0] = -loc```  and ```z[0] = loc```</span>
<span class="sd">    following the density</span>
<span class="sd">    ```</span>
<span class="sd">    log(p) = 1/2 * ((norm(z) - loc) / (2 * scale)) ** 2</span>
<span class="sd">            - log(exp(-1/2 * ((z[0] - loc) / (3 * scale)) ** 2) + exp(-1/2 * ((z[0] + loc) / (3 * scale)) ** 2))</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      loc: distance of modes from the origin</span>
<span class="sd">      scale: scale of modes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.prior.TwoModes.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <pre><code>log(p) = 1/2 * ((norm(z) - loc) / (2 * scale)) ** 2
        - log(exp(-1/2 * ((z[0] - loc) / (3 * scale)) ** 2) + exp(-1/2 * ((z[0] + loc) / (3 * scale)) ** 2))
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    ```</span>
<span class="sd">    log(p) = 1/2 * ((norm(z) - loc) / (2 * scale)) ** 2</span>
<span class="sd">            - log(exp(-1/2 * ((z[0] - loc) / (3 * scale)) ** 2) + exp(-1/2 * ((z[0] + loc) / (3 * scale)) ** 2))</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">))</span>

    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
        <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.distributions.target" class="doc doc-heading">
            <code>target</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.target.CircularGaussianMixture" class="doc doc-heading">
            <code>CircularGaussianMixture</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Two-dimensional Gaussian mixture arranged in a circle</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/target.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CircularGaussianMixture</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Two-dimensional Gaussian mixture arranged in a circle</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_modes</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          n_modes: Number of modes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CircularGaussianMixture</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="n">n_modes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">):</span>
            <span class="n">d_</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">*</span> <span class="n">i</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
                <span class="o">+</span> <span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">*</span> <span class="n">i</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">d_</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span>
        <span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">phi</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">2</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
            <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span>
            <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_samples</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">phi</span><span class="p">),</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">phi</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">eps</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">+</span> <span class="n">loc</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.target.CircularGaussianMixture.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">n_modes</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>n_modes</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of modes</p>
              </div>
            </td>
            <td>
                  <code>8</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/target.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_modes</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      n_modes: Number of modes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CircularGaussianMixture</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="n">n_modes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
        <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.target.ConditionalDiagGaussian" class="doc doc-heading">
            <code>ConditionalDiagGaussian</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.target.Target" href="#normflows.distributions.target.Target">Target</a></code></p>


      <p>Gaussian distribution conditioned on its mean and standard
deviation</p>
<p>The first half of the entries of the condition, also called context,
are the mean, while the second half are the standard deviation.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/target.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ConditionalDiagGaussian</span><span class="p">(</span><span class="n">Target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gaussian distribution conditioned on its mean and standard</span>
<span class="sd">    deviation</span>

<span class="sd">    The first half of the entries of the condition, also called context,</span>
<span class="sd">    are the mean, while the second half are the standard deviation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">context</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d</span><span class="p">]</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">context</span><span class="p">[:,</span> <span class="n">d</span><span class="p">:]</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">context</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d</span><span class="p">]</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">context</span><span class="p">[:,</span> <span class="n">d</span><span class="p">:]</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">loc</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.target.RingMixture" class="doc doc-heading">
            <code>RingMixture</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.target.Target" href="#normflows.distributions.target.Target">Target</a></code></p>


      <p>Mixture of ring distributions in two dimensions</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/target.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">RingMixture</span><span class="p">(</span><span class="n">Target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mixture of ring distributions in two dimensions</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_rings</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dims</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_log_prob</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_rings</span> <span class="o">=</span> <span class="n">n_rings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">4</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rings</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_rings</span><span class="p">):</span>
            <span class="n">d_</span> <span class="o">=</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rings</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
                <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span>
            <span class="p">)</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">d_</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.target.Target" class="doc doc-heading">
            <code>Target</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Sample target distributions to test models</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/target.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Target</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample target distributions to test models</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prop_scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">6.0</span><span class="p">),</span> <span class="n">prop_shift</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          prop_scale: Scale for the uniform proposal</span>
<span class="sd">          prop_shift: Shift for the uniform proposal</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;prop_scale&quot;</span><span class="p">,</span> <span class="n">prop_scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;prop_shift&quot;</span><span class="p">,</span> <span class="n">prop_shift</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;The log probability is not implemented yet.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">rejection_sampling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform rejection sampling on image distribution</span>

<span class="sd">        Args:</span>
<span class="sd">          num_steps: Number of rejection sampling steps to perform</span>

<span class="sd">        Returns:</span>
<span class="sd">          Accepted samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dims</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span> <span class="o">*</span> <span class="n">eps</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prop_shift</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
            <span class="n">num_steps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">prob_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_log_prob</span><span class="p">)</span>
        <span class="n">accept</span> <span class="o">=</span> <span class="n">prob_</span> <span class="o">&gt;</span> <span class="n">prob</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span><span class="p">[</span><span class="n">accept</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample from image distribution through rejection sampling</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: Number of samples to draw</span>

<span class="sd">        Returns:</span>
<span class="sd">          Samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dims</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_samples</span><span class="p">:</span>
            <span class="n">z_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rejection_sampling</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">num_samples</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)])</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">[:</span><span class="n">ind</span><span class="p">,</span> <span class="p">:]],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.target.Target.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">prop_scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">6.0</span><span class="p">),</span> <span class="n">prop_shift</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">))</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prop_scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scale for the uniform proposal</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.tensor">tensor</span>(6.0)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prop_shift</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shift for the uniform proposal</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.tensor">tensor</span>(-3.0)</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/target.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prop_scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">6.0</span><span class="p">),</span> <span class="n">prop_shift</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      prop_scale: Scale for the uniform proposal</span>
<span class="sd">      prop_shift: Shift for the uniform proposal</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;prop_scale&quot;</span><span class="p">,</span> <span class="n">prop_scale</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;prop_shift&quot;</span><span class="p">,</span> <span class="n">prop_shift</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.target.Target.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/target.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;The log probability is not implemented yet.&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.target.Target.rejection_sampling" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">rejection_sampling</span><span class="p">(</span><span class="n">num_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Perform rejection sampling on image distribution</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_steps</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of rejection sampling steps to perform</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Accepted samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/target.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">rejection_sampling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform rejection sampling on image distribution</span>

<span class="sd">    Args:</span>
<span class="sd">      num_steps: Number of rejection sampling steps to perform</span>

<span class="sd">    Returns:</span>
<span class="sd">      Accepted samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
        <span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dims</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">z_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span> <span class="o">*</span> <span class="n">eps</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prop_shift</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
        <span class="n">num_steps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="n">prob_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_log_prob</span><span class="p">)</span>
    <span class="n">accept</span> <span class="o">=</span> <span class="n">prob_</span> <span class="o">&gt;</span> <span class="n">prob</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z_</span><span class="p">[</span><span class="n">accept</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.target.Target.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Sample from image distribution through rejection sampling</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to draw</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Samples</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/target.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from image distribution through rejection sampling</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: Number of samples to draw</span>

<span class="sd">    Returns:</span>
<span class="sd">      Samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dims</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prop_scale</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_samples</span><span class="p">:</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rejection_sampling</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">z_</span><span class="p">),</span> <span class="n">num_samples</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)])</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z</span><span class="p">,</span> <span class="n">z_</span><span class="p">[:</span><span class="n">ind</span><span class="p">,</span> <span class="p">:]],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.target.TwoIndependent" class="doc doc-heading">
            <code>TwoIndependent</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.target.Target" href="#normflows.distributions.target.Target">Target</a></code></p>


      <p>Target distribution that combines two independent distributions of equal
size into one distribution. This is needed for Augmented Normalizing Flows,
see https://arxiv.org/abs/2002.07101</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/target.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TwoIndependent</span><span class="p">(</span><span class="n">Target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Target distribution that combines two independent distributions of equal</span>
<span class="sd">    size into one distribution. This is needed for Augmented Normalizing Flows,</span>
<span class="sd">    see https://arxiv.org/abs/2002.07101</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target1</span><span class="p">,</span> <span class="n">target2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target1</span> <span class="o">=</span> <span class="n">target1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target2</span> <span class="o">=</span> <span class="n">target2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">Split</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;channel&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">z</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">target1</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">target2</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">z1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target1</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">z2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target2</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="o">.</span><span class="n">inverse</span><span class="p">([</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.distributions.target.TwoMoons" class="doc doc-heading">
            <code>TwoMoons</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.distributions.target.Target" href="#normflows.distributions.target.Target">Target</a></code></p>


      <p>Bimodal two-dimensional distribution</p>

              <details class="quote">
                <summary>Source code in <code>normflows/distributions/target.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TwoMoons</span><span class="p">(</span><span class="n">Target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bimodal two-dimensional distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dims</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_log_prob</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ```</span>
<span class="sd">        log(p) = - 1/2 * ((norm(z) - 2) / 0.2) ** 2</span>
<span class="sd">                 + log(  exp(-1/2 * ((z[0] - 2) / 0.3) ** 2)</span>
<span class="sd">                       + exp(-1/2 * ((z[0] + 2) / 0.3) ** 2))</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">          z: value or batch of latent variable</span>

<span class="sd">        Returns:</span>
<span class="sd">          log probability of the distribution for z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.3</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span> <span class="o">*</span> <span class="n">a</span> <span class="o">/</span> <span class="mf">0.09</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.distributions.target.TwoMoons.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <pre><code>log(p) = - 1/2 * ((norm(z) - 2) / 0.2) ** 2
         + log(  exp(-1/2 * ((z[0] - 2) / 0.3) ** 2)
               + exp(-1/2 * ((z[0] + 2) / 0.3) ** 2))
</code></pre>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>value or batch of latent variable</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log probability of the distribution for z</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/distributions/target.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ```</span>
<span class="sd">    log(p) = - 1/2 * ((norm(z) - 2) / 0.2) ** 2</span>
<span class="sd">             + log(  exp(-1/2 * ((z[0] - 2) / 0.3) ** 2)</span>
<span class="sd">                   + exp(-1/2 * ((z[0] + 2) / 0.3) ** 2))</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      z: value or batch of latent variable</span>

<span class="sd">    Returns:</span>
<span class="sd">      log probability of the distribution for z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
        <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.3</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span> <span class="o">*</span> <span class="n">a</span> <span class="o">/</span> <span class="mf">0.09</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>


  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="normflows.flows" class="doc doc-heading">
            <code>flows</code>


</h2>

    <div class="doc doc-contents ">



  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h3 id="normflows.flows.affine" class="doc doc-heading">
            <code>affine</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h4 id="normflows.flows.affine.autoregressive" class="doc doc-heading">
            <code>autoregressive</code>


</h4>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.autoregressive.Autoregressive" class="doc doc-heading">
            <code>Autoregressive</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Transforms each input variable with an invertible elementwise transformation.</p>
<p>The parameters of each invertible elementwise transformation can be functions of previous input
variables, but they must not depend on the current or any following input variables.</p>
<p><strong>NOTE</strong> Calculating the inverse transform is D times slower than calculating the
forward transform, where D is the dimensionality of the input to the transform.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/autoregressive.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Autoregressive</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms each input variable with an invertible elementwise transformation.</span>

<span class="sd">    The parameters of each invertible elementwise transformation can be functions of previous input</span>
<span class="sd">    variables, but they must not depend on the current or any following input variables.</span>

<span class="sd">    **NOTE** Calculating the inverse transform is D times slower than calculating the</span>
<span class="sd">    forward transform, where D is the dimensionality of the input to the transform.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">autoregressive_net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Autoregressive</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">autoregressive_net</span> <span class="o">=</span> <span class="n">autoregressive_net</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">autoregressive_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoregressive_net</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_elementwise_forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">autoregressive_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">num_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">logabsdet</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">):</span>
            <span class="n">autoregressive_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoregressive_net</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_elementwise_inverse</span><span class="p">(</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">autoregressive_params</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span>

    <span class="k">def</span> <span class="nf">_output_dim_multiplier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_elementwise_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">autoregressive_params</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_elementwise_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">autoregressive_params</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.autoregressive.MaskedAffineAutoregressive" class="doc doc-heading">
            <code>MaskedAffineAutoregressive</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.affine.autoregressive.Autoregressive" href="#normflows.flows.affine.autoregressive.Autoregressive">Autoregressive</a></code></p>


      <p>Masked affine autoregressive flow, mostly referred to as
Masked Autoregressive Flow (MAF), see
<a href="https://arxiv.org/abs/1705.07057">arXiv 1705.07057</a>.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/autoregressive.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MaskedAffineAutoregressive</span><span class="p">(</span><span class="n">Autoregressive</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Masked affine autoregressive flow, mostly referred to as</span>
<span class="sd">    Masked Autoregressive Flow (MAF), see</span>
<span class="sd">    [arXiv 1705.07057](https://arxiv.org/abs/1705.07057).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="n">hidden_features</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          features: Number of features/input dimensions</span>
<span class="sd">          hidden_features: Number of hidden units in the MADE network</span>
<span class="sd">          context_features: Number of context/conditional features</span>
<span class="sd">          num_blocks: Number of blocks in the MADE network</span>
<span class="sd">          use_residual_blocks: Flag whether residual blocks should be used</span>
<span class="sd">          random_mask: Flag whether to use random masks</span>
<span class="sd">          activation: Activation function to be used in the MADE network</span>
<span class="sd">          dropout_probability: Dropout probability in the MADE network</span>
<span class="sd">          use_batch_norm: Flag whether batch normalization should be used</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="n">made</span> <span class="o">=</span> <span class="n">made_module</span><span class="o">.</span><span class="n">MADE</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">context_features</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
            <span class="n">output_multiplier</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_dim_multiplier</span><span class="p">(),</span>
            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="n">use_residual_blocks</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="n">random_mask</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">use_batch_norm</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaskedAffineAutoregressive</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">made</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_output_dim_multiplier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="nf">_elementwise_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">autoregressive_params</span><span class="p">):</span>
        <span class="n">unconstrained_scale</span><span class="p">,</span> <span class="n">shift</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unconstrained_scale_and_shift</span><span class="p">(</span>
            <span class="n">autoregressive_params</span>
        <span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">unconstrained_scale</span> <span class="o">+</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-3</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">inputs</span> <span class="o">+</span> <span class="n">shift</span>
        <span class="n">logabsdet</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">sum_except_batch</span><span class="p">(</span><span class="n">log_scale</span><span class="p">,</span> <span class="n">num_batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span>

    <span class="k">def</span> <span class="nf">_elementwise_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">autoregressive_params</span><span class="p">):</span>
        <span class="n">unconstrained_scale</span><span class="p">,</span> <span class="n">shift</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unconstrained_scale_and_shift</span><span class="p">(</span>
            <span class="n">autoregressive_params</span>
        <span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">unconstrained_scale</span> <span class="o">+</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-3</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">-</span> <span class="n">shift</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
        <span class="n">logabsdet</span> <span class="o">=</span> <span class="o">-</span><span class="n">utils</span><span class="o">.</span><span class="n">sum_except_batch</span><span class="p">(</span><span class="n">log_scale</span><span class="p">,</span> <span class="n">num_batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span>

    <span class="k">def</span> <span class="nf">_unconstrained_scale_and_shift</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">autoregressive_params</span><span class="p">):</span>
        <span class="c1"># split_idx = autoregressive_params.size(1) // 2</span>
        <span class="c1"># unconstrained_scale = autoregressive_params[..., :split_idx]</span>
        <span class="c1"># shift = autoregressive_params[..., split_idx:]</span>
        <span class="c1"># return unconstrained_scale, shift</span>
        <span class="n">autoregressive_params</span> <span class="o">=</span> <span class="n">autoregressive_params</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_dim_multiplier</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">unconstrained_scale</span> <span class="o">=</span> <span class="n">autoregressive_params</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="n">autoregressive_params</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">unconstrained_scale</span><span class="p">,</span> <span class="n">shift</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.affine.autoregressive.MaskedAffineAutoregressive.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">,</span> <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>features</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of features/input dimensions</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>hidden_features</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units in the MADE network</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>context_features</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of context/conditional features</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_blocks</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of blocks in the MADE network</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>use_residual_blocks</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether residual blocks should be used</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>random_mask</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to use random masks</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>activation</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function to be used in the MADE network</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.functional.relu">relu</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dropout_probability</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout probability in the MADE network</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>use_batch_norm</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether batch normalization should be used</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/affine/autoregressive.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">features</span><span class="p">,</span>
    <span class="n">hidden_features</span><span class="p">,</span>
    <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
    <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      features: Number of features/input dimensions</span>
<span class="sd">      hidden_features: Number of hidden units in the MADE network</span>
<span class="sd">      context_features: Number of context/conditional features</span>
<span class="sd">      num_blocks: Number of blocks in the MADE network</span>
<span class="sd">      use_residual_blocks: Flag whether residual blocks should be used</span>
<span class="sd">      random_mask: Flag whether to use random masks</span>
<span class="sd">      activation: Activation function to be used in the MADE network</span>
<span class="sd">      dropout_probability: Dropout probability in the MADE network</span>
<span class="sd">      use_batch_norm: Flag whether batch normalization should be used</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
    <span class="n">made</span> <span class="o">=</span> <span class="n">made_module</span><span class="o">.</span><span class="n">MADE</span><span class="p">(</span>
        <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
        <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="n">context_features</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">output_multiplier</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_dim_multiplier</span><span class="p">(),</span>
        <span class="n">use_residual_blocks</span><span class="o">=</span><span class="n">use_residual_blocks</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="o">=</span><span class="n">random_mask</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">use_batch_norm</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MaskedAffineAutoregressive</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">made</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h4 id="normflows.flows.affine.coupling" class="doc doc-heading">
            <code>coupling</code>


</h4>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.coupling.AffineConstFlow" class="doc doc-heading">
            <code>AffineConstFlow</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>scales and shifts with learned constants per dimension. In the NICE paper there is a
scaling layer which is a special case of this where t is None</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AffineConstFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    scales and shifts with learned constants per dimension. In the NICE paper there is a</span>
<span class="sd">    scaling layer which is a special case of this where t is None</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Shape of the coupling layer</span>
<span class="sd">          scale: Flag whether to apply scaling</span>
<span class="sd">          shift: Flag whether to apply shift</span>
<span class="sd">          logscale_factor: Optional factor which can be used to control the scale of the log scale factor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">scale</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;s&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">shift</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">prod_batch_dims</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">prod_batch_dims</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.affine.coupling.AffineConstFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape of the coupling layer</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to apply scaling</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>shift</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to apply shift</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>logscale_factor</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional factor which can be used to control the scale of the log scale factor</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Shape of the coupling layer</span>
<span class="sd">      scale: Flag whether to apply scaling</span>
<span class="sd">      shift: Flag whether to apply shift</span>
<span class="sd">      logscale_factor: Optional factor which can be used to control the scale of the log scale factor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">scale</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;s&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">shift</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.coupling.AffineCoupling" class="doc doc-heading">
            <code>AffineCoupling</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Affine Coupling layer as introduced RealNVP paper, see arXiv: 1605.08803</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AffineCoupling</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Affine Coupling layer as introduced RealNVP paper, see arXiv: 1605.08803</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_map</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          param_map: Maps features to shift and scale parameter (if applicable)</span>
<span class="sd">          scale: Flag whether scale shall be applied</span>
<span class="sd">          scale_map: Map to be applied to the scale parameter, can be &#39;exp&#39; as in RealNVP or &#39;sigmoid&#39; as in Glow, &#39;sigmoid_inv&#39; uses multiplicative sigmoid scale when sampling from the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;param_map&quot;</span><span class="p">,</span> <span class="n">param_map</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">=</span> <span class="n">scale_map</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        z is a list of z1 and z2; ```z = [z1, z2]```</span>
<span class="sd">        z1 is left constant and affine map is applied to z2 with parameters depending</span>
<span class="sd">        on z1</span>

<span class="sd">        Args:</span>
<span class="sd">          z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_map</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">:</span>
            <span class="n">shift</span> <span class="o">=</span> <span class="n">param</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">scale_</span> <span class="o">=</span> <span class="n">param</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
                <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scale_</span><span class="p">)</span> <span class="o">+</span> <span class="n">shift</span>
                <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scale_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">scale_</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">/</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">shift</span>
                <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;sigmoid_inv&quot;</span><span class="p">:</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">scale_</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">shift</span>
                <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This scale map is not implemented.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">+</span> <span class="n">param</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">zero_log_det_like_z</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_map</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">:</span>
            <span class="n">shift</span> <span class="o">=</span> <span class="n">param</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">scale_</span> <span class="o">=</span> <span class="n">param</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
                <span class="n">z2</span> <span class="o">=</span> <span class="p">(</span><span class="n">z2</span> <span class="o">-</span> <span class="n">shift</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">scale_</span><span class="p">)</span>
                <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scale_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">scale_</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">z2</span> <span class="o">=</span> <span class="p">(</span><span class="n">z2</span> <span class="o">-</span> <span class="n">shift</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span>
                <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;sigmoid_inv&quot;</span><span class="p">:</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">scale_</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">z2</span> <span class="o">=</span> <span class="p">(</span><span class="n">z2</span> <span class="o">-</span> <span class="n">shift</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
                <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This scale map is not implemented.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">-</span> <span class="n">param</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">zero_log_det_like_z</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.affine.coupling.AffineCoupling.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_map</span><span class="o">=</span><span class="s1">&#39;exp&#39;</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>param_map</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maps features to shift and scale parameter (if applicable)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether scale shall be applied</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale_map</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Map to be applied to the scale parameter, can be 'exp' as in RealNVP or 'sigmoid' as in Glow, 'sigmoid_inv' uses multiplicative sigmoid scale when sampling from the model</p>
              </div>
            </td>
            <td>
                  <code>&#39;exp&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_map</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      param_map: Maps features to shift and scale parameter (if applicable)</span>
<span class="sd">      scale: Flag whether scale shall be applied</span>
<span class="sd">      scale_map: Map to be applied to the scale parameter, can be &#39;exp&#39; as in RealNVP or &#39;sigmoid&#39; as in Glow, &#39;sigmoid_inv&#39; uses multiplicative sigmoid scale when sampling from the model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;param_map&quot;</span><span class="p">,</span> <span class="n">param_map</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">=</span> <span class="n">scale_map</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="normflows.flows.affine.coupling.AffineCoupling.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>z is a list of z1 and z2; <code>z = [z1, z2]</code>
z1 is left constant and affine map is applied to z2 with parameters depending
on z1</p>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    z is a list of z1 and z2; ```z = [z1, z2]```</span>
<span class="sd">    z1 is left constant and affine map is applied to z2 with parameters depending</span>
<span class="sd">    on z1</span>

<span class="sd">    Args:</span>
<span class="sd">      z</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span>
    <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_map</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">:</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="n">param</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="n">scale_</span> <span class="o">=</span> <span class="n">param</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scale_</span><span class="p">)</span> <span class="o">+</span> <span class="n">shift</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scale_</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">scale_</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">/</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">shift</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_map</span> <span class="o">==</span> <span class="s2">&quot;sigmoid_inv&quot;</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">scale_</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">shift</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This scale map is not implemented.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">+</span> <span class="n">param</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">zero_log_det_like_z</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.coupling.AffineCouplingBlock" class="doc doc-heading">
            <code>AffineCouplingBlock</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Affine Coupling layer including split and merge operation</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AffineCouplingBlock</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Affine Coupling layer including split and merge operation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_map</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">,</span> <span class="n">split_mode</span><span class="o">=</span><span class="s2">&quot;channel&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          param_map: Maps features to shift and scale parameter (if applicable)</span>
<span class="sd">          scale: Flag whether scale shall be applied</span>
<span class="sd">          scale_map: Map to be applied to the scale parameter, can be &#39;exp&#39; as in RealNVP or &#39;sigmoid&#39; as in Glow</span>
<span class="sd">          split_mode: Splitting mode, for possible values see Split class</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="c1"># Split layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Split</span><span class="p">(</span><span class="n">split_mode</span><span class="p">)]</span>
        <span class="c1"># Affine coupling layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">AffineCoupling</span><span class="p">(</span><span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">scale_map</span><span class="p">)]</span>
        <span class="c1"># Merge layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Merge</span><span class="p">(</span><span class="n">split_mode</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">log_det_tot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_det_tot</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det_tot</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">log_det_tot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_det_tot</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det_tot</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.affine.coupling.AffineCouplingBlock.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_map</span><span class="o">=</span><span class="s1">&#39;exp&#39;</span><span class="p">,</span> <span class="n">split_mode</span><span class="o">=</span><span class="s1">&#39;channel&#39;</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>param_map</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maps features to shift and scale parameter (if applicable)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether scale shall be applied</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale_map</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Map to be applied to the scale parameter, can be 'exp' as in RealNVP or 'sigmoid' as in Glow</p>
              </div>
            </td>
            <td>
                  <code>&#39;exp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>split_mode</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Splitting mode, for possible values see Split class</p>
              </div>
            </td>
            <td>
                  <code>&#39;channel&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_map</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">,</span> <span class="n">split_mode</span><span class="o">=</span><span class="s2">&quot;channel&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      param_map: Maps features to shift and scale parameter (if applicable)</span>
<span class="sd">      scale: Flag whether scale shall be applied</span>
<span class="sd">      scale_map: Map to be applied to the scale parameter, can be &#39;exp&#39; as in RealNVP or &#39;sigmoid&#39; as in Glow</span>
<span class="sd">      split_mode: Splitting mode, for possible values see Split class</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
    <span class="c1"># Split layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Split</span><span class="p">(</span><span class="n">split_mode</span><span class="p">)]</span>
    <span class="c1"># Affine coupling layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">AffineCoupling</span><span class="p">(</span><span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">scale_map</span><span class="p">)]</span>
    <span class="c1"># Merge layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Merge</span><span class="p">(</span><span class="n">split_mode</span><span class="p">)]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.coupling.CCAffineConst" class="doc doc-heading">
            <code>CCAffineConst</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Affine constant flow layer with class-conditional parameters</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CCAffineConst</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Affine constant flow layer with class-conditional parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s_cc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t_cc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="n">t</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">prod_batch_dims</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_cc</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prod_batch_dims</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">prod_batch_dims</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.coupling.MaskedAffineFlow" class="doc doc-heading">
            <code>MaskedAffineFlow</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>RealNVP as introduced in <a href="https://arxiv.org/abs/1605.08803">arXiv: 1605.08803</a></p>
<p>Masked affine flow:</p>
<pre><code>f(z) = b * z + (1 - b) * (z * exp(s(b * z)) + t)
</code></pre>
<ul>
<li>class AffineHalfFlow(Flow): is MaskedAffineFlow with alternating bit mask</li>
<li>NICE is AffineFlow with only shifts (volume preserving)</li>
</ul>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MaskedAffineFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;RealNVP as introduced in [arXiv: 1605.08803](https://arxiv.org/abs/1605.08803)</span>

<span class="sd">    Masked affine flow:</span>

<span class="sd">    ```</span>
<span class="sd">    f(z) = b * z + (1 - b) * (z * exp(s(b * z)) + t)</span>
<span class="sd">    ```</span>

<span class="sd">    - class AffineHalfFlow(Flow): is MaskedAffineFlow with alternating bit mask</span>
<span class="sd">    - NICE is AffineFlow with only shifts (volume preserving)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          b: mask for features, i.e. tensor of same size as latent data point filled with 0s and 1s</span>
<span class="sd">          t: translation mapping, i.e. neural network, where first input dimension is batch dim, if None no translation is applied</span>
<span class="sd">          s: scale mapping, i.e. neural network, where first input dimension is batch dim, if None no scale is applied</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_cpu</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">b</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_cpu</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;s&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_masked</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">*</span> <span class="n">z</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">z_masked</span><span class="p">)</span>
        <span class="n">nan</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">scale</span><span class="p">,</span> <span class="n">nan</span><span class="p">)</span>
        <span class="n">trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">z_masked</span><span class="p">)</span>
        <span class="n">trans</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">trans</span><span class="p">),</span> <span class="n">trans</span><span class="p">,</span> <span class="n">nan</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z_masked</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">z</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="n">trans</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_masked</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">*</span> <span class="n">z</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">z_masked</span><span class="p">)</span>
        <span class="n">nan</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">scale</span><span class="p">),</span> <span class="n">scale</span><span class="p">,</span> <span class="n">nan</span><span class="p">)</span>
        <span class="n">trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">z_masked</span><span class="p">)</span>
        <span class="n">trans</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">trans</span><span class="p">),</span> <span class="n">trans</span><span class="p">,</span> <span class="n">nan</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z_masked</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">trans</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.affine.coupling.MaskedAffineFlow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>b</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>mask for features, i.e. tensor of same size as latent data point filled with 0s and 1s</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>t</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>translation mapping, i.e. neural network, where first input dimension is batch dim, if None no translation is applied</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>s</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>scale mapping, i.e. neural network, where first input dimension is batch dim, if None no scale is applied</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/affine/coupling.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      b: mask for features, i.e. tensor of same size as latent data point filled with 0s and 1s</span>
<span class="sd">      t: translation mapping, i.e. neural network, where first input dimension is batch dim, if None no translation is applied</span>
<span class="sd">      s: scale mapping, i.e. neural network, where first input dimension is batch dim, if None no scale is applied</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b_cpu</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">b</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_cpu</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;s&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h4 id="normflows.flows.affine.glow" class="doc doc-heading">
            <code>glow</code>


</h4>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h5 id="normflows.flows.affine.glow.GlowBlock" class="doc doc-heading">
            <code>GlowBlock</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Glow: Generative Flow with Invertible 1×1 Convolutions, <a href="https://arxiv.org/abs/1807.03039">arXiv: 1807.03039</a></p>
<p>One Block of the Glow model, comprised of</p>
<ul>
<li>MaskedAffineFlow (affine coupling layer)</li>
<li>Invertible1x1Conv (dropped if there is only one channel)</li>
<li>ActNorm (first batch used for initialization)</li>
</ul>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/affine/glow.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">GlowBlock</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Glow: Generative Flow with Invertible 1×1 Convolutions, [arXiv: 1807.03039](https://arxiv.org/abs/1807.03039)</span>

<span class="sd">    One Block of the Glow model, comprised of</span>

<span class="sd">    - MaskedAffineFlow (affine coupling layer)</span>
<span class="sd">    - Invertible1x1Conv (dropped if there is only one channel)</span>
<span class="sd">    - ActNorm (first batch used for initialization)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="p">,</span>
        <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">scale_map</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
        <span class="n">split_mode</span><span class="o">=</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span>
        <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">use_lu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">net_actnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          channels: Number of channels of the data</span>
<span class="sd">          hidden_channels: number of channels in the hidden layer of the ConvNet</span>
<span class="sd">          scale: Flag, whether to include scale in affine coupling layer</span>
<span class="sd">          scale_map: Map to be applied to the scale parameter, can be &#39;exp&#39; as in RealNVP or &#39;sigmoid&#39; as in Glow</span>
<span class="sd">          split_mode: Splitting mode, for possible values see Split class</span>
<span class="sd">          leaky: Leaky parameter of LeakyReLUs of ConvNet2d</span>
<span class="sd">          init_zeros: Flag whether to initialize last conv layer with zeros</span>
<span class="sd">          use_lu: Flag whether to parametrize weights through the LU decomposition in invertible 1x1 convolution layers</span>
<span class="sd">          logscale_factor: Factor which can be used to control the scale of the log scale factor, see [source](https://github.com/openai/glow)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="c1"># Coupling layer</span>
        <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">num_param</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">scale</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="s2">&quot;channel&quot;</span> <span class="o">==</span> <span class="n">split_mode</span><span class="p">:</span>
            <span class="n">channels_</span> <span class="o">=</span> <span class="p">((</span><span class="n">channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_channels</span><span class="p">,)</span>
            <span class="n">channels_</span> <span class="o">+=</span> <span class="p">(</span><span class="n">num_param</span> <span class="o">*</span> <span class="p">(</span><span class="n">channels</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),)</span>
        <span class="k">elif</span> <span class="s2">&quot;channel_inv&quot;</span> <span class="o">==</span> <span class="n">split_mode</span><span class="p">:</span>
            <span class="n">channels_</span> <span class="o">=</span> <span class="p">(</span><span class="n">channels</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_channels</span><span class="p">,)</span>
            <span class="n">channels_</span> <span class="o">+=</span> <span class="p">(</span><span class="n">num_param</span> <span class="o">*</span> <span class="p">((</span><span class="n">channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),)</span>
        <span class="k">elif</span> <span class="s2">&quot;checkerboard&quot;</span> <span class="ow">in</span> <span class="n">split_mode</span><span class="p">:</span>
            <span class="n">channels_</span> <span class="o">=</span> <span class="p">(</span><span class="n">channels</span><span class="p">,)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_channels</span><span class="p">,)</span>
            <span class="n">channels_</span> <span class="o">+=</span> <span class="p">(</span><span class="n">num_param</span> <span class="o">*</span> <span class="n">channels</span><span class="p">,)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Mode &quot;</span> <span class="o">+</span> <span class="n">split_mode</span> <span class="o">+</span> <span class="s2">&quot; is not implemented.&quot;</span><span class="p">)</span>
        <span class="n">param_map</span> <span class="o">=</span> <span class="n">nets</span><span class="o">.</span><span class="n">ConvNet2d</span><span class="p">(</span>
            <span class="n">channels_</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">leaky</span><span class="p">,</span> <span class="n">init_zeros</span><span class="p">,</span> <span class="n">actnorm</span><span class="o">=</span><span class="n">net_actnorm</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">AffineCouplingBlock</span><span class="p">(</span><span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">scale_map</span><span class="p">,</span> <span class="n">split_mode</span><span class="p">)]</span>
        <span class="c1"># Invertible 1x1 convolution</span>
        <span class="k">if</span> <span class="n">channels</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Invertible1x1Conv</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="p">)]</span>
        <span class="c1"># Activation normalization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ActNorm</span><span class="p">((</span><span class="n">channels</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">log_det_tot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_det_tot</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det_tot</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">log_det_tot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_det_tot</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det_tot</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.affine.glow.GlowBlock.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_map</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">split_mode</span><span class="o">=</span><span class="s1">&#39;channel&#39;</span><span class="p">,</span> <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_lu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">net_actnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>channels</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of channels of the data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>hidden_channels</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of channels in the hidden layer of the ConvNet</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, whether to include scale in affine coupling layer</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale_map</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Map to be applied to the scale parameter, can be 'exp' as in RealNVP or 'sigmoid' as in Glow</p>
              </div>
            </td>
            <td>
                  <code>&#39;sigmoid&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>split_mode</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Splitting mode, for possible values see Split class</p>
              </div>
            </td>
            <td>
                  <code>&#39;channel&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>leaky</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Leaky parameter of LeakyReLUs of ConvNet2d</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_zeros</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to initialize last conv layer with zeros</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>use_lu</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to parametrize weights through the LU decomposition in invertible 1x1 convolution layers</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>logscale_factor</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Factor which can be used to control the scale of the log scale factor, see <a href="https://github.com/openai/glow">source</a></p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/affine/glow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">channels</span><span class="p">,</span>
    <span class="n">hidden_channels</span><span class="p">,</span>
    <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">scale_map</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
    <span class="n">split_mode</span><span class="o">=</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span>
    <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">use_lu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">net_actnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      channels: Number of channels of the data</span>
<span class="sd">      hidden_channels: number of channels in the hidden layer of the ConvNet</span>
<span class="sd">      scale: Flag, whether to include scale in affine coupling layer</span>
<span class="sd">      scale_map: Map to be applied to the scale parameter, can be &#39;exp&#39; as in RealNVP or &#39;sigmoid&#39; as in Glow</span>
<span class="sd">      split_mode: Splitting mode, for possible values see Split class</span>
<span class="sd">      leaky: Leaky parameter of LeakyReLUs of ConvNet2d</span>
<span class="sd">      init_zeros: Flag whether to initialize last conv layer with zeros</span>
<span class="sd">      use_lu: Flag whether to parametrize weights through the LU decomposition in invertible 1x1 convolution layers</span>
<span class="sd">      logscale_factor: Factor which can be used to control the scale of the log scale factor, see [source](https://github.com/openai/glow)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
    <span class="c1"># Coupling layer</span>
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">num_param</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">scale</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="s2">&quot;channel&quot;</span> <span class="o">==</span> <span class="n">split_mode</span><span class="p">:</span>
        <span class="n">channels_</span> <span class="o">=</span> <span class="p">((</span><span class="n">channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_channels</span><span class="p">,)</span>
        <span class="n">channels_</span> <span class="o">+=</span> <span class="p">(</span><span class="n">num_param</span> <span class="o">*</span> <span class="p">(</span><span class="n">channels</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),)</span>
    <span class="k">elif</span> <span class="s2">&quot;channel_inv&quot;</span> <span class="o">==</span> <span class="n">split_mode</span><span class="p">:</span>
        <span class="n">channels_</span> <span class="o">=</span> <span class="p">(</span><span class="n">channels</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_channels</span><span class="p">,)</span>
        <span class="n">channels_</span> <span class="o">+=</span> <span class="p">(</span><span class="n">num_param</span> <span class="o">*</span> <span class="p">((</span><span class="n">channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),)</span>
    <span class="k">elif</span> <span class="s2">&quot;checkerboard&quot;</span> <span class="ow">in</span> <span class="n">split_mode</span><span class="p">:</span>
        <span class="n">channels_</span> <span class="o">=</span> <span class="p">(</span><span class="n">channels</span><span class="p">,)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_channels</span><span class="p">,)</span>
        <span class="n">channels_</span> <span class="o">+=</span> <span class="p">(</span><span class="n">num_param</span> <span class="o">*</span> <span class="n">channels</span><span class="p">,)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Mode &quot;</span> <span class="o">+</span> <span class="n">split_mode</span> <span class="o">+</span> <span class="s2">&quot; is not implemented.&quot;</span><span class="p">)</span>
    <span class="n">param_map</span> <span class="o">=</span> <span class="n">nets</span><span class="o">.</span><span class="n">ConvNet2d</span><span class="p">(</span>
        <span class="n">channels_</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">leaky</span><span class="p">,</span> <span class="n">init_zeros</span><span class="p">,</span> <span class="n">actnorm</span><span class="o">=</span><span class="n">net_actnorm</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">AffineCouplingBlock</span><span class="p">(</span><span class="n">param_map</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">scale_map</span><span class="p">,</span> <span class="n">split_mode</span><span class="p">)]</span>
    <span class="c1"># Invertible 1x1 convolution</span>
    <span class="k">if</span> <span class="n">channels</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Invertible1x1Conv</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="p">)]</span>
    <span class="c1"># Activation normalization</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flows</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ActNorm</span><span class="p">((</span><span class="n">channels</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>


  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.base" class="doc doc-heading">
            <code>base</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.base.Composite" class="doc doc-heading">
            <code>Composite</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Composes several flows into one, in the order they are given.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Composite</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Composes several flows into one, in the order they are given.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flows</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          flows: Iterable of flows to composite</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_cascade</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">funcs</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">total_logabsdet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">funcs</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
            <span class="n">total_logabsdet</span> <span class="o">+=</span> <span class="n">logabsdet</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">total_logabsdet</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">funcs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flows</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cascade</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">funcs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">funcs</span> <span class="o">=</span> <span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">inverse</span> <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flows</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cascade</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">funcs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.base.Composite.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>flows</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Iterable of flows to composite</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flows</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      flows: Iterable of flows to composite</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_flows</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">flows</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.base.Flow" class="doc doc-heading">
            <code>Flow</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Generic class for flow functions</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Flow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generic class for flow functions</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          z: input variable, first dimension is batch dim</span>

<span class="sd">        Returns:</span>
<span class="sd">          transformed z and log of absolute determinant</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Forward pass has not been implemented.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This flow has no algebraic inverse.&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.base.Flow.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>z</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>input variable, first dimension is batch dim</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>transformed z and log of absolute determinant</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      z: input variable, first dimension is batch dim</span>

<span class="sd">    Returns:</span>
<span class="sd">      transformed z and log of absolute determinant</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Forward pass has not been implemented.&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.base.Reverse" class="doc doc-heading">
            <code>Reverse</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Switches the forward transform of a flow layer with its inverse and vice versa</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Reverse</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Switches the forward transform of a flow layer with its inverse and vice versa</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flow</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          flow: Flow layer to be reversed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="o">=</span> <span class="n">flow</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.base.Reverse.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>flow</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flow layer to be reversed</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      flow: Flow layer to be reversed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="o">=</span> <span class="n">flow</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.flow_test" class="doc doc-heading">
            <code>flow_test</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.flow_test.FlowTest" class="doc doc-heading">
            <code>FlowTest</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="unittest.TestCase">TestCase</span></code></p>


      <p>Generic test case for flow modules</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/flow_test.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">FlowTest</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generic test case for flow modules</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">assertClose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">assert_close</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">checkForward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flow</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Do forward transform</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="c1"># Check type</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span>
        <span class="c1"># Check shape</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># Return results</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">checkInverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flow</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Do inverse transform</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="c1"># Check type</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span>
        <span class="c1"># Check shape</span>
        <span class="k">assert</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># Return results</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">checkForwardInverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flow</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Check forward</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkForward</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="c1"># Check inverse</span>
        <span class="n">input_</span><span class="p">,</span> <span class="n">log_det_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkInverse</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="c1"># Check identity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertClose</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">atol</span><span class="p">,</span> <span class="n">rtol</span><span class="p">)</span>
        <span class="n">ld_id</span> <span class="o">=</span> <span class="n">log_det</span> <span class="o">+</span> <span class="n">log_det_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertClose</span><span class="p">(</span><span class="n">ld_id</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">ld_id</span><span class="p">),</span> <span class="n">atol</span><span class="p">,</span> <span class="n">rtol</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.mixing" class="doc doc-heading">
            <code>mixing</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.mixing.Invertible1x1Conv" class="doc doc-heading">
            <code>Invertible1x1Conv</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Invertible 1x1 convolution introduced in the Glow paper
Assumes 4d input/output tensors of the form NCHW</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Invertible1x1Conv</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invertible 1x1 convolution introduced in the Glow paper</span>
<span class="sd">    Assumes 4d input/output tensors of the form NCHW</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_channels: Number of channels of the data</span>
<span class="sd">          use_lu: Flag whether to parametrize weights through the LU decomposition</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span> <span class="o">=</span> <span class="n">use_lu</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">use_lu</span><span class="p">:</span>
            <span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">lu_unpack</span><span class="p">(</span><span class="o">*</span><span class="n">Q</span><span class="o">.</span><span class="n">lu</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>  <span class="c1"># remains fixed during optimization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>  <span class="c1"># lower triangular portion</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>  <span class="c1"># &quot;crop out&quot; the diagonal to its own parameter</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;sign_S&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_S</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>  <span class="c1"># &quot;crop out&quot; diagonal, stored in S</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;eye&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_assemble_W</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># assemble W from its components (P, L, U, S)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eye</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sign_S</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">inverse</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="n">L_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
                <span class="n">U_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">L_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">double</span><span class="p">())</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="n">U_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">double</span><span class="p">())</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">U_inv</span> <span class="o">@</span> <span class="n">L_inv</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">@</span> <span class="n">L</span> <span class="o">@</span> <span class="n">U</span>
        <span class="k">return</span> <span class="n">W</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assemble_W</span><span class="p">(</span><span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">W_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">dtype</span>
            <span class="k">if</span> <span class="n">W_dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">double</span><span class="p">())</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">W_dtype</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">W</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">log_det</span> <span class="o">*</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assemble_W</span><span class="p">()</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">log_det</span> <span class="o">*</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.mixing.Invertible1x1Conv.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_channels</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of channels of the data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>use_lu</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to parametrize weights through the LU decomposition</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_channels: Number of channels of the data</span>
<span class="sd">      use_lu: Flag whether to parametrize weights through the LU decomposition</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span> <span class="o">=</span> <span class="n">use_lu</span>
    <span class="n">Q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">use_lu</span><span class="p">:</span>
        <span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">lu_unpack</span><span class="p">(</span><span class="o">*</span><span class="n">Q</span><span class="o">.</span><span class="n">lu</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>  <span class="c1"># remains fixed during optimization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>  <span class="c1"># lower triangular portion</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>  <span class="c1"># &quot;crop out&quot; the diagonal to its own parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;sign_S&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_S</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># &quot;crop out&quot; diagonal, stored in S</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;eye&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.mixing.InvertibleAffine" class="doc doc-heading">
            <code>InvertibleAffine</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Invertible affine transformation without shift, i.e. one-dimensional
version of the invertible 1x1 convolutions</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">InvertibleAffine</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invertible affine transformation without shift, i.e. one-dimensional</span>
<span class="sd">    version of the invertible 1x1 convolutions</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_channels: Number of channels of the data</span>
<span class="sd">          use_lu: Flag whether to parametrize weights through the LU decomposition</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span> <span class="o">=</span> <span class="n">use_lu</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">use_lu</span><span class="p">:</span>
            <span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">lu_unpack</span><span class="p">(</span><span class="o">*</span><span class="n">Q</span><span class="o">.</span><span class="n">lu</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>  <span class="c1"># remains fixed during optimization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>  <span class="c1"># lower triangular portion</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>  <span class="c1"># &quot;crop out&quot; the diagonal to its own parameter</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;sign_S&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_S</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>  <span class="c1"># &quot;crop out&quot; diagonal, stored in S</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;eye&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_assemble_W</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># assemble W from its components (P, L, U, S)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eye</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sign_S</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">inverse</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="n">L_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
                <span class="n">U_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">L_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">double</span><span class="p">())</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="n">U_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">double</span><span class="p">())</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">U_inv</span> <span class="o">@</span> <span class="n">L_inv</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">@</span> <span class="n">L</span> <span class="o">@</span> <span class="n">U</span>
        <span class="k">return</span> <span class="n">W</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assemble_W</span><span class="p">(</span><span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">W_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">dtype</span>
            <span class="k">if</span> <span class="n">W_dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">double</span><span class="p">())</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">W_dtype</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">@</span> <span class="n">W</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assemble_W</span><span class="p">()</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_S</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">@</span> <span class="n">W</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.mixing.InvertibleAffine.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_channels</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of channels of the data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>use_lu</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to parametrize weights through the LU decomposition</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">use_lu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_channels: Number of channels of the data</span>
<span class="sd">      use_lu: Flag whether to parametrize weights through the LU decomposition</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_lu</span> <span class="o">=</span> <span class="n">use_lu</span>
    <span class="n">Q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">use_lu</span><span class="p">:</span>
        <span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">lu_unpack</span><span class="p">(</span><span class="o">*</span><span class="n">Q</span><span class="o">.</span><span class="n">lu</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>  <span class="c1"># remains fixed during optimization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>  <span class="c1"># lower triangular portion</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>  <span class="c1"># &quot;crop out&quot; the diagonal to its own parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;sign_S&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_S</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># &quot;crop out&quot; diagonal, stored in S</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;eye&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.mixing.LULinearPermute" class="doc doc-heading">
            <code>LULinearPermute</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Fixed permutation combined with a linear transformation parametrized
using the LU decomposition, used in https://arxiv.org/abs/1906.04032</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LULinearPermute</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fixed permutation combined with a linear transformation parametrized</span>
<span class="sd">    using the LU decomposition, used in https://arxiv.org/abs/1906.04032</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_channels: Number of dimensions of the data</span>
<span class="sd">          identity_init: Flag, whether to initialize linear transform as identity matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Define modules</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">permutation</span> <span class="o">=</span> <span class="n">_RandomPermutation</span><span class="p">(</span><span class="n">num_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">_LULinear</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="n">identity_init</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">permutation</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.mixing.LULinearPermute.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_channels</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of dimensions of the data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>identity_init</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, whether to initialize linear transform as identity matrix</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_channels: Number of dimensions of the data</span>
<span class="sd">      identity_init: Flag, whether to initialize linear transform as identity matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Initialize</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># Define modules</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">permutation</span> <span class="o">=</span> <span class="n">_RandomPermutation</span><span class="p">(</span><span class="n">num_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">_LULinear</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="n">identity_init</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.mixing.Permute" class="doc doc-heading">
            <code>Permute</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Permutation features along the channel dimension</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Permute</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Permutation features along the channel dimension</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;shuffle&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_channel: Number of channels</span>
<span class="sd">          mode: Mode of permuting features, can be shuffle for random permutation or swap for interchanging upper and lower part</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span>
            <span class="n">perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
            <span class="n">inv_perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">perm</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;perm&quot;</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;inv_perm&quot;</span><span class="p">,</span> <span class="n">inv_perm</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">perm</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;swap&quot;</span><span class="p">:</span>
            <span class="n">z1</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">//</span> <span class="mi">2</span> <span class="p">:,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z2</span><span class="p">,</span> <span class="n">z1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;The mode &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">+</span> <span class="s2">&quot; is not implemented.&quot;</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_perm</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;swap&quot;</span><span class="p">:</span>
            <span class="n">z1</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="p">:,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z2</span><span class="p">,</span> <span class="n">z1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;The mode &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">+</span> <span class="s2">&quot; is not implemented.&quot;</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.mixing.Permute.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;shuffle&#39;</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_channel</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of channels</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>mode</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mode of permuting features, can be shuffle for random permutation or swap for interchanging upper and lower part</p>
              </div>
            </td>
            <td>
                  <code>&#39;shuffle&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/mixing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;shuffle&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_channel: Number of channels</span>
<span class="sd">      mode: Mode of permuting features, can be shuffle for random permutation or swap for interchanging upper and lower part</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
        <span class="n">inv_perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">perm</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;perm&quot;</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;inv_perm&quot;</span><span class="p">,</span> <span class="n">inv_perm</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.neural_spline" class="doc doc-heading">
            <code>neural_spline</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h4 id="normflows.flows.neural_spline.autoregressive" class="doc doc-heading">
            <code>autoregressive</code>


</h4>

    <div class="doc doc-contents ">

      <p>Implementations of autoregressive transforms.
Code taken from https://github.com/bayesiains/nsf</p>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h4 id="normflows.flows.neural_spline.autoregressive_test" class="doc doc-heading">
            <code>autoregressive_test</code>


</h4>

    <div class="doc doc-contents ">

      <p>Tests for the autoregressive transforms.
Code partially taken from https://github.com/bayesiains/nsf</p>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h4 id="normflows.flows.neural_spline.coupling" class="doc doc-heading">
            <code>coupling</code>


</h4>

    <div class="doc doc-contents ">

      <p>Implementations of various coupling layers.
Code taken from https://github.com/bayesiains/nsf</p>



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h5 id="normflows.flows.neural_spline.coupling.Coupling" class="doc doc-heading">
            <code>Coupling</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>A base class for coupling layers. Supports 2D inputs (NxD), as well as 4D inputs for
images (NxCxHxW). For images the splitting is done on the channel dimension, using the
provided 1D mask.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/neural_spline/coupling.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Coupling</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A base class for coupling layers. Supports 2D inputs (NxD), as well as 4D inputs for</span>
<span class="sd">    images (NxCxHxW). For images the splitting is done on the channel dimension, using the</span>
<span class="sd">    provided 1D mask.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">transform_net_create_fn</span><span class="p">,</span> <span class="n">unconditional_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">        mask: a 1-dim tensor, tuple or list. It indexes inputs as follows:</span>

<span class="sd">        - if `mask[i] &gt; 0`, `input[i]` will be transformed.</span>
<span class="sd">        - if `mask[i] &lt;= 0`, `input[i]` will be passed unchanged.</span>

<span class="sd">        Args:</span>
<span class="sd">          mask</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mask must be a 1-dim tensor.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mask can&#39;t be empty.&quot;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">features_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;identity_features&quot;</span><span class="p">,</span> <span class="n">features_vector</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;transform_features&quot;</span><span class="p">,</span> <span class="n">features_vector</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_identity_features</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_transform_features</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transform_net</span> <span class="o">=</span> <span class="n">transform_net_create_fn</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_identity_features</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_transform_features</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_dim_multiplier</span><span class="p">(),</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">unconditional_transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span> <span class="o">=</span> <span class="n">unconditional_transform</span><span class="p">(</span>
                <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_identity_features</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_identity_features</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">identity_features</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_transform_features</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Inputs must be a 2D or a 4D tensor.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected features = </span><span class="si">{}</span><span class="s2">, got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>

        <span class="n">identity_split</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">identity_features</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="n">transform_split</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_features</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>

        <span class="n">transform_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_net</span><span class="p">(</span><span class="n">identity_split</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">transform_split</span><span class="p">,</span> <span class="n">logabsdet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coupling_transform_forward</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">transform_split</span><span class="p">,</span> <span class="n">transform_params</span><span class="o">=</span><span class="n">transform_params</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity_split</span><span class="p">,</span> <span class="n">logabsdet_identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span><span class="p">(</span>
                <span class="n">identity_split</span><span class="p">,</span> <span class="n">context</span>
            <span class="p">)</span>
            <span class="n">logabsdet</span> <span class="o">+=</span> <span class="n">logabsdet_identity</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">identity_features</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">identity_split</span>
        <span class="n">outputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_features</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_split</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Inputs must be a 2D or a 4D tensor.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected features = </span><span class="si">{}</span><span class="s2">, got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>

        <span class="n">identity_split</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">identity_features</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="n">transform_split</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_features</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>

        <span class="n">logabsdet</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity_split</span><span class="p">,</span> <span class="n">logabsdet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span>
                <span class="n">identity_split</span><span class="p">,</span> <span class="n">context</span>
            <span class="p">)</span>

        <span class="n">transform_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_net</span><span class="p">(</span><span class="n">identity_split</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">transform_split</span><span class="p">,</span> <span class="n">logabsdet_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coupling_transform_inverse</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">transform_split</span><span class="p">,</span> <span class="n">transform_params</span><span class="o">=</span><span class="n">transform_params</span>
        <span class="p">)</span>
        <span class="n">logabsdet</span> <span class="o">+=</span> <span class="n">logabsdet_split</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">identity_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">identity_split</span>
        <span class="n">outputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_split</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">logabsdet</span>

    <span class="k">def</span> <span class="nf">_transform_dim_multiplier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of features to output for each transform dimension.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_coupling_transform_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">transform_params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass of the coupling transform.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_coupling_transform_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">transform_params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverse of the coupling transform.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.neural_spline.coupling.Coupling.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">transform_net_create_fn</span><span class="p">,</span> <span class="n">unconditional_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor.</p>
<p>mask: a 1-dim tensor, tuple or list. It indexes inputs as follows:</p>
<ul>
<li>if <code>mask[i] &gt; 0</code>, <code>input[i]</code> will be transformed.</li>
<li>if <code>mask[i] &lt;= 0</code>, <code>input[i]</code> will be passed unchanged.</li>
</ul>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/neural_spline/coupling.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">transform_net_create_fn</span><span class="p">,</span> <span class="n">unconditional_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">    mask: a 1-dim tensor, tuple or list. It indexes inputs as follows:</span>

<span class="sd">    - if `mask[i] &gt; 0`, `input[i]` will be transformed.</span>
<span class="sd">    - if `mask[i] &lt;= 0`, `input[i]` will be passed unchanged.</span>

<span class="sd">    Args:</span>
<span class="sd">      mask</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mask must be a 1-dim tensor.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mask can&#39;t be empty.&quot;</span><span class="p">)</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">features_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
        <span class="s2">&quot;identity_features&quot;</span><span class="p">,</span> <span class="n">features_vector</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
        <span class="s2">&quot;transform_features&quot;</span><span class="p">,</span> <span class="n">features_vector</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_identity_features</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_transform_features</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">transform_net</span> <span class="o">=</span> <span class="n">transform_net_create_fn</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_identity_features</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_transform_features</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_dim_multiplier</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">unconditional_transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unconditional_transform</span> <span class="o">=</span> <span class="n">unconditional_transform</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_identity_features</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h4 id="normflows.flows.neural_spline.coupling_test" class="doc doc-heading">
            <code>coupling_test</code>


</h4>

    <div class="doc doc-contents ">

      <p>Tests for the coupling Transforms.
Code partially taken from https://github.com/bayesiains/nsf</p>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h4 id="normflows.flows.neural_spline.wrapper" class="doc doc-heading">
            <code>wrapper</code>


</h4>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h5 id="normflows.flows.neural_spline.wrapper.AutoregressiveRationalQuadraticSpline" class="doc doc-heading">
            <code>AutoregressiveRationalQuadraticSpline</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Neural spline flow coupling layer, wrapper for the implementation
of Durkan et al., see <a href="https://github.com/bayesiains/nsf">sources</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AutoregressiveRationalQuadraticSpline</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Neural spline flow coupling layer, wrapper for the implementation</span>
<span class="sd">    of Durkan et al., see [sources](https://github.com/bayesiains/nsf)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_input_channels</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">num_hidden_channels</span><span class="p">,</span>
        <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">permute_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_input_channels (int): Flow dimension</span>
<span class="sd">          num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">          num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">          num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">          num_bins (int): Number of bins</span>
<span class="sd">          tail_bound (int): Bound of the spline tails</span>
<span class="sd">          activation (torch.nn.Module): Activation function</span>
<span class="sd">          dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">          permute_mask (bool): Flag, permutes the mask of the NN</span>
<span class="sd">          init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span> <span class="o">=</span> <span class="n">MaskedPiecewiseRationalQuadraticAutoregressive</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">num_input_channels</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
            <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
            <span class="n">tails</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
            <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">permute_mask</span><span class="o">=</span><span class="n">permute_mask</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">init_identity</span><span class="o">=</span><span class="n">init_identity</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.neural_spline.wrapper.AutoregressiveRationalQuadraticSpline.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">num_hidden_channels</span><span class="p">,</span> <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">tail_bound</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">permute_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_input_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flow dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_blocks</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of residual blocks of the parameter NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_hidden_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units of the NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_context_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of context/conditional channels</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of bins</p>
              </div>
            </td>
            <td>
                  <code>8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tail_bound</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bound of the spline tails</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>activation</code></td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dropout_probability</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout probability of the NN</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>permute_mask</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, permutes the mask of the NN</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_identity</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, initialize transform as identity</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_input_channels</span><span class="p">,</span>
    <span class="n">num_blocks</span><span class="p">,</span>
    <span class="n">num_hidden_channels</span><span class="p">,</span>
    <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">tail_bound</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">permute_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_input_channels (int): Flow dimension</span>
<span class="sd">      num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">      num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">      num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">      num_bins (int): Number of bins</span>
<span class="sd">      tail_bound (int): Bound of the spline tails</span>
<span class="sd">      activation (torch.nn.Module): Activation function</span>
<span class="sd">      dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">      permute_mask (bool): Flag, permutes the mask of the NN</span>
<span class="sd">      init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span> <span class="o">=</span> <span class="n">MaskedPiecewiseRationalQuadraticAutoregressive</span><span class="p">(</span>
        <span class="n">features</span><span class="o">=</span><span class="n">num_input_channels</span><span class="p">,</span>
        <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
        <span class="n">tails</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">permute_mask</span><span class="o">=</span><span class="n">permute_mask</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">init_identity</span><span class="o">=</span><span class="n">init_identity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.neural_spline.wrapper.CircularAutoregressiveRationalQuadraticSpline" class="doc doc-heading">
            <code>CircularAutoregressiveRationalQuadraticSpline</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Neural spline flow coupling layer, wrapper for the implementation
of Durkan et al., see <a href="https://github.com/bayesiains/nsf">sources</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CircularAutoregressiveRationalQuadraticSpline</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Neural spline flow coupling layer, wrapper for the implementation</span>
<span class="sd">    of Durkan et al., see [sources](https://github.com/bayesiains/nsf)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_input_channels</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">num_hidden_channels</span><span class="p">,</span>
        <span class="n">ind_circ</span><span class="p">,</span>
        <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">permute_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_input_channels (int): Flow dimension</span>
<span class="sd">          num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">          num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">          ind_circ (Iterable): Indices of the circular coordinates</span>
<span class="sd">          num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">          num_bins (int): Number of bins</span>
<span class="sd">          tail_bound (int): Bound of the spline tails</span>
<span class="sd">          activation (torch module): Activation function</span>
<span class="sd">          dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">          permute_mask (bool): Flag, permutes the mask of the NN</span>
<span class="sd">          init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">tails</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;circular&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind_circ</span> <span class="k">else</span> <span class="s2">&quot;linear&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span> <span class="o">=</span> <span class="n">MaskedPiecewiseRationalQuadraticAutoregressive</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">num_input_channels</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
            <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
            <span class="n">tails</span><span class="o">=</span><span class="n">tails</span><span class="p">,</span>
            <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">permute_mask</span><span class="o">=</span><span class="n">permute_mask</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">init_identity</span><span class="o">=</span><span class="n">init_identity</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.neural_spline.wrapper.CircularAutoregressiveRationalQuadraticSpline.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">num_hidden_channels</span><span class="p">,</span> <span class="n">ind_circ</span><span class="p">,</span> <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">tail_bound</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">permute_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_input_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flow dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_blocks</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of residual blocks of the parameter NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_hidden_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units of the NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ind_circ</code></td>
            <td>
                  <code>Iterable</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Indices of the circular coordinates</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_context_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of context/conditional channels</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of bins</p>
              </div>
            </td>
            <td>
                  <code>8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tail_bound</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bound of the spline tails</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>activation</code></td>
            <td>
                  <code>torch module</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dropout_probability</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout probability of the NN</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>permute_mask</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, permutes the mask of the NN</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_identity</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, initialize transform as identity</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_input_channels</span><span class="p">,</span>
    <span class="n">num_blocks</span><span class="p">,</span>
    <span class="n">num_hidden_channels</span><span class="p">,</span>
    <span class="n">ind_circ</span><span class="p">,</span>
    <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">tail_bound</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">permute_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_input_channels (int): Flow dimension</span>
<span class="sd">      num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">      num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">      ind_circ (Iterable): Indices of the circular coordinates</span>
<span class="sd">      num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">      num_bins (int): Number of bins</span>
<span class="sd">      tail_bound (int): Bound of the spline tails</span>
<span class="sd">      activation (torch module): Activation function</span>
<span class="sd">      dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">      permute_mask (bool): Flag, permutes the mask of the NN</span>
<span class="sd">      init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="n">tails</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;circular&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind_circ</span> <span class="k">else</span> <span class="s2">&quot;linear&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mprqat</span> <span class="o">=</span> <span class="n">MaskedPiecewiseRationalQuadraticAutoregressive</span><span class="p">(</span>
        <span class="n">features</span><span class="o">=</span><span class="n">num_input_channels</span><span class="p">,</span>
        <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
        <span class="n">tails</span><span class="o">=</span><span class="n">tails</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">permute_mask</span><span class="o">=</span><span class="n">permute_mask</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">init_identity</span><span class="o">=</span><span class="n">init_identity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.neural_spline.wrapper.CircularCoupledRationalQuadraticSpline" class="doc doc-heading">
            <code>CircularCoupledRationalQuadraticSpline</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Neural spline flow coupling layer with circular coordinates</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CircularCoupledRationalQuadraticSpline</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Neural spline flow coupling layer with circular coordinates</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_input_channels</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">num_hidden_channels</span><span class="p">,</span>
        <span class="n">ind_circ</span><span class="p">,</span>
        <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">reverse_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_input_channels (int): Flow dimension</span>
<span class="sd">          num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">          num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">          num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">          ind_circ (Iterable): Indices of the circular coordinates</span>
<span class="sd">          num_bins (int): Number of bins</span>
<span class="sd">          tail_bound (float or Iterable): Bound of the spline tails</span>
<span class="sd">          activation (torch module): Activation function</span>
<span class="sd">          dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">          reverse_mask (bool): Flag whether the reverse mask should be used</span>
<span class="sd">          mask (torch tensor): Mask to be used, alternating masked generated is None</span>
<span class="sd">          init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">create_alternating_binary_mask</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="n">reverse_mask</span><span class="p">)</span>
        <span class="n">features_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">)</span>
        <span class="n">identity_features</span> <span class="o">=</span> <span class="n">features_vector</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">ind_circ</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_circ</span><span class="p">)</span>
        <span class="n">ind_circ_id</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="nb">id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">identity_features</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">ind_circ</span><span class="p">:</span>
                <span class="n">ind_circ_id</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">tail_bound</span><span class="p">):</span>
            <span class="n">scale_pf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="n">tail_bound</span><span class="p">[</span><span class="n">ind_circ_id</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale_pf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="n">tail_bound</span>

        <span class="k">def</span> <span class="nf">transform_net_create_fn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind_circ_id</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">pf</span> <span class="o">=</span> <span class="n">PeriodicFeaturesElementwise</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">ind_circ_id</span><span class="p">,</span> <span class="n">scale_pf</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pf</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">ResidualNet</span><span class="p">(</span>
                <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
                <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
                <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
                <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
                <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
                <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
                <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">preprocessing</span><span class="o">=</span><span class="n">pf</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">init_identity</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span>
                    <span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">DEFAULT_MIN_DERIVATIVE</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">net</span>

        <span class="n">tails</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;circular&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind_circ</span> <span class="k">else</span> <span class="s2">&quot;linear&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span> <span class="o">=</span> <span class="n">PiecewiseRationalQuadraticCoupling</span><span class="p">(</span>
            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
            <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="n">transform_net_create_fn</span><span class="p">,</span>
            <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
            <span class="n">tails</span><span class="o">=</span><span class="n">tails</span><span class="p">,</span>
            <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
            <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.neural_spline.wrapper.CircularCoupledRationalQuadraticSpline.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">num_hidden_channels</span><span class="p">,</span> <span class="n">ind_circ</span><span class="p">,</span> <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">reverse_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_input_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flow dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_blocks</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of residual blocks of the parameter NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_hidden_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units of the NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_context_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of context/conditional channels</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ind_circ</code></td>
            <td>
                  <code>Iterable</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Indices of the circular coordinates</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of bins</p>
              </div>
            </td>
            <td>
                  <code>8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tail_bound</code></td>
            <td>
                  <code>float or Iterable</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bound of the spline tails</p>
              </div>
            </td>
            <td>
                  <code>3.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>activation</code></td>
            <td>
                  <code>torch module</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dropout_probability</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout probability of the NN</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>reverse_mask</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether the reverse mask should be used</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>mask</code></td>
            <td>
                  <code>torch tensor</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mask to be used, alternating masked generated is None</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_identity</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, initialize transform as identity</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_input_channels</span><span class="p">,</span>
    <span class="n">num_blocks</span><span class="p">,</span>
    <span class="n">num_hidden_channels</span><span class="p">,</span>
    <span class="n">ind_circ</span><span class="p">,</span>
    <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">reverse_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_input_channels (int): Flow dimension</span>
<span class="sd">      num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">      num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">      num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">      ind_circ (Iterable): Indices of the circular coordinates</span>
<span class="sd">      num_bins (int): Number of bins</span>
<span class="sd">      tail_bound (float or Iterable): Bound of the spline tails</span>
<span class="sd">      activation (torch module): Activation function</span>
<span class="sd">      dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">      reverse_mask (bool): Flag whether the reverse mask should be used</span>
<span class="sd">      mask (torch tensor): Mask to be used, alternating masked generated is None</span>
<span class="sd">      init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">create_alternating_binary_mask</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="n">reverse_mask</span><span class="p">)</span>
    <span class="n">features_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">)</span>
    <span class="n">identity_features</span> <span class="o">=</span> <span class="n">features_vector</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ind_circ</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_circ</span><span class="p">)</span>
    <span class="n">ind_circ_id</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="nb">id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">identity_features</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">ind_circ</span><span class="p">:</span>
            <span class="n">ind_circ_id</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">tail_bound</span><span class="p">):</span>
        <span class="n">scale_pf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="n">tail_bound</span><span class="p">[</span><span class="n">ind_circ_id</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scale_pf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="n">tail_bound</span>

    <span class="k">def</span> <span class="nf">transform_net_create_fn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind_circ_id</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pf</span> <span class="o">=</span> <span class="n">PeriodicFeaturesElementwise</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">ind_circ_id</span><span class="p">,</span> <span class="n">scale_pf</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pf</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">ResidualNet</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">preprocessing</span><span class="o">=</span><span class="n">pf</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">init_identity</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span>
                <span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">DEFAULT_MIN_DERIVATIVE</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>

    <span class="n">tails</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;circular&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind_circ</span> <span class="k">else</span> <span class="s2">&quot;linear&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span> <span class="o">=</span> <span class="n">PiecewiseRationalQuadraticCoupling</span><span class="p">(</span>
        <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
        <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="n">transform_net_create_fn</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
        <span class="n">tails</span><span class="o">=</span><span class="n">tails</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
        <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h5 id="normflows.flows.neural_spline.wrapper.CoupledRationalQuadraticSpline" class="doc doc-heading">
            <code>CoupledRationalQuadraticSpline</code>


</h5>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Neural spline flow coupling layer, wrapper for the implementation
of Durkan et al., see <a href="https://github.com/bayesiains/nsf">source</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CoupledRationalQuadraticSpline</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Neural spline flow coupling layer, wrapper for the implementation</span>
<span class="sd">    of Durkan et al., see [source](https://github.com/bayesiains/nsf)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_input_channels</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">num_hidden_channels</span><span class="p">,</span>
        <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">tails</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">reverse_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          num_input_channels (int): Flow dimension</span>
<span class="sd">          num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">          num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">          num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">          num_bins (int): Number of bins</span>
<span class="sd">          tails (str): Behaviour of the tails of the distribution, can be linear, circular for periodic distribution, or None for distribution on the compact interval</span>
<span class="sd">          tail_bound (float): Bound of the spline tails</span>
<span class="sd">          activation (torch module): Activation function</span>
<span class="sd">          dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">          reverse_mask (bool): Flag whether the reverse mask should be used</span>
<span class="sd">          init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">transform_net_create_fn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">ResidualNet</span><span class="p">(</span>
                <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
                <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
                <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
                <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
                <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
                <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
                <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">init_identity</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span>
                    <span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">DEFAULT_MIN_DERIVATIVE</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">net</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span> <span class="o">=</span> <span class="n">PiecewiseRationalQuadraticCoupling</span><span class="p">(</span>
            <span class="n">mask</span><span class="o">=</span><span class="n">create_alternating_binary_mask</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="n">reverse_mask</span><span class="p">),</span>
            <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="n">transform_net_create_fn</span><span class="p">,</span>
            <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
            <span class="n">tails</span><span class="o">=</span><span class="n">tails</span><span class="p">,</span>
            <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
            <span class="c1"># Setting True corresponds to equations (4), (5), (6) in the NSF paper:</span>
            <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h6 id="normflows.flows.neural_spline.wrapper.CoupledRationalQuadraticSpline.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">num_hidden_channels</span><span class="p">,</span> <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">tails</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">reverse_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h6>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_input_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flow dimension</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_blocks</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of residual blocks of the parameter NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_hidden_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units of the NN</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_context_channels</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of context/conditional channels</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of bins</p>
              </div>
            </td>
            <td>
                  <code>8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tails</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Behaviour of the tails of the distribution, can be linear, circular for periodic distribution, or None for distribution on the compact interval</p>
              </div>
            </td>
            <td>
                  <code>&#39;linear&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tail_bound</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bound of the spline tails</p>
              </div>
            </td>
            <td>
                  <code>3.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>activation</code></td>
            <td>
                  <code>torch module</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dropout_probability</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout probability of the NN</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>reverse_mask</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether the reverse mask should be used</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_identity</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, initialize transform as identity</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/neural_spline/wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_input_channels</span><span class="p">,</span>
    <span class="n">num_blocks</span><span class="p">,</span>
    <span class="n">num_hidden_channels</span><span class="p">,</span>
    <span class="n">num_context_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">tails</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">reverse_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">init_identity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      num_input_channels (int): Flow dimension</span>
<span class="sd">      num_blocks (int): Number of residual blocks of the parameter NN</span>
<span class="sd">      num_hidden_channels (int): Number of hidden units of the NN</span>
<span class="sd">      num_context_channels (int): Number of context/conditional channels</span>
<span class="sd">      num_bins (int): Number of bins</span>
<span class="sd">      tails (str): Behaviour of the tails of the distribution, can be linear, circular for periodic distribution, or None for distribution on the compact interval</span>
<span class="sd">      tail_bound (float): Bound of the spline tails</span>
<span class="sd">      activation (torch module): Activation function</span>
<span class="sd">      dropout_probability (float): Dropout probability of the NN</span>
<span class="sd">      reverse_mask (bool): Flag whether the reverse mask should be used</span>
<span class="sd">      init_identity (bool): Flag, initialize transform as identity</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">transform_net_create_fn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">ResidualNet</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">num_context_channels</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">num_hidden_channels</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">(),</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">init_identity</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span>
                <span class="n">net</span><span class="o">.</span><span class="n">final_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">DEFAULT_MIN_DERIVATIVE</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">prqct</span> <span class="o">=</span> <span class="n">PiecewiseRationalQuadraticCoupling</span><span class="p">(</span>
        <span class="n">mask</span><span class="o">=</span><span class="n">create_alternating_binary_mask</span><span class="p">(</span><span class="n">num_input_channels</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="n">reverse_mask</span><span class="p">),</span>
        <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="n">transform_net_create_fn</span><span class="p">,</span>
        <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
        <span class="n">tails</span><span class="o">=</span><span class="n">tails</span><span class="p">,</span>
        <span class="n">tail_bound</span><span class="o">=</span><span class="n">tail_bound</span><span class="p">,</span>
        <span class="c1"># Setting True corresponds to equations (4), (5), (6) in the NSF paper:</span>
        <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>


  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.normalization" class="doc doc-heading">
            <code>normalization</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.normalization.ActNorm" class="doc doc-heading">
            <code>ActNorm</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.affine.coupling.AffineConstFlow" href="#normflows.flows.affine.coupling.AffineConstFlow">AffineConstFlow</a></code></p>


      <p>An AffineConstFlow but with a data-dependent initialization,
where on the very first batch we clever initialize the s,t so that the output
is unit gaussian. As described in Glow paper.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/normalization.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ActNorm</span><span class="p">(</span><span class="n">AffineConstFlow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An AffineConstFlow but with a data-dependent initialization,</span>
<span class="sd">    where on the very first batch we clever initialize the s,t so that the output</span>
<span class="sd">    is unit gaussian. As described in Glow paper.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_dep_init_done_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;data_dep_init_done&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_dep_init_done_cpu</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># first batch is used for initialization, c.f. batchnorm</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_dep_init_done</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">s_init</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">s_init</span><span class="o">.</span><span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
                <span class="o">-</span><span class="n">z</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_dep_init_done</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># first batch is used for initialization, c.f. batchnorm</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_dep_init_done</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">s_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">s_init</span><span class="o">.</span><span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_dep_init_done</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.normalization.BatchNorm" class="doc doc-heading">
            <code>BatchNorm</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Batch Normalization with out considering the derivatives of the batch statistics, see <a href="https://arxiv.org/abs/1605.08803">arXiv: 1605.08803</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/normalization.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BatchNorm</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Batch Normalization with out considering the derivatives of the batch statistics, see [arXiv: 1605.08803](https://arxiv.org/abs/1605.08803)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;eps&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps_cpu</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Do batch norm over batch and sample dimension</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">std</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">std</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)))</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
            <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.normalization.BatchNorm.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Do batch norm over batch and sample dimension</p>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Do batch norm over batch and sample dimension</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">z_</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">std</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">std</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)))</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
        <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.periodic" class="doc doc-heading">
            <code>periodic</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.periodic.PeriodicShift" class="doc doc-heading">
            <code>PeriodicShift</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Shift and wrap periodic coordinates</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/periodic.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PeriodicShift</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shift and wrap periodic coordinates</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          ind: Iterable, indices of coordinates to be mapped</span>
<span class="sd">          bound: Float or iterable, bound of interval</span>
<span class="sd">          shift: Tensor, shift to be applied</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ind</span> <span class="o">=</span> <span class="n">ind</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">bound</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;bound&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bound</span> <span class="o">=</span> <span class="n">bound</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">shift</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;shift&quot;</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">z_</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span><span class="p">)</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">z_</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span><span class="p">)</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.periodic.PeriodicShift.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>ind</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Iterable, indices of coordinates to be mapped</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bound</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Float or iterable, bound of interval</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>shift</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor, shift to be applied</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/periodic.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      ind: Iterable, indices of coordinates to be mapped</span>
<span class="sd">      bound: Float or iterable, bound of interval</span>
<span class="sd">      shift: Tensor, shift to be applied</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ind</span> <span class="o">=</span> <span class="n">ind</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">bound</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;bound&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bound</span> <span class="o">=</span> <span class="n">bound</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">shift</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;shift&quot;</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.periodic.PeriodicWrap" class="doc doc-heading">
            <code>PeriodicWrap</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Map periodic coordinates to fixed interval</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/periodic.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PeriodicWrap</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Map periodic coordinates to fixed interval</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        ind: Iterable, indices of coordinates to be mapped</span>
<span class="sd">        bound: Float or iterable, bound of interval</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ind</span> <span class="o">=</span> <span class="n">ind</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">bound</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;bound&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bound</span> <span class="o">=</span> <span class="n">bound</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">z_</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">z_</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">bound</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.periodic.PeriodicWrap.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>
<p>ind: Iterable, indices of coordinates to be mapped
bound: Float or iterable, bound of interval</p>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/periodic.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    ind: Iterable, indices of coordinates to be mapped</span>
<span class="sd">    bound: Float or iterable, bound of interval</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ind</span> <span class="o">=</span> <span class="n">ind</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">bound</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;bound&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bound</span> <span class="o">=</span> <span class="n">bound</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.planar" class="doc doc-heading">
            <code>planar</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.planar.Planar" class="doc doc-heading">
            <code>Planar</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Planar flow as introduced in <a href="https://arxiv.org/abs/1505.05770">arXiv: 1505.05770</a></p>
<pre><code>    f(z) = z + u * h(w * z + b)
</code></pre>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/planar.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Planar</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Planar flow as introduced in [arXiv: 1505.05770](https://arxiv.org/abs/1505.05770)</span>

<span class="sd">    ```</span>
<span class="sd">        f(z) = z + u * h(w * z + b)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor of the planar flow</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: shape of the latent variable z</span>
<span class="sd">          h: nonlinear function h of the planar flow (see definition of f above)</span>
<span class="sd">          u,w,b: optional initialization for parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">lim_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="n">lim_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">,</span> <span class="o">-</span><span class="n">lim_u</span><span class="p">,</span> <span class="n">lim_u</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="o">-</span><span class="n">lim_w</span><span class="p">,</span> <span class="n">lim_w</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">act</span>
        <span class="k">if</span> <span class="n">act</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span>
        <span class="k">elif</span> <span class="n">act</span> <span class="o">==</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Nonlinearity is not implemented.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">lin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">z</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">dim</span><span class="p">())),</span>
                        <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">+</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inner</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">inner</span><span class="p">)</span> \
            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># constraint w.T * u &gt; -1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span><span class="p">:</span>
            <span class="n">h_</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">==</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">:</span>
            <span class="n">h_</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">negative_slope</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span>

        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">(</span><span class="n">lin</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">u</span><span class="p">)</span> <span class="o">*</span> <span class="n">h_</span><span class="p">(</span><span class="n">lin</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))))</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">!=</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This flow has no algebraic inverse.&quot;</span><span class="p">)</span>
        <span class="n">lin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">z</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
        <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="n">lin</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">negative_slope</span> <span class="o">-</span> <span class="mf">1.0</span>
        <span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span>  <span class="c1"># absorb leakyReLU slope into u</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">+</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inner</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">inner</span><span class="p">)</span> \
            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">dims</span><span class="p">)</span> <span class="o">*</span> <span class="n">u</span>
        <span class="n">inner_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">u</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">dim</span><span class="p">())))</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">u</span> <span class="o">*</span> <span class="p">(</span><span class="n">lin</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">inner_</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">dims</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">inner_</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.planar.Planar.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor of the planar flow</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>shape of the latent variable z</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>h</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>nonlinear function h of the planar flow (see definition of f above)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>u,w,b</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>optional initialization for parameters</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/planar.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor of the planar flow</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: shape of the latent variable z</span>
<span class="sd">      h: nonlinear function h of the planar flow (see definition of f above)</span>
<span class="sd">      u,w,b: optional initialization for parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">lim_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">lim_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">,</span> <span class="o">-</span><span class="n">lim_u</span><span class="p">,</span> <span class="n">lim_u</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="o">-</span><span class="n">lim_w</span><span class="p">,</span> <span class="n">lim_w</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">act</span>
    <span class="k">if</span> <span class="n">act</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span>
    <span class="k">elif</span> <span class="n">act</span> <span class="o">==</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Nonlinearity is not implemented.&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.radial" class="doc doc-heading">
            <code>radial</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.radial.Radial" class="doc doc-heading">
            <code>Radial</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Radial flow as introduced in <a href="https://arxiv.org/abs/1505.05770">arXiv: 1505.05770</a></p>
<pre><code>    f(z) = z + beta * h(alpha, r) * (z - z_0)
</code></pre>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/radial.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Radial</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Radial flow as introduced in [arXiv: 1505.05770](https://arxiv.org/abs/1505.05770)</span>

<span class="sd">    ```</span>
<span class="sd">        f(z) = z + beta * h(alpha, r) * (z - z_0)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">z_0</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor of the radial flow</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: shape of the latent variable z</span>
<span class="sd">          z_0: parameter of the radial flow</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_cpu</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">lim</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="o">-</span><span class="n">lim</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">lim</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="o">-</span><span class="n">lim</span><span class="p">,</span> <span class="n">lim</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">z_0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">z_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">z_0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">z_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">))</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">dz</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_0</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">(</span><span class="n">dz</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_0</span><span class="o">.</span><span class="n">dim</span><span class="p">())),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">h_arr</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">h_arr_</span> <span class="o">=</span> <span class="o">-</span><span class="n">beta</span> <span class="o">*</span> <span class="n">r</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">h_arr</span> <span class="o">*</span> <span class="n">dz</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">h_arr</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">h_arr</span> <span class="o">+</span> <span class="n">h_arr_</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">log_det</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.radial.Radial.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">z_0</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor of the radial flow</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>shape of the latent variable z</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>z_0</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>parameter of the radial flow</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/radial.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">z_0</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor of the radial flow</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: shape of the latent variable z</span>
<span class="sd">      z_0: parameter of the radial flow</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_cpu</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">lim</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="o">-</span><span class="n">lim</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">lim</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="o">-</span><span class="n">lim</span><span class="p">,</span> <span class="n">lim</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">z_0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">z_0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">)[</span><span class="kc">None</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.reshape" class="doc doc-heading">
            <code>reshape</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.reshape.Merge" class="doc doc-heading">
            <code>Merge</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.reshape.Split" href="#normflows.flows.reshape.Split">Split</a></code></p>


      <p>Same as Split but with forward and backward pass interchanged</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/reshape.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Merge</span><span class="p">(</span><span class="n">Split</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Same as Split but with forward and backward pass interchanged</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;channel&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.reshape.Split" class="doc doc-heading">
            <code>Split</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Split features into two sets</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/reshape.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Split</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Split features into two sets</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;channel&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        The splitting mode can be:</span>

<span class="sd">        - channel: Splits first feature dimension, usually channels, into two halfs</span>
<span class="sd">        - channel_inv: Same as channel, but with z1 and z2 flipped</span>
<span class="sd">        - checkerboard: Splits features using a checkerboard pattern (last feature dimension must be even)</span>
<span class="sd">        - checkerboard_inv: Same as checkerboard, but with inverted coloring</span>

<span class="sd">        Args:</span>
<span class="sd">         mode: splitting mode</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;channel&quot;</span><span class="p">:</span>
            <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;channel_inv&quot;</span><span class="p">:</span>
            <span class="n">z2</span><span class="p">,</span> <span class="n">z1</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;checkerboard&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span>
            <span class="n">n_dims</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
            <span class="n">cb0</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cb1</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">):</span>
                <span class="n">cb0_</span> <span class="o">=</span> <span class="n">cb0</span>
                <span class="n">cb1_</span> <span class="o">=</span> <span class="n">cb1</span>
                <span class="n">cb0</span> <span class="o">=</span> <span class="p">[</span><span class="n">cb0_</span> <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">cb1_</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">n_dims</span> <span class="o">-</span> <span class="n">i</span><span class="p">))]</span>
                <span class="n">cb1</span> <span class="o">=</span> <span class="p">[</span><span class="n">cb1_</span> <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">cb0_</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">n_dims</span> <span class="o">-</span> <span class="n">i</span><span class="p">))]</span>
            <span class="n">cb</span> <span class="o">=</span> <span class="n">cb1</span> <span class="k">if</span> <span class="s2">&quot;inv&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="k">else</span> <span class="n">cb0</span>
            <span class="n">cb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">cb</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="o">*</span><span class="p">((</span><span class="n">n_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">cb</span> <span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">z_size</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
            <span class="n">z1</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="o">*</span><span class="n">z_size</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cb</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="o">*</span><span class="n">z_size</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Mode &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">+</span> <span class="s2">&quot; is not implemented.&quot;</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;channel&quot;</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;channel_inv&quot;</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z2</span><span class="p">,</span> <span class="n">z1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;checkerboard&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span>
            <span class="n">n_dims</span> <span class="o">=</span> <span class="n">z1</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
            <span class="n">z_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">z1</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
            <span class="n">z_size</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">2</span>
            <span class="n">cb0</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cb1</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">):</span>
                <span class="n">cb0_</span> <span class="o">=</span> <span class="n">cb0</span>
                <span class="n">cb1_</span> <span class="o">=</span> <span class="n">cb1</span>
                <span class="n">cb0</span> <span class="o">=</span> <span class="p">[</span><span class="n">cb0_</span> <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">cb1_</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">z_size</span><span class="p">[</span><span class="n">n_dims</span> <span class="o">-</span> <span class="n">i</span><span class="p">])]</span>
                <span class="n">cb1</span> <span class="o">=</span> <span class="p">[</span><span class="n">cb1_</span> <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">cb0_</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">z_size</span><span class="p">[</span><span class="n">n_dims</span> <span class="o">-</span> <span class="n">i</span><span class="p">])]</span>
            <span class="n">cb</span> <span class="o">=</span> <span class="n">cb1</span> <span class="k">if</span> <span class="s2">&quot;inv&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="k">else</span> <span class="n">cb0</span>
            <span class="n">cb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">cb</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">z_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">((</span><span class="n">n_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">cb</span> <span class="o">=</span> <span class="n">cb</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z1</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">z1</span> <span class="o">=</span> <span class="n">z1</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">n_dims</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">z_size</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">z2</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">n_dims</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">z_size</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">cb</span> <span class="o">*</span> <span class="n">z1</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cb</span><span class="p">)</span> <span class="o">*</span> <span class="n">z2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Mode &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">+</span> <span class="s2">&quot; is not implemented.&quot;</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.reshape.Split.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;channel&#39;</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>
<p>The splitting mode can be:</p>
<ul>
<li>channel: Splits first feature dimension, usually channels, into two halfs</li>
<li>channel_inv: Same as channel, but with z1 and z2 flipped</li>
<li>checkerboard: Splits features using a checkerboard pattern (last feature dimension must be even)</li>
<li>checkerboard_inv: Same as checkerboard, but with inverted coloring</li>
</ul>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>mode</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>splitting mode</p>
              </div>
            </td>
            <td>
                  <code>&#39;channel&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/reshape.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;channel&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    The splitting mode can be:</span>

<span class="sd">    - channel: Splits first feature dimension, usually channels, into two halfs</span>
<span class="sd">    - channel_inv: Same as channel, but with z1 and z2 flipped</span>
<span class="sd">    - checkerboard: Splits features using a checkerboard pattern (last feature dimension must be even)</span>
<span class="sd">    - checkerboard_inv: Same as checkerboard, but with inverted coloring</span>

<span class="sd">    Args:</span>
<span class="sd">     mode: splitting mode</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.reshape.Squeeze" class="doc doc-heading">
            <code>Squeeze</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Squeeze operation of multi-scale architecture, RealNVP or Glow paper</p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/reshape.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Squeeze</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Squeeze operation of multi-scale architecture, RealNVP or Glow paper</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">s</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.reshape.Squeeze.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">()</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/reshape.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.residual" class="doc doc-heading">
            <code>residual</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.residual.Residual" class="doc doc-heading">
            <code>Residual</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Invertible residual net block, wrapper to the implementation of Chen et al.,
see <a href="https://github.com/rtqichen/residual-flows">sources</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/residual.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Residual</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invertible residual net block, wrapper to the implementation of Chen et al.,</span>
<span class="sd">    see [sources](https://github.com/rtqichen/residual-flows)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">net</span><span class="p">,</span>
        <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">reduce_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">geom_p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lamb</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
        <span class="n">n_power_series</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">exact_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">brute_force</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_exact_terms</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">n_dist</span><span class="o">=</span><span class="s2">&quot;geometric&quot;</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          net: Neural network, must be Lipschitz continuous with L &lt; 1</span>
<span class="sd">          reverse: Flag, if true the map ```f(x) = x + net(x)``` is applied in the inverse pass, otherwise it is done in forward</span>
<span class="sd">          reduce_memory: Flag, if true Neumann series and precomputations, for backward pass in forward pass are done</span>
<span class="sd">          geom_p: Parameter of the geometric distribution used for the Neumann series</span>
<span class="sd">          lamb: Parameter of the geometric distribution used for the Neumann series</span>
<span class="sd">          n_power_series: Number of terms in the Neumann series</span>
<span class="sd">          exact_trace: Flag, if true the trace of the Jacobian is computed exactly</span>
<span class="sd">          brute_force: Flag, if true the Jacobian is computed exactly in 2D</span>
<span class="sd">          n_samples: Number of samples used to estimate power series</span>
<span class="sd">          n_exact_terms: Number of terms always included in the power series</span>
<span class="sd">          n_dist: Distribution used for the power series, either &quot;geometric&quot; or &quot;poisson&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reverse</span> <span class="o">=</span> <span class="n">reverse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iresblock</span> <span class="o">=</span> <span class="n">iResBlock</span><span class="p">(</span>
            <span class="n">net</span><span class="p">,</span>
            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
            <span class="n">n_exact_terms</span><span class="o">=</span><span class="n">n_exact_terms</span><span class="p">,</span>
            <span class="n">neumann_grad</span><span class="o">=</span><span class="n">reduce_memory</span><span class="p">,</span>
            <span class="n">grad_in_forward</span><span class="o">=</span><span class="n">reduce_memory</span><span class="p">,</span>
            <span class="n">exact_trace</span><span class="o">=</span><span class="n">exact_trace</span><span class="p">,</span>
            <span class="n">geom_p</span><span class="o">=</span><span class="n">geom_p</span><span class="p">,</span>
            <span class="n">lamb</span><span class="o">=</span><span class="n">lamb</span><span class="p">,</span>
            <span class="n">n_power_series</span><span class="o">=</span><span class="n">n_power_series</span><span class="p">,</span>
            <span class="n">brute_force</span><span class="o">=</span><span class="n">brute_force</span><span class="p">,</span>
            <span class="n">n_dist</span><span class="o">=</span><span class="n">n_dist</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iresblock</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iresblock</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="o">-</span><span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iresblock</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iresblock</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="o">-</span><span class="n">log_det</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.residual.Residual.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">geom_p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">n_power_series</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exact_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">brute_force</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_exact_terms</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_dist</span><span class="o">=</span><span class="s1">&#39;geometric&#39;</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>net</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neural network, must be Lipschitz continuous with L &lt; 1</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>reverse</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, if true the map <code>f(x) = x + net(x)</code> is applied in the inverse pass, otherwise it is done in forward</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>reduce_memory</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, if true Neumann series and precomputations, for backward pass in forward pass are done</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>geom_p</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Parameter of the geometric distribution used for the Neumann series</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>lamb</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Parameter of the geometric distribution used for the Neumann series</p>
              </div>
            </td>
            <td>
                  <code>2.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_power_series</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of terms in the Neumann series</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>exact_trace</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, if true the trace of the Jacobian is computed exactly</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>brute_force</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, if true the Jacobian is computed exactly in 2D</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples used to estimate power series</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_exact_terms</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of terms always included in the power series</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_dist</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Distribution used for the power series, either "geometric" or "poisson"</p>
              </div>
            </td>
            <td>
                  <code>&#39;geometric&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/residual.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">net</span><span class="p">,</span>
    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">reduce_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">geom_p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">lamb</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="n">n_power_series</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exact_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">brute_force</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_exact_terms</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_dist</span><span class="o">=</span><span class="s2">&quot;geometric&quot;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      net: Neural network, must be Lipschitz continuous with L &lt; 1</span>
<span class="sd">      reverse: Flag, if true the map ```f(x) = x + net(x)``` is applied in the inverse pass, otherwise it is done in forward</span>
<span class="sd">      reduce_memory: Flag, if true Neumann series and precomputations, for backward pass in forward pass are done</span>
<span class="sd">      geom_p: Parameter of the geometric distribution used for the Neumann series</span>
<span class="sd">      lamb: Parameter of the geometric distribution used for the Neumann series</span>
<span class="sd">      n_power_series: Number of terms in the Neumann series</span>
<span class="sd">      exact_trace: Flag, if true the trace of the Jacobian is computed exactly</span>
<span class="sd">      brute_force: Flag, if true the Jacobian is computed exactly in 2D</span>
<span class="sd">      n_samples: Number of samples used to estimate power series</span>
<span class="sd">      n_exact_terms: Number of terms always included in the power series</span>
<span class="sd">      n_dist: Distribution used for the power series, either &quot;geometric&quot; or &quot;poisson&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reverse</span> <span class="o">=</span> <span class="n">reverse</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">iresblock</span> <span class="o">=</span> <span class="n">iResBlock</span><span class="p">(</span>
        <span class="n">net</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
        <span class="n">n_exact_terms</span><span class="o">=</span><span class="n">n_exact_terms</span><span class="p">,</span>
        <span class="n">neumann_grad</span><span class="o">=</span><span class="n">reduce_memory</span><span class="p">,</span>
        <span class="n">grad_in_forward</span><span class="o">=</span><span class="n">reduce_memory</span><span class="p">,</span>
        <span class="n">exact_trace</span><span class="o">=</span><span class="n">exact_trace</span><span class="p">,</span>
        <span class="n">geom_p</span><span class="o">=</span><span class="n">geom_p</span><span class="p">,</span>
        <span class="n">lamb</span><span class="o">=</span><span class="n">lamb</span><span class="p">,</span>
        <span class="n">n_power_series</span><span class="o">=</span><span class="n">n_power_series</span><span class="p">,</span>
        <span class="n">brute_force</span><span class="o">=</span><span class="n">brute_force</span><span class="p">,</span>
        <span class="n">n_dist</span><span class="o">=</span><span class="n">n_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.residual.iResBlock" class="doc doc-heading">
            <code>iResBlock</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


              <details class="quote">
                <summary>Source code in <code>normflows/flows/residual.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">iResBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nnet</span><span class="p">,</span>
        <span class="n">geom_p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lamb</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
        <span class="n">n_power_series</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">exact_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">brute_force</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_exact_terms</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">n_dist</span><span class="o">=</span><span class="s2">&quot;geometric&quot;</span><span class="p">,</span>
        <span class="n">neumann_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">grad_in_forward</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            nnet: a nn.Module</span>
<span class="sd">            n_power_series: number of power series. If not None, uses a biased approximation to logdet.</span>
<span class="sd">            exact_trace: if False, uses a Hutchinson trace estimator. Otherwise computes the exact full Jacobian.</span>
<span class="sd">            brute_force: Computes the exact logdet. Only available for 2D inputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">nnet</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dist</span> <span class="o">=</span> <span class="n">n_dist</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">geom_p</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">geom_p</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">geom_p</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lamb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lamb</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_power_series</span> <span class="o">=</span> <span class="n">n_power_series</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exact_trace</span> <span class="o">=</span> <span class="n">exact_trace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">brute_force</span> <span class="o">=</span> <span class="n">brute_force</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_exact_terms</span> <span class="o">=</span> <span class="n">n_exact_terms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_in_forward</span> <span class="o">=</span> <span class="n">grad_in_forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neumann_grad</span> <span class="o">=</span> <span class="n">neumann_grad</span>

        <span class="c1"># store the samples of n.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;last_n_samples&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;last_firmom&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;last_secmom&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">logpx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">logpx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">logdetgrad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logdetgrad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">g</span><span class="p">,</span> <span class="n">logpx</span> <span class="o">-</span> <span class="n">logdetgrad</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">logpy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_fixed_point</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">logpy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">logpy</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logdetgrad</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_inverse_fixed_point</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">x_prev</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">y</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="n">atol</span> <span class="o">+</span> <span class="n">y</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">*</span> <span class="n">rtol</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_prev</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">tol</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">x_prev</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">_logdetgrad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns g(x) and ```logdet|d(x+g(x))/dx|```&quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">brute_force</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="n">x</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
            <span class="p">):</span>
                <span class="c1">###########################################</span>
                <span class="c1"># Brute-force compute Jacobian determinant.</span>
                <span class="c1">###########################################</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="c1"># Brute-force logdet only available for 2D.</span>
                <span class="n">jac</span> <span class="o">=</span> <span class="n">batch_jacobian</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                <span class="n">batch_dets</span> <span class="o">=</span> <span class="p">(</span><span class="n">jac</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">jac</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">jac</span><span class="p">[</span>
                    <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
                <span class="p">]</span> <span class="o">*</span> <span class="n">jac</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">g</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">batch_dets</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dist</span> <span class="o">==</span> <span class="s2">&quot;geometric&quot;</span><span class="p">:</span>
                <span class="n">geom_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">geom_p</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">sample_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">geometric_sample</span><span class="p">(</span><span class="n">geom_p</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
                <span class="n">rcdf_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">k</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="n">geometric_1mcdf</span><span class="p">(</span><span class="n">geom_p</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dist</span> <span class="o">==</span> <span class="s2">&quot;poisson&quot;</span><span class="p">:</span>
                <span class="n">lamb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lamb</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">sample_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">poisson_sample</span><span class="p">(</span><span class="n">lamb</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
                <span class="n">rcdf_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">k</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="n">poisson_1mcdf</span><span class="p">(</span><span class="n">lamb</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_power_series</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Unbiased estimation.</span>
                    <span class="n">lamb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lamb</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">sample_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">)</span>
                    <span class="n">n_power_series</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_exact_terms</span>
                    <span class="n">coeff_fn</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="mi">1</span>
                        <span class="o">/</span> <span class="n">rcdf_fn</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_exact_terms</span><span class="p">)</span>
                        <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">&gt;=</span> <span class="n">k</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_exact_terms</span><span class="p">)</span>
                        <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Truncated estimation.</span>
                    <span class="n">n_power_series</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_power_series</span>
                    <span class="n">coeff_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="mf">1.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Unbiased estimation with more exact terms.</span>
                <span class="n">lamb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lamb</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">n_samples</span> <span class="o">=</span> <span class="n">sample_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">)</span>
                <span class="n">n_power_series</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">+</span> <span class="mi">20</span>
                <span class="n">coeff_fn</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="mi">1</span>
                    <span class="o">/</span> <span class="n">rcdf_fn</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
                    <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">&gt;=</span> <span class="n">k</span> <span class="o">-</span> <span class="mi">20</span><span class="p">)</span>
                    <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">exact_trace</span><span class="p">:</span>
                <span class="c1">####################################</span>
                <span class="c1"># Power series with trace estimator.</span>
                <span class="c1">####################################</span>
                <span class="n">vareps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

                <span class="c1"># Choose the type of estimator.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">neumann_grad</span><span class="p">:</span>
                    <span class="n">estimator_fn</span> <span class="o">=</span> <span class="n">neumann_logdet_estimator</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">estimator_fn</span> <span class="o">=</span> <span class="n">basic_logdet_estimator</span>

                <span class="c1"># Do backprop-in-forward to save memory.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_in_forward</span><span class="p">:</span>
                    <span class="n">g</span><span class="p">,</span> <span class="n">logdetgrad</span> <span class="o">=</span> <span class="n">mem_eff_wrapper</span><span class="p">(</span>
                        <span class="n">estimator_fn</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">,</span>
                        <span class="n">x</span><span class="p">,</span>
                        <span class="n">n_power_series</span><span class="p">,</span>
                        <span class="n">vareps</span><span class="p">,</span>
                        <span class="n">coeff_fn</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="n">logdetgrad</span> <span class="o">=</span> <span class="n">estimator_fn</span><span class="p">(</span>
                        <span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_power_series</span><span class="p">,</span> <span class="n">vareps</span><span class="p">,</span> <span class="n">coeff_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">############################################</span>
                <span class="c1"># Power series with exact trace computation.</span>
                <span class="c1">############################################</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">jac</span> <span class="o">=</span> <span class="n">batch_jacobian</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                <span class="n">logdetgrad</span> <span class="o">=</span> <span class="n">batch_trace</span><span class="p">(</span><span class="n">jac</span><span class="p">)</span>
                <span class="n">jac_k</span> <span class="o">=</span> <span class="n">jac</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_power_series</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">jac_k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">jac</span><span class="p">,</span> <span class="n">jac_k</span><span class="p">)</span>
                    <span class="n">logdetgrad</span> <span class="o">=</span> <span class="n">logdetgrad</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">k</span> <span class="o">*</span> <span class="n">coeff_fn</span><span class="p">(</span>
                        <span class="n">k</span>
                    <span class="p">)</span> <span class="o">*</span> <span class="n">batch_trace</span><span class="p">(</span><span class="n">jac_k</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_power_series</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">last_n_samples</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_n_samples</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">estimator</span> <span class="o">=</span> <span class="n">logdetgrad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">last_firmom</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_firmom</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">last_secmom</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">estimator</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_secmom</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">g</span><span class="p">,</span> <span class="n">logdetgrad</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;dist=</span><span class="si">{}</span><span class="s2">, n_samples=</span><span class="si">{}</span><span class="s2">, n_power_series=</span><span class="si">{}</span><span class="s2">, neumann_grad=</span><span class="si">{}</span><span class="s2">, exact_trace=</span><span class="si">{}</span><span class="s2">, brute_force=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_dist</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_power_series</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">neumann_grad</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exact_trace</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">brute_force</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.residual.iResBlock.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">nnet</span><span class="p">,</span> <span class="n">geom_p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">n_power_series</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exact_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">brute_force</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_exact_terms</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_dist</span><span class="o">=</span><span class="s1">&#39;geometric&#39;</span><span class="p">,</span> <span class="n">neumann_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">grad_in_forward</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>nnet</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>a nn.Module</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_power_series</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of power series. If not None, uses a biased approximation to logdet.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>exact_trace</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>if False, uses a Hutchinson trace estimator. Otherwise computes the exact full Jacobian.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>brute_force</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computes the exact logdet. Only available for 2D inputs.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/residual.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">nnet</span><span class="p">,</span>
    <span class="n">geom_p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">lamb</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="n">n_power_series</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exact_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">brute_force</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_exact_terms</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_dist</span><span class="o">=</span><span class="s2">&quot;geometric&quot;</span><span class="p">,</span>
    <span class="n">neumann_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">grad_in_forward</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        nnet: a nn.Module</span>
<span class="sd">        n_power_series: number of power series. If not None, uses a biased approximation to logdet.</span>
<span class="sd">        exact_trace: if False, uses a Hutchinson trace estimator. Otherwise computes the exact full Jacobian.</span>
<span class="sd">        brute_force: Computes the exact logdet. Only available for 2D inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">nnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_dist</span> <span class="o">=</span> <span class="n">n_dist</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">geom_p</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">geom_p</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">geom_p</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lamb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lamb</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_power_series</span> <span class="o">=</span> <span class="n">n_power_series</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">exact_trace</span> <span class="o">=</span> <span class="n">exact_trace</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">brute_force</span> <span class="o">=</span> <span class="n">brute_force</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_exact_terms</span> <span class="o">=</span> <span class="n">n_exact_terms</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">grad_in_forward</span> <span class="o">=</span> <span class="n">grad_in_forward</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">neumann_grad</span> <span class="o">=</span> <span class="n">neumann_grad</span>

    <span class="c1"># store the samples of n.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;last_n_samples&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;last_firmom&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;last_secmom&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.flows.stochastic" class="doc doc-heading">
            <code>stochastic</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.flows.stochastic.HamiltonianMonteCarlo" class="doc doc-heading">
            <code>HamiltonianMonteCarlo</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Flow layer using the HMC proposal in Stochastic Normalising Flows</p>
<p>See <a href="https://arxiv.org/abs/2002.06707">arXiv: 2002.06707</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/stochastic.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">HamiltonianMonteCarlo</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Flow layer using the HMC proposal in Stochastic Normalising Flows</span>

<span class="sd">    See [arXiv: 2002.06707](https://arxiv.org/abs/2002.06707)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">log_step_size</span><span class="p">,</span> <span class="n">log_mass</span><span class="p">,</span> <span class="n">max_abs_grad</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          target: The stationary distribution of this Markov transition, i.e. the target distribution to sample from.</span>
<span class="sd">          steps: The number of leapfrog steps</span>
<span class="sd">          log_step_size: The log step size used in the leapfrog integrator. shape (dim)</span>
<span class="sd">          log_mass: The log_mass determining the variance of the momentum samples. shape (dim)</span>
<span class="sd">          max_abs_grad: Maximum absolute value of the gradient of the target distribution&#39;s log probability. If set to None then no gradient clipping is applied. Useful for improving numerical stability.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">=</span> <span class="n">steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;log_step_size&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">log_step_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;log_mass&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">log_mass</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_abs_grad</span> <span class="o">=</span> <span class="n">max_abs_grad</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># Draw momentum</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_mass</span><span class="p">)</span>

        <span class="c1"># leapfrog</span>
        <span class="n">z_new</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">p_new</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">step_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_step_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">p_half</span> <span class="o">=</span> <span class="n">p_new</span> <span class="o">-</span> <span class="p">(</span><span class="n">step_size</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">gradlogP</span><span class="p">(</span><span class="n">z_new</span><span class="p">)</span>
            <span class="n">z_new</span> <span class="o">=</span> <span class="n">z_new</span> <span class="o">+</span> <span class="n">step_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">p_half</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mass</span><span class="p">))</span>
            <span class="n">p_new</span> <span class="o">=</span> <span class="n">p_half</span> <span class="o">-</span> <span class="p">(</span><span class="n">step_size</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">gradlogP</span><span class="p">(</span><span class="n">z_new</span><span class="p">)</span>

        <span class="c1"># Metropolis Hastings correction</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_new</span><span class="p">)</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p_new</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mass</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mass</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">uniforms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">uniforms</span> <span class="o">&lt;</span> <span class="n">probabilities</span>
        <span class="n">z_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">z_new</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">z_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">gradlogP</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="n">logp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">logp</span><span class="p">,</span> <span class="n">z_</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logp</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_abs_grad</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_abs_grad</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_abs_grad</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">grad</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.stochastic.HamiltonianMonteCarlo.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">log_step_size</span><span class="p">,</span> <span class="n">log_mass</span><span class="p">,</span> <span class="n">max_abs_grad</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>target</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The stationary distribution of this Markov transition, i.e. the target distribution to sample from.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>steps</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of leapfrog steps</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>log_step_size</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The log step size used in the leapfrog integrator. shape (dim)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>log_mass</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The log_mass determining the variance of the momentum samples. shape (dim)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>max_abs_grad</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum absolute value of the gradient of the target distribution's log probability. If set to None then no gradient clipping is applied. Useful for improving numerical stability.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/stochastic.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">log_step_size</span><span class="p">,</span> <span class="n">log_mass</span><span class="p">,</span> <span class="n">max_abs_grad</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      target: The stationary distribution of this Markov transition, i.e. the target distribution to sample from.</span>
<span class="sd">      steps: The number of leapfrog steps</span>
<span class="sd">      log_step_size: The log step size used in the leapfrog integrator. shape (dim)</span>
<span class="sd">      log_mass: The log_mass determining the variance of the momentum samples. shape (dim)</span>
<span class="sd">      max_abs_grad: Maximum absolute value of the gradient of the target distribution&#39;s log probability. If set to None then no gradient clipping is applied. Useful for improving numerical stability.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">=</span> <span class="n">steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;log_step_size&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">log_step_size</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;log_mass&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">log_mass</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_abs_grad</span> <span class="o">=</span> <span class="n">max_abs_grad</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.flows.stochastic.MetropolisHastings" class="doc doc-heading">
            <code>MetropolisHastings</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.base.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Sampling through Metropolis Hastings in Stochastic Normalizing Flow</p>
<p>See <a href="https://arxiv.org/abs/2002.06707">arXiv: 2002.06707</a></p>

              <details class="quote">
                <summary>Source code in <code>normflows/flows/stochastic.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MetropolisHastings</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sampling through Metropolis Hastings in Stochastic Normalizing Flow</span>

<span class="sd">    See [arXiv: 2002.06707](https://arxiv.org/abs/2002.06707)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">proposal</span><span class="p">,</span> <span class="n">steps</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          target: The stationary distribution of this Markov transition, i.e. the target distribution to sample from.</span>
<span class="sd">          proposal: Proposal distribution</span>
<span class="sd">          steps: Number of MCMC steps to perform</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proposal</span> <span class="o">=</span> <span class="n">proposal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">=</span> <span class="n">steps</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># Initialize number of samples and log(det)</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Get log(p) for current samples</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
            <span class="c1"># Make proposal and get log(p)</span>
            <span class="n">z_</span><span class="p">,</span> <span class="n">log_p_diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proposal</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_p_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_</span><span class="p">)</span>
            <span class="c1"># Make acceptance decision</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">log_w_accept</span> <span class="o">=</span> <span class="n">log_p_</span> <span class="o">-</span> <span class="n">log_p</span> <span class="o">+</span> <span class="n">log_p_diff</span>
            <span class="n">w_accept</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_w_accept</span><span class="p">),</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">accept</span> <span class="o">=</span> <span class="n">w</span> <span class="o">&lt;=</span> <span class="n">w_accept</span>
            <span class="c1"># Update samples, log(det), and log(p)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">accept</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">z_</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
            <span class="n">log_det_</span> <span class="o">=</span> <span class="n">log_p</span> <span class="o">-</span> <span class="n">log_p_</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">accept</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">+</span> <span class="n">log_det_</span><span class="p">,</span> <span class="n">log_det</span><span class="p">)</span>
            <span class="n">log_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">accept</span><span class="p">,</span> <span class="n">log_p_</span><span class="p">,</span> <span class="n">log_p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># Equivalent to forward pass</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.flows.stochastic.MetropolisHastings.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">proposal</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>target</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The stationary distribution of this Markov transition, i.e. the target distribution to sample from.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>proposal</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Proposal distribution</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>steps</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of MCMC steps to perform</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/flows/stochastic.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">proposal</span><span class="p">,</span> <span class="n">steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      target: The stationary distribution of this Markov transition, i.e. the target distribution to sample from.</span>
<span class="sd">      proposal: Proposal distribution</span>
<span class="sd">      steps: Number of MCMC steps to perform</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">proposal</span> <span class="o">=</span> <span class="n">proposal</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">=</span> <span class="n">steps</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>


  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="normflows.nets" class="doc doc-heading">
            <code>nets</code>


</h2>

    <div class="doc doc-contents ">



  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h3 id="normflows.nets.cnn" class="doc doc-heading">
            <code>cnn</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.nets.cnn.ConvNet2d" class="doc doc-heading">
            <code>ConvNet2d</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Convolutional Neural Network with leaky ReLU nonlinearities</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/cnn.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ConvNet2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convolutional Neural Network with leaky ReLU nonlinearities</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">actnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">weight_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          channels: List of channels of conv layers, first entry is in_channels</span>
<span class="sd">          kernel_size: List of kernel sizes, same for height and width</span>
<span class="sd">          leaky: Leaky part of ReLU</span>
<span class="sd">          init_zeros: Flag whether last layer shall be initialized with zeros</span>
<span class="sd">          scale_output: Flag whether to scale output with a log scale parameter</span>
<span class="sd">          logscale_factor: Constant factor to be multiplied to log scaling</span>
<span class="sd">          actnorm: Flag whether activation normalization shall be done after each conv layer except output</span>
<span class="sd">          weight_std: Fixed std used to initialize every layer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Build network</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                <span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">actnorm</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">weight_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">weight_std</span><span class="p">)</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">actnorm</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ActNorm</span><span class="p">((</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">leaky</span><span class="p">))</span>
        <span class="n">i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                <span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">init_zeros</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">net</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.nets.cnn.ConvNet2d.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">actnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_std</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>channels</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of channels of conv layers, first entry is in_channels</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>kernel_size</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of kernel sizes, same for height and width</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>leaky</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Leaky part of ReLU</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_zeros</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether last layer shall be initialized with zeros</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale_output</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether to scale output with a log scale parameter</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>logscale_factor</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Constant factor to be multiplied to log scaling</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>actnorm</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag whether activation normalization shall be done after each conv layer except output</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weight_std</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fixed std used to initialize every layer</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/nets/cnn.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">channels</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">,</span>
    <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">actnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">weight_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      channels: List of channels of conv layers, first entry is in_channels</span>
<span class="sd">      kernel_size: List of kernel sizes, same for height and width</span>
<span class="sd">      leaky: Leaky part of ReLU</span>
<span class="sd">      init_zeros: Flag whether last layer shall be initialized with zeros</span>
<span class="sd">      scale_output: Flag whether to scale output with a log scale parameter</span>
<span class="sd">      logscale_factor: Constant factor to be multiplied to log scaling</span>
<span class="sd">      actnorm: Flag whether activation normalization shall be done after each conv layer except output</span>
<span class="sd">      weight_std: Fixed std used to initialize every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># Build network</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">actnorm</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">weight_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">weight_std</span><span class="p">)</span>
        <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">actnorm</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ActNorm</span><span class="p">((</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">leaky</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">init_zeros</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">net</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.nets.lipschitz" class="doc doc-heading">
            <code>lipschitz</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.nets.lipschitz.LipschitzCNN" class="doc doc-heading">
            <code>LipschitzCNN</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Convolutional neural network which is Lipschitz continuous
with Lipschitz constant L &lt; 1</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/lipschitz.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LipschitzCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convolutional neural network which is Lipschitz continuous</span>
<span class="sd">    with Lipschitz constant L &lt; 1</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">lipschitz_const</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span>
        <span class="n">max_lipschitz_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">lipschitz_tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          channels: Integer list with the number of channels of the layers</span>
<span class="sd">          kernel_size: Integer list of kernel sizes of the layers</span>
<span class="sd">          lipschitz_const: Maximum Lipschitz constant of each layer</span>
<span class="sd">          max_lipschitz_iter: Maximum number of iterations used to ensure that layers are Lipschitz continuous with L smaller than set maximum; if None, tolerance is used</span>
<span class="sd">          lipschitz_tolerance: Float, tolerance used to ensure Lipschitz continuity if max_lipschitz_iter is None, typically 1e-3</span>
<span class="sd">          init_zeros: Flag, whether to initialize last layer approximately with zeros</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_const</span> <span class="o">=</span> <span class="n">lipschitz_const</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_lipschitz_iter</span> <span class="o">=</span> <span class="n">max_lipschitz_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_tolerance</span> <span class="o">=</span> <span class="n">lipschitz_tolerance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_zeros</span> <span class="o">=</span> <span class="n">init_zeros</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">Swish</span><span class="p">(),</span>
                <span class="n">InducedNormConv2d</span><span class="p">(</span>
                    <span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">coeff</span><span class="o">=</span><span class="n">lipschitz_const</span><span class="p">,</span>
                    <span class="n">domain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">codomain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">n_iterations</span><span class="o">=</span><span class="n">max_lipschitz_iter</span><span class="p">,</span>
                    <span class="n">atol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                    <span class="n">rtol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                    <span class="n">zero_init</span><span class="o">=</span><span class="n">init_zeros</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.nets.lipschitz.LipschitzCNN.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">lipschitz_const</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">max_lipschitz_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lipschitz_tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>channels</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Integer list with the number of channels of the layers</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>kernel_size</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Integer list of kernel sizes of the layers</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>lipschitz_const</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum Lipschitz constant of each layer</p>
              </div>
            </td>
            <td>
                  <code>0.97</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>max_lipschitz_iter</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of iterations used to ensure that layers are Lipschitz continuous with L smaller than set maximum; if None, tolerance is used</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>lipschitz_tolerance</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Float, tolerance used to ensure Lipschitz continuity if max_lipschitz_iter is None, typically 1e-3</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_zeros</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, whether to initialize last layer approximately with zeros</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/nets/lipschitz.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">channels</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">,</span>
    <span class="n">lipschitz_const</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span>
    <span class="n">max_lipschitz_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">lipschitz_tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      channels: Integer list with the number of channels of the layers</span>
<span class="sd">      kernel_size: Integer list of kernel sizes of the layers</span>
<span class="sd">      lipschitz_const: Maximum Lipschitz constant of each layer</span>
<span class="sd">      max_lipschitz_iter: Maximum number of iterations used to ensure that layers are Lipschitz continuous with L smaller than set maximum; if None, tolerance is used</span>
<span class="sd">      lipschitz_tolerance: Float, tolerance used to ensure Lipschitz continuity if max_lipschitz_iter is None, typically 1e-3</span>
<span class="sd">      init_zeros: Flag, whether to initialize last layer approximately with zeros</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_const</span> <span class="o">=</span> <span class="n">lipschitz_const</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_lipschitz_iter</span> <span class="o">=</span> <span class="n">max_lipschitz_iter</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_tolerance</span> <span class="o">=</span> <span class="n">lipschitz_tolerance</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">init_zeros</span> <span class="o">=</span> <span class="n">init_zeros</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">Swish</span><span class="p">(),</span>
            <span class="n">InducedNormConv2d</span><span class="p">(</span>
                <span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">coeff</span><span class="o">=</span><span class="n">lipschitz_const</span><span class="p">,</span>
                <span class="n">domain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">codomain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">n_iterations</span><span class="o">=</span><span class="n">max_lipschitz_iter</span><span class="p">,</span>
                <span class="n">atol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                <span class="n">rtol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                <span class="n">zero_init</span><span class="o">=</span><span class="n">init_zeros</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.nets.lipschitz.LipschitzMLP" class="doc doc-heading">
            <code>LipschitzMLP</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Fully connected neural net which is Lipschitz continuou with Lipschitz constant L &lt; 1</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/lipschitz.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LipschitzMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fully connected neural net which is Lipschitz continuou with Lipschitz constant L &lt; 1&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">,</span>
        <span class="n">lipschitz_const</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span>
        <span class="n">max_lipschitz_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">lipschitz_tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor</span>
<span class="sd">          channels: Integer list with the number of channels of</span>
<span class="sd">        the layers</span>
<span class="sd">          lipschitz_const: Maximum Lipschitz constant of each layer</span>
<span class="sd">          max_lipschitz_iter: Maximum number of iterations used to</span>
<span class="sd">        ensure that layers are Lipschitz continuous with L smaller than</span>
<span class="sd">        set maximum; if None, tolerance is used</span>
<span class="sd">          lipschitz_tolerance: Float, tolerance used to ensure</span>
<span class="sd">        Lipschitz continuity if max_lipschitz_iter is None, typically 1e-3</span>
<span class="sd">          init_zeros: Flag, whether to initialize last layer</span>
<span class="sd">        approximately with zeros</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_const</span> <span class="o">=</span> <span class="n">lipschitz_const</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_lipschitz_iter</span> <span class="o">=</span> <span class="n">max_lipschitz_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_tolerance</span> <span class="o">=</span> <span class="n">lipschitz_tolerance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_zeros</span> <span class="o">=</span> <span class="n">init_zeros</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">Swish</span><span class="p">(),</span>
                <span class="n">InducedNormLinear</span><span class="p">(</span>
                    <span class="n">in_features</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">out_features</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">coeff</span><span class="o">=</span><span class="n">lipschitz_const</span><span class="p">,</span>
                    <span class="n">domain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">codomain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">n_iterations</span><span class="o">=</span><span class="n">max_lipschitz_iter</span><span class="p">,</span>
                    <span class="n">atol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                    <span class="n">rtol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                    <span class="n">zero_init</span><span class="o">=</span><span class="n">init_zeros</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.nets.lipschitz.LipschitzMLP.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">lipschitz_const</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">max_lipschitz_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lipschitz_tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor
  channels: Integer list with the number of channels of
the layers
  lipschitz_const: Maximum Lipschitz constant of each layer
  max_lipschitz_iter: Maximum number of iterations used to
ensure that layers are Lipschitz continuous with L smaller than
set maximum; if None, tolerance is used
  lipschitz_tolerance: Float, tolerance used to ensure
Lipschitz continuity if max_lipschitz_iter is None, typically 1e-3
  init_zeros: Flag, whether to initialize last layer
approximately with zeros</p>

            <details class="quote">
              <summary>Source code in <code>normflows/nets/lipschitz.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">channels</span><span class="p">,</span>
    <span class="n">lipschitz_const</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span>
    <span class="n">max_lipschitz_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">lipschitz_tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">init_zeros</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructor</span>
<span class="sd">      channels: Integer list with the number of channels of</span>
<span class="sd">    the layers</span>
<span class="sd">      lipschitz_const: Maximum Lipschitz constant of each layer</span>
<span class="sd">      max_lipschitz_iter: Maximum number of iterations used to</span>
<span class="sd">    ensure that layers are Lipschitz continuous with L smaller than</span>
<span class="sd">    set maximum; if None, tolerance is used</span>
<span class="sd">      lipschitz_tolerance: Float, tolerance used to ensure</span>
<span class="sd">    Lipschitz continuity if max_lipschitz_iter is None, typically 1e-3</span>
<span class="sd">      init_zeros: Flag, whether to initialize last layer</span>
<span class="sd">    approximately with zeros</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_const</span> <span class="o">=</span> <span class="n">lipschitz_const</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_lipschitz_iter</span> <span class="o">=</span> <span class="n">max_lipschitz_iter</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz_tolerance</span> <span class="o">=</span> <span class="n">lipschitz_tolerance</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">init_zeros</span> <span class="o">=</span> <span class="n">init_zeros</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">Swish</span><span class="p">(),</span>
            <span class="n">InducedNormLinear</span><span class="p">(</span>
                <span class="n">in_features</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">out_features</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">coeff</span><span class="o">=</span><span class="n">lipschitz_const</span><span class="p">,</span>
                <span class="n">domain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">codomain</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">n_iterations</span><span class="o">=</span><span class="n">max_lipschitz_iter</span><span class="p">,</span>
                <span class="n">atol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                <span class="n">rtol</span><span class="o">=</span><span class="n">lipschitz_tolerance</span><span class="p">,</span>
                <span class="n">zero_init</span><span class="o">=</span><span class="n">init_zeros</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h4 id="normflows.nets.lipschitz.projmax_" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">projmax_</span><span class="p">(</span><span class="n">v</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Inplace argmax on absolute value.</p>

            <details class="quote">
              <summary>Source code in <code>normflows/nets/lipschitz.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">projmax_</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Inplace argmax on absolute value.&quot;&quot;&quot;</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
    <span class="n">v</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="n">v</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">v</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.nets.made" class="doc doc-heading">
            <code>made</code>


</h3>

    <div class="doc doc-contents ">

      <p>Implementation of MADE.
Code taken from https://github.com/bayesiains/nsf</p>



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.nets.made.MADE" class="doc doc-heading">
            <code>MADE</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Implementation of MADE.</p>
<p>It can use either feedforward blocks or residual blocks (default is residual).
Optionally, it can use batch norm or dropout within blocks (default is no).</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/made.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MADE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Implementation of MADE.</span>

<span class="sd">    It can use either feedforward blocks or residual blocks (default is residual).</span>
<span class="sd">    Optionally, it can use batch norm or dropout within blocks (default is no).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="n">hidden_features</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">output_multiplier</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">permute_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">preprocessing</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">use_residual_blocks</span> <span class="ow">and</span> <span class="n">random_mask</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Residual blocks can&#39;t be used with random masks.&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Preprocessing</span>
        <span class="k">if</span> <span class="n">preprocessing</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="o">=</span> <span class="n">preprocessing</span>

        <span class="c1"># Initial layer.</span>
        <span class="n">input_degrees_</span> <span class="o">=</span> <span class="n">_get_input_degrees</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">permute_mask</span><span class="p">:</span>
            <span class="n">input_degrees_</span> <span class="o">=</span> <span class="n">input_degrees_</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">features</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_layer</span> <span class="o">=</span> <span class="n">MaskedLinear</span><span class="p">(</span>
            <span class="n">in_degrees</span><span class="o">=</span><span class="n">input_degrees_</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">autoregressive_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="n">random_mask</span><span class="p">,</span>
            <span class="n">is_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">context_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">context_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">context_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>

        <span class="c1"># Residual blocks.</span>
        <span class="n">blocks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">use_residual_blocks</span><span class="p">:</span>
            <span class="n">block_constructor</span> <span class="o">=</span> <span class="n">MaskedResidualBlock</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">block_constructor</span> <span class="o">=</span> <span class="n">MaskedFeedforwardBlock</span>
        <span class="n">prev_out_degrees</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_layer</span><span class="o">.</span><span class="n">degrees</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">):</span>
            <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">block_constructor</span><span class="p">(</span>
                    <span class="n">in_degrees</span><span class="o">=</span><span class="n">prev_out_degrees</span><span class="p">,</span>
                    <span class="n">autoregressive_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                    <span class="n">context_features</span><span class="o">=</span><span class="n">context_features</span><span class="p">,</span>
                    <span class="n">random_mask</span><span class="o">=</span><span class="n">random_mask</span><span class="p">,</span>
                    <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                    <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
                    <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">use_batch_norm</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">prev_out_degrees</span> <span class="o">=</span> <span class="n">blocks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">degrees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">blocks</span><span class="p">)</span>

        <span class="c1"># Final layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">MaskedLinear</span><span class="p">(</span>
            <span class="n">in_degrees</span><span class="o">=</span><span class="n">prev_out_degrees</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">features</span> <span class="o">*</span> <span class="n">output_multiplier</span><span class="p">,</span>
            <span class="n">autoregressive_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="n">random_mask</span><span class="p">,</span>
            <span class="n">is_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">out_degrees_</span><span class="o">=</span><span class="n">input_degrees_</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_layer</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_layer</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.nets.made.MaskedFeedforwardBlock" class="doc doc-heading">
            <code>MaskedFeedforwardBlock</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>A feedforward block based on a masked linear module.</p>
<p><strong>NOTE</strong> In this implementation, the number of output features is taken to be equal to the number of input features.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/made.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MaskedFeedforwardBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A feedforward block based on a masked linear module.</span>

<span class="sd">    **NOTE** In this implementation, the number of output features is taken to be equal to the number of input features.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_degrees</span><span class="p">,</span>
        <span class="n">autoregressive_features</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_degrees</span><span class="p">)</span>

        <span class="c1"># Batch norm.</span>
        <span class="k">if</span> <span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">context_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

        <span class="c1"># Masked linear.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">MaskedLinear</span><span class="p">(</span>
            <span class="n">in_degrees</span><span class="o">=</span><span class="n">in_degrees</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">autoregressive_features</span><span class="o">=</span><span class="n">autoregressive_features</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="n">random_mask</span><span class="p">,</span>
            <span class="n">is_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">degrees</span>

        <span class="c1"># Activation and dropout.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.nets.made.MaskedLinear" class="doc doc-heading">
            <code>MaskedLinear</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Linear">Linear</span></code></p>


      <p>A linear module with a masked weight matrix.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/made.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MaskedLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A linear module with a masked weight matrix.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_degrees</span><span class="p">,</span>
        <span class="n">out_features</span><span class="p">,</span>
        <span class="n">autoregressive_features</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="p">,</span>
        <span class="n">is_output</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">out_degrees_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">in_degrees</span><span class="p">),</span> <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span>
        <span class="p">)</span>
        <span class="n">mask</span><span class="p">,</span> <span class="n">degrees</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_mask_and_degrees</span><span class="p">(</span>
            <span class="n">in_degrees</span><span class="o">=</span><span class="n">in_degrees</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
            <span class="n">autoregressive_features</span><span class="o">=</span><span class="n">autoregressive_features</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="n">random_mask</span><span class="p">,</span>
            <span class="n">is_output</span><span class="o">=</span><span class="n">is_output</span><span class="p">,</span>
            <span class="n">out_degrees_</span><span class="o">=</span><span class="n">out_degrees_</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;mask&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;degrees&quot;</span><span class="p">,</span> <span class="n">degrees</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_get_mask_and_degrees</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">in_degrees</span><span class="p">,</span>
        <span class="n">out_features</span><span class="p">,</span>
        <span class="n">autoregressive_features</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="p">,</span>
        <span class="n">is_output</span><span class="p">,</span>
        <span class="n">out_degrees_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">is_output</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">out_degrees_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">out_degrees_</span> <span class="o">=</span> <span class="n">_get_input_degrees</span><span class="p">(</span><span class="n">autoregressive_features</span><span class="p">)</span>
            <span class="n">out_degrees</span> <span class="o">=</span> <span class="n">tile</span><span class="p">(</span><span class="n">out_degrees_</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">//</span> <span class="n">autoregressive_features</span><span class="p">)</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_degrees</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">in_degrees</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">random_mask</span><span class="p">:</span>
                <span class="n">min_in_degree</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">in_degrees</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">min_in_degree</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">min_in_degree</span><span class="p">,</span> <span class="n">autoregressive_features</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">out_degrees</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="n">min_in_degree</span><span class="p">,</span>
                    <span class="n">high</span><span class="o">=</span><span class="n">autoregressive_features</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">out_features</span><span class="p">],</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">autoregressive_features</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">min_</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">autoregressive_features</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">out_degrees</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">out_features</span><span class="p">)</span> <span class="o">%</span> <span class="n">max_</span> <span class="o">+</span> <span class="n">min_</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_degrees</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">in_degrees</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">mask</span><span class="p">,</span> <span class="n">out_degrees</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.nets.made.MaskedResidualBlock" class="doc doc-heading">
            <code>MaskedResidualBlock</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>A residual block containing masked linear modules.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/made.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MaskedResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A residual block containing masked linear modules.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_degrees</span><span class="p">,</span>
        <span class="n">autoregressive_features</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">zero_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">random_mask</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Masked residual block can&#39;t be used with random masks.&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_degrees</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">context_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">context_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">context_features</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>

        <span class="c1"># Batch norm.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_batch_norm</span> <span class="o">=</span> <span class="n">use_batch_norm</span>
        <span class="k">if</span> <span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
                <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
            <span class="p">)</span>

        <span class="c1"># Masked linear.</span>
        <span class="n">linear_0</span> <span class="o">=</span> <span class="n">MaskedLinear</span><span class="p">(</span>
            <span class="n">in_degrees</span><span class="o">=</span><span class="n">in_degrees</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">autoregressive_features</span><span class="o">=</span><span class="n">autoregressive_features</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">is_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">linear_1</span> <span class="o">=</span> <span class="n">MaskedLinear</span><span class="p">(</span>
            <span class="n">in_degrees</span><span class="o">=</span><span class="n">linear_0</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">autoregressive_features</span><span class="o">=</span><span class="n">autoregressive_features</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">is_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">linear_0</span><span class="p">,</span> <span class="n">linear_1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">linear_1</span><span class="o">.</span><span class="n">degrees</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">&gt;=</span> <span class="n">in_degrees</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;In a masked residual block, the output degrees can&#39;t be&quot;</span>
                <span class="s2">&quot; less than the corresponding input degrees.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Activation and dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">)</span>

        <span class="c1"># Initialization.</span>
        <span class="k">if</span> <span class="n">zero_initialization</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=-</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
            <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">a</span><span class="o">=-</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">glu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">temps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_layer</span><span class="p">(</span><span class="n">context</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">inputs</span> <span class="o">+</span> <span class="n">temps</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.nets.made_test" class="doc doc-heading">
            <code>made_test</code>


</h3>

    <div class="doc doc-contents ">

      <p>Tests for MADE.
Code partially taken from https://github.com/bayesiains/nsf</p>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.nets.mlp" class="doc doc-heading">
            <code>mlp</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.nets.mlp.MLP" class="doc doc-heading">
            <code>MLP</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>A multilayer perceptron with Leaky ReLU nonlinearities</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/mlp.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A multilayer perceptron with Leaky ReLU nonlinearities</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">layers</span><span class="p">,</span>
        <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">score_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">init_zeros</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        layers: list of layer sizes from start to end</span>
<span class="sd">        leaky: slope of the leaky part of the ReLU, if 0.0, standard ReLU is used</span>
<span class="sd">        score_scale: Factor to apply to the scores, i.e. output before output_fn.</span>
<span class="sd">        output_fn: String, function to be applied to the output, either None, &quot;sigmoid&quot;, &quot;relu&quot;, &quot;tanh&quot;, or &quot;clampexp&quot;</span>
<span class="sd">        output_scale: Rescale outputs if output_fn is specified, i.e. ```scale * output_fn(out / scale)```</span>
<span class="sd">        init_zeros: Flag, if true, weights and biases of last layer are initialized with zeros (helpful for deep models, see [arXiv 1807.03039](https://arxiv.org/abs/1807.03039))</span>
<span class="sd">        dropout: Float, if specified, dropout is done before last layer; if None, no dropout is done</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">leaky</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">init_zeros</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">score_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ConstScaleLayer</span><span class="p">(</span><span class="n">score_scale</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
            <span class="k">elif</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;relu&quot;</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="k">elif</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
            <span class="k">elif</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;clampexp&quot;</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ClampExp</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This output function is not implemented.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">output_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ConstScaleLayer</span><span class="p">(</span><span class="n">output_scale</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">net</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.nets.mlp.MLP.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">layers</span><span class="p">,</span> <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">score_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_zeros</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>layers: list of layer sizes from start to end
leaky: slope of the leaky part of the ReLU, if 0.0, standard ReLU is used
score_scale: Factor to apply to the scores, i.e. output before output_fn.
output_fn: String, function to be applied to the output, either None, "sigmoid", "relu", "tanh", or "clampexp"
output_scale: Rescale outputs if output_fn is specified, i.e. <code>scale * output_fn(out / scale)</code>
init_zeros: Flag, if true, weights and biases of last layer are initialized with zeros (helpful for deep models, see <a href="https://arxiv.org/abs/1807.03039">arXiv 1807.03039</a>)
dropout: Float, if specified, dropout is done before last layer; if None, no dropout is done</p>

            <details class="quote">
              <summary>Source code in <code>normflows/nets/mlp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">layers</span><span class="p">,</span>
    <span class="n">leaky</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">score_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">output_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">output_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">init_zeros</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">dropout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    layers: list of layer sizes from start to end</span>
<span class="sd">    leaky: slope of the leaky part of the ReLU, if 0.0, standard ReLU is used</span>
<span class="sd">    score_scale: Factor to apply to the scores, i.e. output before output_fn.</span>
<span class="sd">    output_fn: String, function to be applied to the output, either None, &quot;sigmoid&quot;, &quot;relu&quot;, &quot;tanh&quot;, or &quot;clampexp&quot;</span>
<span class="sd">    output_scale: Rescale outputs if output_fn is specified, i.e. ```scale * output_fn(out / scale)```</span>
<span class="sd">    init_zeros: Flag, if true, weights and biases of last layer are initialized with zeros (helpful for deep models, see [arXiv 1807.03039](https://arxiv.org/abs/1807.03039))</span>
<span class="sd">    dropout: Float, if specified, dropout is done before last layer; if None, no dropout is done</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">leaky</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
    <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">if</span> <span class="n">init_zeros</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">output_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">score_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ConstScaleLayer</span><span class="p">(</span><span class="n">score_scale</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
        <span class="k">elif</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;relu&quot;</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="k">elif</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
        <span class="k">elif</span> <span class="n">output_fn</span> <span class="o">==</span> <span class="s2">&quot;clampexp&quot;</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ClampExp</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This output function is not implemented.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ConstScaleLayer</span><span class="p">(</span><span class="n">output_scale</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">net</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.nets.resnet" class="doc doc-heading">
            <code>resnet</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.nets.resnet.ResidualBlock" class="doc doc-heading">
            <code>ResidualBlock</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>A general-purpose residual block. Works only with 1-dim inputs.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/resnet.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A general-purpose residual block. Works only with 1-dim inputs.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="n">context_features</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">zero_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">use_batch_norm</span> <span class="o">=</span> <span class="n">use_batch_norm</span>
        <span class="k">if</span> <span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
                <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">context_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">context_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">context_features</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">zero_initialization</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span>
            <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_batch_norm</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">temps</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">glu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">temps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_layer</span><span class="p">(</span><span class="n">context</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">inputs</span> <span class="o">+</span> <span class="n">temps</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.nets.resnet.ResidualNet" class="doc doc-heading">
            <code>ResidualNet</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>A general-purpose residual network. Works only with 1-dim inputs.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/nets/resnet.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ResidualNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A general-purpose residual network. Works only with 1-dim inputs.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_features</span><span class="p">,</span>
        <span class="n">out_features</span><span class="p">,</span>
        <span class="n">hidden_features</span><span class="p">,</span>
        <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">preprocessing</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_features</span> <span class="o">=</span> <span class="n">hidden_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_features</span> <span class="o">=</span> <span class="n">context_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="o">=</span> <span class="n">preprocessing</span>
        <span class="k">if</span> <span class="n">context_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initial_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
                <span class="n">in_features</span> <span class="o">+</span> <span class="n">context_features</span><span class="p">,</span> <span class="n">hidden_features</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initial_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">ResidualBlock</span><span class="p">(</span>
                    <span class="n">features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                    <span class="n">context_features</span><span class="o">=</span><span class="n">context_features</span><span class="p">,</span>
                    <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                    <span class="n">dropout_probability</span><span class="o">=</span><span class="n">dropout_probability</span><span class="p">,</span>
                    <span class="n">use_batch_norm</span><span class="o">=</span><span class="n">use_batch_norm</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_layer</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">temps</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
            <span class="n">temps</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">temps</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">temps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>




  </div>

    </div>

</div>


  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="normflows.sampling" class="doc doc-heading">
            <code>sampling</code>


</h2>

    <div class="doc doc-contents ">



  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h3 id="normflows.sampling.hais" class="doc doc-heading">
            <code>hais</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.sampling.hais.HAIS" class="doc doc-heading">
            <code>HAIS</code>


</h4>


    <div class="doc doc-contents ">


      <p>Class which performs HAIS</p>

              <details class="quote">
                <summary>Source code in <code>normflows/sampling/hais.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">HAIS</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class which performs HAIS</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">num_leapfrog</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">log_mass</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">          betas: Annealing schedule, the jth target is ```f_j(x) = f_0(x)^{\beta_j} f_n(x)^{1-\beta_j}``` where the target is proportional to f_0 and the prior is proportional to f_n. The number of intermediate steps is infered from the shape of betas. Should be of the form 1 = \beta_0 &gt; \beta_1 &gt; ... &gt; \beta_n = 0</span>
<span class="sd">          prior: The prior distribution to start the HAIS chain.</span>
<span class="sd">          target: The target distribution from which we would like to draw weighted samples.</span>
<span class="sd">          num_leapfrog: Number of leapfrog steps in the HMC transitions.</span>
<span class="sd">          step_size: step_size to use for HMC transitions.</span>
<span class="sd">          log_mass: log_mass to use for HMC transitions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">prior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">betas</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">intermediate_target</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">LinearInterpolation</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="p">,</span> <span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">flows</span><span class="o">.</span><span class="n">HamiltonianMonteCarlo</span><span class="p">(</span>
                    <span class="n">intermediate_target</span><span class="p">,</span> <span class="n">num_leapfrog</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">step_size</span><span class="p">),</span> <span class="n">log_mass</span>
                <span class="p">)</span>
            <span class="p">]</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run HAIS to draw samples from the target with appropriate weights.</span>

<span class="sd">        Args:</span>
<span class="sd">          num_samples: The number of samples to draw.a</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">log_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">log_weights</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_weights</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
            <span class="n">samples</span><span class="p">,</span> <span class="n">log_weights_addition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
            <span class="n">log_weights</span> <span class="o">+=</span> <span class="n">log_weights_addition</span>
        <span class="n">log_weights</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">log_weights</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.sampling.hais.HAIS.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">num_leapfrog</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">log_mass</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>betas</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Annealing schedule, the jth target is <code>f_j(x) = f_0(x)^{eta_j} f_n(x)^{1-eta_j}</code> where the target is proportional to f_0 and the prior is proportional to f_n. The number of intermediate steps is infered from the shape of betas. Should be of the form 1 = eta_0 &gt; eta_1 &gt; ... &gt; eta_n = 0</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prior distribution to start the HAIS chain.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>target</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target distribution from which we would like to draw weighted samples.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_leapfrog</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of leapfrog steps in the HMC transitions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>step_size</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>step_size to use for HMC transitions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>log_mass</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>log_mass to use for HMC transitions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/sampling/hais.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">num_leapfrog</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">log_mass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      betas: Annealing schedule, the jth target is ```f_j(x) = f_0(x)^{\beta_j} f_n(x)^{1-\beta_j}``` where the target is proportional to f_0 and the prior is proportional to f_n. The number of intermediate steps is infered from the shape of betas. Should be of the form 1 = \beta_0 &gt; \beta_1 &gt; ... &gt; \beta_n = 0</span>
<span class="sd">      prior: The prior distribution to start the HAIS chain.</span>
<span class="sd">      target: The target distribution from which we would like to draw weighted samples.</span>
<span class="sd">      num_leapfrog: Number of leapfrog steps in the HMC transitions.</span>
<span class="sd">      step_size: step_size to use for HMC transitions.</span>
<span class="sd">      log_mass: log_mass to use for HMC transitions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">prior</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">betas</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">intermediate_target</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">LinearInterpolation</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="p">,</span> <span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">flows</span><span class="o">.</span><span class="n">HamiltonianMonteCarlo</span><span class="p">(</span>
                <span class="n">intermediate_target</span><span class="p">,</span> <span class="n">num_leapfrog</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">step_size</span><span class="p">),</span> <span class="n">log_mass</span>
            <span class="p">)</span>
        <span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="normflows.sampling.hais.HAIS.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Run HAIS to draw samples from the target with appropriate weights.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>num_samples</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of samples to draw.a</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/sampling/hais.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run HAIS to draw samples from the target with appropriate weights.</span>

<span class="sd">    Args:</span>
<span class="sd">      num_samples: The number of samples to draw.a</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples</span><span class="p">,</span> <span class="n">log_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="n">log_weights</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_weights</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">log_weights_addition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">log_weights</span> <span class="o">+=</span> <span class="n">log_weights_addition</span>
    <span class="n">log_weights</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">log_weights</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>


  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="normflows.transforms" class="doc doc-heading">
            <code>transforms</code>


</h2>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="normflows.transforms.Logit" class="doc doc-heading">
            <code>Logit</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Logit mapping of image tensor, see RealNVP paper</p>
<pre><code>logit(alpha + (1 - alpha) * x) where logit(x) = log(x / (1 - x))
</code></pre>

              <details class="quote">
                <summary>Source code in <code>normflows/transforms.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Logit</span><span class="p">(</span><span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Logit mapping of image tensor, see RealNVP paper</span>

<span class="sd">    ```</span>
<span class="sd">    logit(alpha + (1 - alpha) * x) where logit(x) = log(x / (1 - x))</span>
<span class="sd">    ```</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          alpha: Alpha parameter, see above</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">sum_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span>
        <span class="n">ls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">sum_dims</span><span class="p">)</span>
        <span class="n">mls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">sum_dims</span><span class="p">)</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span> <span class="o">+</span> <span class="n">ls</span> <span class="o">+</span> <span class="n">mls</span>
        <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">beta</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">z</span>
        <span class="n">logz</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">log1mz</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">logz</span> <span class="o">-</span> <span class="n">log1mz</span>
        <span class="n">sum_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>
            <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">logz</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">sum_dims</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log1mz</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">sum_dims</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.transforms.Logit.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>alpha</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Alpha parameter, see above</p>
              </div>
            </td>
            <td>
                  <code>0.05</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/transforms.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      alpha: Alpha parameter, see above</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="normflows.transforms.Shift" class="doc doc-heading">
            <code>Shift</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="normflows.flows.Flow" href="#normflows.flows.base.Flow">Flow</a></code></p>


      <p>Shift data by a fixed constant</p>
<p>Default is -0.5 to shift data from
interval [0, 1] to [-0.5, 0.5]</p>

              <details class="quote">
                <summary>Source code in <code>normflows/transforms.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Shift</span><span class="p">(</span><span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Shift data by a fixed constant</span>

<span class="sd">    Default is -0.5 to shift data from</span>
<span class="sd">    interval [0, 1] to [-0.5, 0.5]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shift</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shift: Shift to apply to the data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                              <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span>
        <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                              <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.transforms.Shift.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shift</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shift</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shift to apply to the data</p>
              </div>
            </td>
            <td>
                  <code>-0.5</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/transforms.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shift</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shift: Shift to apply to the data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="normflows.utils" class="doc doc-heading">
            <code>utils</code>


</h2>

    <div class="doc doc-contents ">



  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h3 id="normflows.utils.eval" class="doc doc-heading">
            <code>eval</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.utils.eval.bitsPerDim" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">bitsPerDim</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span> <span class="n">trans_param</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">])</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Computes the bits per dim for a batch of data</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model to compute bits per dim for</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch of data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Class labels for batch of data if base distribution is class conditional</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>trans</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Transformation to be applied to images during training</p>
              </div>
            </td>
            <td>
                  <code>&#39;logit&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>trans_param</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of parameters of the transformation</p>
              </div>
            </td>
            <td>
                  <code>[0.05]</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bits per dim for data batch under model</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/eval.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">bitsPerDim</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s2">&quot;logit&quot;</span><span class="p">,</span> <span class="n">trans_param</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the bits per dim for a batch of data</span>

<span class="sd">    Args:</span>
<span class="sd">      model: Model to compute bits per dim for</span>
<span class="sd">      x: Batch of data</span>
<span class="sd">      y: Class labels for batch of data if base distribution is class conditional</span>
<span class="sd">      trans: Transformation to be applied to images during training</span>
<span class="sd">      trans_param: List of parameters of the transformation</span>

<span class="sd">    Returns:</span>
<span class="sd">      Bits per dim for data batch under model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]))</span>
    <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;logit&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log_q</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">sum_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span>
        <span class="n">ls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LogSigmoid</span><span class="p">()</span>
        <span class="n">sig_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ls</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">sum_dims</span><span class="p">)</span>
        <span class="n">sig_</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ls</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">sum_dims</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_q</span> <span class="o">/</span> <span class="n">dims</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">trans_param</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mi">8</span>
        <span class="n">b</span> <span class="o">+=</span> <span class="n">sig_</span> <span class="o">/</span> <span class="n">dims</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;The transformation &quot;</span> <span class="o">+</span> <span class="n">trans</span> <span class="o">+</span> <span class="s2">&quot; is not implemented.&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">b</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.utils.eval.bitsPerDimDataset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">bitsPerDimDataset</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s1">&#39;logit&#39;</span><span class="p">,</span> <span class="n">trans_param</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">])</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Computes average bits per dim for an entire dataset given by a data loader</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model to compute bits per dim for</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>data_loader</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data loader of dataset</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_cond</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag indicating whether model is class_conditional</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>trans</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Transformation to be applied to images during training</p>
              </div>
            </td>
            <td>
                  <code>&#39;logit&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>trans_param</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of parameters of the transformation</p>
              </div>
            </td>
            <td>
                  <code>[0.05]</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Average bits per dim for dataset</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/eval.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">bitsPerDimDataset</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">class_cond</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s2">&quot;logit&quot;</span><span class="p">,</span> <span class="n">trans_param</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">]</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes average bits per dim for an entire dataset given by a data loader</span>

<span class="sd">    Args:</span>
<span class="sd">      model: Model to compute bits per dim for</span>
<span class="sd">      data_loader: Data loader of dataset</span>
<span class="sd">      class_cond: Flag indicating whether model is class_conditional</span>
<span class="sd">      trans: Transformation to be applied to images during training</span>
<span class="sd">      trans_param: List of parameters of the transformation</span>

<span class="sd">    Returns:</span>
<span class="sd">      Average bits per dim for dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">b_cum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
            <span class="n">b_</span> <span class="o">=</span> <span class="n">bitsPerDim</span><span class="p">(</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">class_cond</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span> <span class="n">trans</span><span class="p">,</span> <span class="n">trans_param</span>
            <span class="p">)</span>
            <span class="n">b_np</span> <span class="o">=</span> <span class="n">b_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">b_cum</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">nansum</span><span class="p">(</span><span class="n">b_np</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">b_np</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b_cum</span> <span class="o">/</span> <span class="n">n</span>
    <span class="k">return</span> <span class="n">b</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.utils.masks" class="doc doc-heading">
            <code>masks</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.utils.masks.create_alternating_binary_mask" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_alternating_binary_mask</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Creates a binary mask of a given dimension which alternates its masking.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>features</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension of mask.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>even</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, even values are assigned 1s, odd 0s. If False, vice versa.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Alternating binary mask of type torch.Tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/masks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_alternating_binary_mask</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a binary mask of a given dimension which alternates its masking.</span>

<span class="sd">    Args:</span>
<span class="sd">      features: Dimension of mask.</span>
<span class="sd">      even: If True, even values are assigned 1s, odd 0s. If False, vice versa.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Alternating binary mask of type torch.Tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">even</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="n">mask</span><span class="p">[</span><span class="n">start</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.utils.masks.create_mid_split_binary_mask" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_mid_split_binary_mask</span><span class="p">(</span><span class="n">features</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Creates a binary mask of a given dimension which splits its masking at the midpoint.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>features</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension of mask.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Binary mask split at midpoint of type torch.Tensor</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/masks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_mid_split_binary_mask</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a binary mask of a given dimension which splits its masking at the midpoint.</span>

<span class="sd">    Args:</span>
<span class="sd">      features: Dimension of mask.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Binary mask split at midpoint of type torch.Tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span>
    <span class="n">midpoint</span> <span class="o">=</span> <span class="n">features</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">features</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">features</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">mask</span><span class="p">[:</span><span class="n">midpoint</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.utils.masks.create_random_binary_mask" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_random_binary_mask</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Creates a random binary mask of a given dimension with half of its entries randomly set to 1s.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>features</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension of mask.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>seed</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Seed to be used</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Binary mask with half of its entries set to 1s, of type torch.Tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/masks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_random_binary_mask</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a random binary mask of a given dimension with half of its entries randomly set to 1s.</span>

<span class="sd">    Args:</span>
<span class="sd">      features: Dimension of mask.</span>
<span class="sd">      seed: Seed to be used</span>

<span class="sd">    Returns:</span>
<span class="sd">      Binary mask with half of its entries set to 1s, of type torch.Tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="n">features</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">features</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">features</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
        <span class="n">generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span>
    <span class="p">)</span>
    <span class="n">mask</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.utils.nn" class="doc doc-heading">
            <code>nn</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.utils.nn.ActNorm" class="doc doc-heading">
            <code>ActNorm</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>ActNorm layer with just one forward pass</p>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/nn.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ActNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ActNorm layer with just one forward pass</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          shape: Same as shape in flows.ActNorm</span>
<span class="sd">          logscale_factor: Same as shape in flows.ActNorm</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actNorm</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">ActNorm</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actNorm</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.nn.ActNorm.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>shape</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Same as shape in flows.ActNorm</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>logscale_factor</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Same as shape in flows.ActNorm</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/nn.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: Same as shape in flows.ActNorm</span>
<span class="sd">      logscale_factor: Same as shape in flows.ActNorm</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">actNorm</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">ActNorm</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.utils.nn.ClampExp" class="doc doc-heading">
            <code>ClampExp</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Nonlinearity min(exp(lam * x), 1)</p>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/nn.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ClampExp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Nonlinearity min(exp(lam * x), 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          lam: Lambda parameter</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClampExp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">one</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">one</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.nn.ClampExp.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">()</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>lam</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lambda parameter</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/nn.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      lam: Lambda parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ClampExp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.utils.nn.ConstScaleLayer" class="doc doc-heading">
            <code>ConstScaleLayer</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Scaling features by a fixed factor</p>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/nn.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ConstScaleLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Scaling features by a fixed factor</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          scale: Scale to apply to features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.nn.ConstScaleLayer.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scale to apply to features</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/nn.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      scale: Scale to apply to features</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_cpu</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.utils.nn.PeriodicFeaturesCat" class="doc doc-heading">
            <code>PeriodicFeaturesCat</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Converts a specified part of the input to periodic features by
replacing those features f with [sin(scale * f), cos(scale * f)].</p>
<p>Note that this decreases the number of features and their order
is changed.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/nn.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PeriodicFeaturesCat</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a specified part of the input to periodic features by</span>
<span class="sd">    replacing those features f with [sin(scale * f), cos(scale * f)].</span>

<span class="sd">    Note that this decreases the number of features and their order</span>
<span class="sd">    is changed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor</span>
<span class="sd">        :param ndim: Int, number of dimensions</span>
<span class="sd">        :param ind: Iterable, indices of input elements to convert to</span>
<span class="sd">        periodic features</span>
<span class="sd">        :param scale: Scalar or iterable, used to scale inputs before</span>
<span class="sd">        converting them to periodic features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PeriodicFeaturesCat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Set up indices and permutations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_cast_Long</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

        <span class="n">ind_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">:</span>
                <span class="n">ind_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind_&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">inputs_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span>
        <span class="n">inputs_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">inputs_</span>
        <span class="n">inputs_sin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">inputs_</span><span class="p">)</span>
        <span class="n">inputs_cos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">inputs_</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">inputs_sin</span><span class="p">,</span> <span class="n">inputs_cos</span><span class="p">,</span>
                         <span class="n">inputs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.nn.PeriodicFeaturesCat.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor
:param ndim: Int, number of dimensions
:param ind: Iterable, indices of input elements to convert to
periodic features
:param scale: Scalar or iterable, used to scale inputs before
converting them to periodic features</p>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/nn.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructor</span>
<span class="sd">    :param ndim: Int, number of dimensions</span>
<span class="sd">    :param ind: Iterable, indices of input elements to convert to</span>
<span class="sd">    periodic features</span>
<span class="sd">    :param scale: Scalar or iterable, used to scale inputs before</span>
<span class="sd">    converting them to periodic features</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PeriodicFeaturesCat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># Set up indices and permutations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_cast_Long</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

    <span class="n">ind_</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">:</span>
            <span class="n">ind_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind_&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.utils.nn.PeriodicFeaturesElementwise" class="doc doc-heading">
            <code>PeriodicFeaturesElementwise</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Converts a specified part of the input to periodic features by
replacing those features f with
w1 * sin(scale * f) + w2 * cos(scale * f).</p>
<p>Note that this operation is done elementwise and, therefore,
some information about the feature can be lost.</p>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/nn.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PeriodicFeaturesElementwise</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a specified part of the input to periodic features by</span>
<span class="sd">    replacing those features f with</span>
<span class="sd">    w1 * sin(scale * f) + w2 * cos(scale * f).</span>

<span class="sd">    Note that this operation is done elementwise and, therefore,</span>
<span class="sd">    some information about the feature can be lost.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          ndim (int): number of dimensions</span>
<span class="sd">          ind (iterable): indices of input elements to convert to periodic features</span>
<span class="sd">          scale: Scalar or iterable, used to scale inputs before converting them to periodic features</span>
<span class="sd">          bias: Flag, whether to add a bias</span>
<span class="sd">          activation: Function or None, activation function to be applied</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PeriodicFeaturesElementwise</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Set up indices and permutations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_cast_Long</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

        <span class="n">ind_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">:</span>
                <span class="n">ind_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind_&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

        <span class="n">perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">))</span>
        <span class="n">inv_perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">perm_</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
            <span class="n">inv_perm_</span><span class="p">[</span><span class="n">perm_</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">i</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;inv_perm&quot;</span><span class="p">,</span> <span class="n">inv_perm_</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">apply_bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">)))</span>

        <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">inputs_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">]</span>
        <span class="n">inputs_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">inputs_</span>
        <span class="n">inputs_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">inputs_</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span>
            <span class="p">:,</span> <span class="mi">1</span>
        <span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">inputs_</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_bias</span><span class="p">:</span>
            <span class="n">inputs_</span> <span class="o">=</span> <span class="n">inputs_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
        <span class="n">inputs_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">inputs_</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">inputs_</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_perm</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.nn.PeriodicFeaturesElementwise.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>ndim</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of dimensions</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ind</code></td>
            <td>
                  <code>iterable</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>indices of input elements to convert to periodic features</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scalar or iterable, used to scale inputs before converting them to periodic features</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bias</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag, whether to add a bias</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>activation</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function or None, activation function to be applied</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/nn.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      ndim (int): number of dimensions</span>
<span class="sd">      ind (iterable): indices of input elements to convert to periodic features</span>
<span class="sd">      scale: Scalar or iterable, used to scale inputs before converting them to periodic features</span>
<span class="sd">      bias: Flag, whether to add a bias</span>
<span class="sd">      activation: Function or None, activation function to be applied</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PeriodicFeaturesElementwise</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># Set up indices and permutations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_cast_Long</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

    <span class="n">ind_</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">:</span>
            <span class="n">ind_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;ind_&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ind_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

    <span class="n">perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ind_</span><span class="p">))</span>
    <span class="n">inv_perm_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">perm_</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">inv_perm_</span><span class="p">[</span><span class="n">perm_</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;inv_perm&quot;</span><span class="p">,</span> <span class="n">inv_perm_</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">apply_bias</span> <span class="o">=</span> <span class="n">bias</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_bias</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ind</span><span class="p">)))</span>

    <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h4 id="normflows.utils.nn.sum_except_batch" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sum_except_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Sums all elements of <code>x</code> except for the first <code>num_batch_dims</code> dimensions.</p>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/nn.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sum_except_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sums all elements of `x` except for the first `num_batch_dims` dimensions.&quot;&quot;&quot;</span>
    <span class="n">reduce_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_batch_dims</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">reduce_dims</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.utils.optim" class="doc doc-heading">
            <code>optim</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="normflows.utils.optim.clear_grad" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">clear_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Set gradients of model parameter to None as this speeds up training,</p>
<p>See <a href="https://www.youtube.com/watch?v=9mS1fIYj1So">youtube</a></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model to clear gradients of</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/optim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">clear_grad</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set gradients of model parameter to None as this speeds up training,</span>

<span class="sd">    See [youtube](https://www.youtube.com/watch?v=9mS1fIYj1So)</span>

<span class="sd">    Args:</span>
<span class="sd">      model: Model to clear gradients of</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="normflows.utils.optim.set_requires_grad" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">set_requires_grad</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">flag</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

      <p>Sets requires_grad flag of all parameters of a torch.nn.module</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>module</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.nn.module</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>flag</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag to set requires_grad to</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/optim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_requires_grad</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">flag</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sets requires_grad flag of all parameters of a torch.nn.module</span>

<span class="sd">    Args:</span>
<span class="sd">      module: torch.nn.module</span>
<span class="sd">      flag: Flag to set requires_grad to</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">flag</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="normflows.utils.preprocessing" class="doc doc-heading">
            <code>preprocessing</code>


</h3>

    <div class="doc doc-contents ">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="normflows.utils.preprocessing.Jitter" class="doc doc-heading">
            <code>Jitter</code>


</h4>


    <div class="doc doc-contents ">


      <p>Transform for dataloader, adds uniform jitter noise to data</p>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/preprocessing.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Jitter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform for dataloader, adds uniform jitter noise to data&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mi">256</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          scale: Scaling factor for noise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">x_</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">eps</span>
        <span class="k">return</span> <span class="n">x_</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.preprocessing.Jitter.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mi">256</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scaling factor for noise</p>
              </div>
            </td>
            <td>
                  <code>1.0 / 256</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/preprocessing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mi">256</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      scale: Scaling factor for noise</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.utils.preprocessing.Logit" class="doc doc-heading">
            <code>Logit</code>


</h4>


    <div class="doc doc-contents ">


      <p>Transform for dataloader</p>
<pre><code>logit(alpha + (1 - alpha) * x) where logit(x) = log(x / (1 - x))
</code></pre>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/preprocessing.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Logit</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform for dataloader</span>

<span class="sd">    ```</span>
<span class="sd">    logit(alpha + (1 - alpha) * x) where logit(x) = log(x / (1 - x))</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          alpha: see above</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x_</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x_</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.preprocessing.Logit.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>alpha</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>see above</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/preprocessing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      alpha: see above</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="normflows.utils.preprocessing.Scale" class="doc doc-heading">
            <code>Scale</code>


</h4>


    <div class="doc doc-contents ">


      <p>Transform for dataloader, adds uniform jitter noise to data</p>

              <details class="quote">
                <summary>Source code in <code>normflows/utils/preprocessing.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Scale</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform for dataloader, adds uniform jitter noise to data&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">255.0</span> <span class="o">/</span> <span class="mf">256.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">          scale: Scaling factor for noise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="normflows.utils.preprocessing.Scale.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">255.0</span> <span class="o">/</span> <span class="mf">256.0</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

      <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>scale</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scaling factor for noise</p>
              </div>
            </td>
            <td>
                  <code>255.0 / 256.0</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>normflows/utils/preprocessing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">255.0</span> <span class="o">/</span> <span class="mf">256.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">    Args:</span>
<span class="sd">      scale: Scaling factor for noise</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>


  </div>

    </div>

</div>


  </div>

    </div>

</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
